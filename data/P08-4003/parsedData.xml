<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000420">
<bodyText confidence="0.7861935">
b&amp;apos;Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 912,
Columbus, June 2008. c
</bodyText>
<figure confidence="0.589689777777778">
2008 Association for Computational Linguistics
BART: A Modular Toolkit for Coreference Resolution
Yannick Versley
University of Tubingen
versley@sfs.uni-tuebingen.de
Simone Paolo Ponzetto
EML Research gGmbH
ponzetto@eml-research.de
Massimo Poesio
</figure>
<affiliation confidence="0.969682">
University of Essex
</affiliation>
<email confidence="0.978772">
poesio@essex.ac.uk
</email>
<author confidence="0.95057">
Vladimir Eidelman
</author>
<affiliation confidence="0.990396">
Columbia University
</affiliation>
<email confidence="0.965904">
vae2101@columbia.edu
</email>
<author confidence="0.595959">
Alan Jern
</author>
<affiliation confidence="0.388974">
UCLA
</affiliation>
<email confidence="0.969065">
ajern@ucla.edu
</email>
<author confidence="0.981243">
Jason Smith
</author>
<affiliation confidence="0.990474">
Johns Hopkins University
</affiliation>
<email confidence="0.994811">
jsmith@jhu.edu
</email>
<author confidence="0.935192">
Xiaofeng Yang
</author>
<affiliation confidence="0.945286">
Inst. for Infocomm Research
</affiliation>
<email confidence="0.951286">
xiaofengy@i2r.a-star.edu.sg
</email>
<author confidence="0.980352">
Alessandro Moschitti
</author>
<affiliation confidence="0.999072">
University of Trento
</affiliation>
<email confidence="0.987107">
moschitti@dit.unitn.it
</email>
<sectionHeader confidence="0.989977" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998759722222222">
Developing a full coreference system able
to run all the way from raw text to seman-
tic interpretation is a considerable engineer-
ing effort, yet there is very limited avail-
ability of off-the shelf tools for researchers
whose interests are not in coreference, or for
researchers who want to concentrate on a
specific aspect of the problem. We present
BART, a highly modular toolkit for de-
veloping coreference applications. In the
Johns Hopkins workshop on using lexical
and encyclopedic knowledge for entity dis-
ambiguation, the toolkit was used to ex-
tend a reimplementation of the Soon et al.
(2001) proposal with a variety of additional
syntactic and knowledge-based features, and
experiment with alternative resolution pro-
cesses, preprocessing tools, and classifiers.
</bodyText>
<sectionHeader confidence="0.997357" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99914775">
Coreference resolution refers to the task of identify-
ing noun phrases that refer to the same extralinguis-
tic entity in a text. Using coreference information
has been shown to be beneficial in a number of other
tasks, including information extraction (McCarthy
and Lehnert, 1995), question answering (Morton,
2000) and summarization (Steinberger et al., 2007).
Developing a full coreference system, however, is
a considerable engineering effort, which is why a
large body of research concerned with feature en-
gineering or learning methods (e.g. Culotta et al.
2007; Denis and Baldridge 2007) uses a simpler but
non-realistic setting, using pre-identified mentions,
and the use of coreference information in summa-
rization or question answering techniques is not as
widespread as it could be. We believe that the avail-
ability of a modular toolkit for coreference will sig-
nificantly lower the entrance barrier for researchers
interested in coreference resolution, as well as pro-
vide a component that can be easily integrated into
other NLP applications.
A number of systems that perform coreference
resolution are publicly available, such as GUITAR
(Steinberger et al., 2007), which handles the full
coreference task, and JAVARAP (Qiu et al., 2004),
which only resolves pronouns. However, literature
on coreference resolution, if providing a baseline,
usually uses the algorithm and feature set of Soon
et al. (2001) for this purpose.
Using the built-in maximum entropy learner
with feature combination, BART reaches 65.8%
F-measure on MUC6 and 62.9% F-measure on
MUC7 using Soon et al.s features, outperforming
JAVARAP on pronoun resolution, as well as the
Soon et al. reimplementation of Uryupina (2006).
Using a specialized tagger for ACE mentions and
an extended feature set including syntactic features
(e.g. using tree kernels to represent the syntactic
relation between anaphor and antecedent, cf. Yang
et al. 2006), as well as features based on knowledge
extracted from Wikipedia (cf. Ponzetto and Smith, in
preparation), BART reaches state-of-the-art results
on ACE-2. Table 1 compares our results, obtained
using this extended feature set, with results from
Ng (2007). Pronoun resolution using the extended
feature set gives 73.4% recall, coming near special-
ized pronoun resolution systems such as (Denis and
Baldridge, 2007).
</bodyText>
<page confidence="0.976238">
9
</page>
<figureCaption confidence="0.489851">
\x0cFigure 1: Results analysis in MMAX2
</figureCaption>
<sectionHeader confidence="0.794244" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.995949035714286">
The BART toolkit has been developed as a tool to
explore the integration of knowledge-rich features
into a coreference system at the Johns Hopkins Sum-
mer Workshop 2007. It is based on code and ideas
from the system of Ponzetto and Strube (2006), but
also includes some ideas from GUITAR (Steinberger
et al., 2007) and other coreference systems (Versley,
2006; Yang et al., 2006). 1
The goal of bringing together state-of-the-art ap-
proaches to different aspects of coreference res-
olution, including specialized preprocessing and
syntax-based features has led to a design that is very
modular. This design provides effective separation
of concerns across several several tasks/roles, in-
cluding engineering new features that exploit dif-
ferent sources of knowledge, designing improved or
specialized preprocessing methods, and improving
the way that coreference resolution is mapped to a
machine learning problem.
Preprocessing To store results of preprocessing
components, BART uses the standoff format of the
MMAX2 annotation tool (Muller and Strube, 2006)
with MiniDiscourse, a library that efficiently imple-
ments a subset of MMAX2s functions. Using a
generic format for standoff annotation allows the use
of the coreference resolution as part of a larger sys-
tem, but also performing qualitative error analysis
using integrated MMAX2 functionality (annotation
</bodyText>
<page confidence="0.686531">
1
</page>
<bodyText confidence="0.987064795918367">
An open source version of BART is available from
http://www.sfs.uni-tuebingen.de/ versley/BART/.
diff, visual display).
Preprocessing consists in marking up noun
chunks and named entities, as well as additional in-
formation such as part-of-speech tags and merging
these information into markables that are the start-
ing point for the mentions used by the coreference
resolution proper.
Starting out with a chunking pipeline, which
uses a classical combination of tagger and chun-
ker, with the Stanford POS tagger (Toutanova et al.,
2003), the YamCha chunker (Kudoh and Mat-
sumoto, 2000) and the Stanford Named Entity Rec-
ognizer (Finkel et al., 2005), the desire to use richer
syntactic representations led to the development of
a parsing pipeline, which uses Charniak and John-
sons reranking parser (Charniak and Johnson, 2005)
to assign POS tags and uses base NPs as chunk
equivalents, while also providing syntactic trees that
can be used by feature extractors. BART also sup-
ports using the Berkeley parser (Petrov et al., 2006),
yielding an easy-to-use Java-only solution.
To provide a better starting point for mention de-
tection on the ACE corpora, the Carafe pipeline
uses an ACE mention tagger provided by MITRE
(Wellner and Vilain, 2006). A specialized merger
then discards any base NP that was not detected to
be an ACE mention.
To perform coreference resolution proper, the
mention-building module uses the markables cre-
ated by the pipeline to create mention objects, which
provide an interface more appropriate for corefer-
ence resolution than the MiniDiscourse markables.
These objects are grouped into equivalence classes
by the resolution process and a coreference layer is
written into the document, which can be used for de-
tailed error analysis.
Feature Extraction BARTs default resolver goes
through all mentions and looks for possible an-
tecedents in previous mentions as described by Soon
et al. (2001). Each pair of anaphor and candi-
date is represented as a PairInstance object,
which is enriched with classification features by fea-
ture extractors, and then handed over to a machine
learning-based classifier that decides, given the fea-
tures, whether anaphor and candidate are corefer-
ent or not. Feature extractors are realized as sepa-
rate classes, allowing for their independent develop-
</bodyText>
<page confidence="0.989953">
10
</page>
<figureCaption confidence="0.7767285">
\x0cFigure 2: Example system configuration
ment. The set of feature extractors that the system
</figureCaption>
<bodyText confidence="0.989181107142857">
uses is set in an XML description file, which allows
for straightforward prototyping and experimentation
with different feature sets.
Learning BART provides a generic abstraction
layer that maps application-internal representations
to a suitable format for several machine learning
toolkits: One module exposes the functionality of
the the WEKA machine learning toolkit (Witten
and Frank, 2005), while others interface to special-
ized state-of-the art learners. SVMLight (Joachims,
1999), in the SVMLight/TK (Moschitti, 2006) vari-
ant, allows to use tree-valued features. SVM Classi-
fication uses a Java Native Interface-based wrapper
replacing SVMLight/TKs svm classify pro-
gram to improve the classification speed. Also in-
cluded is a Maximum entropy classifier that is
based upon Robert Dodiers translation of Liu and
Nocedals (1989) L-BFGS optimization code, with
a function for programmatic feature combination.2
Training/Testing The training and testing phases
slightly differ from each other. In the training phase,
the pairs that are to be used as training examples
have to be selected in a process of sample selection,
whereas in the testing phase, it has to be decided
which pairs are to be given to the decision function
and how to group mentions into equivalence rela-
tions given the classifier decisions.
This functionality is factored out into the en-
</bodyText>
<page confidence="0.91266">
2
</page>
<bodyText confidence="0.980648125">
see http://riso.sourceforge.net
coder/decoder component, which is separate from
feature extraction and machine learning itself. It
is possible to completely change the basic behav-
ior of the coreference system by providing new
encoders/decoders, and still rely on the surround-
ing infrastructure for feature extraction and machine
learning components.
</bodyText>
<sectionHeader confidence="0.990209" genericHeader="method">
3 Using BART
</sectionHeader>
<bodyText confidence="0.999530818181818">
Although BART is primarily meant as a platform for
experimentation, it can be used simply as a corefer-
ence resolver, with a performance close to state of
the art. It is possible to import raw text, perform
preprocessing and coreference resolution, and either
work on the MMAX2-format files, or export the re-
sults to arbitrary inline XML formats using XSL
stylesheets.
Adapting BART to a new coreferentially anno-
tated corpus (which may have different rules for
mention extraction witness the differences be-
tween the annotation guidelines of MUC and ACE
corpora) usually involves fine-tuning of mention cre-
ation (using pipeline and MentionFactory settings),
as well as the selection and fine-tuning of classi-
fier and features. While it is possible to make rad-
ical changes in the preprocessing by re-engineering
complete pipeline components, it is usually possi-
ble to achieve the bulk of the task by simply mix-
ing and matching existing components for prepro-
cessing and feature extraction, which is possible by
modifying only configuration settings and an XML-
</bodyText>
<page confidence="0.999022">
11
</page>
<table confidence="0.971533428571428">
\x0cBNews NPaper NWire
Recl Prec F Recl Prec F Recl Prec F
basic feature set 0.594 0.522 0.556 0.663 0.526 0.586 0.608 0.474 0.533
extended feature set 0.607 0.654 0.630 0.641 0.677 0.658 0.604 0.652 0.627
Ng 2007
0.561 0.763 0.647 0.544 0.797 0.646 0.535 0.775 0.633
: expanded feature set in Ng 2007; Ng trains on the entire ACE training corpus.
</table>
<tableCaption confidence="0.999398">
Table 1: Performance on ACE-2 corpora, basic vs. extended feature set
</tableCaption>
<bodyText confidence="0.9952955">
based description of the feature set and learner(s)
used.
Several research groups focusing on coreference
resolution, including two not involved in the ini-
tial creation of BART, are using it as a platform
for research including the use of new information
sources (which can be easily incorporated into the
coreference resolution process as features), different
resolution algorithms that aim at enhancing global
coherence of coreference chains, and also adapting
BART to different corpora. Through the availability
of BART as open source, as well as its modularity
and adaptability, we hope to create a larger com-
munity that allows both to push the state of the art
further and to make these improvements available to
users of coreference resolution.
Acknowledgements We thank the CLSP at Johns
Hopkins, NSF and the Department of Defense for
ensuring funding for the workshop and to EML
Research, MITRE, the Center for Excellence in
HLT, and FBK-IRST, that provided partial support.
Yannick Versley was supported by the Deutsche
Forschungsgesellschaft as part of SFB 441 Lin-
guistic Data Structures; Simone Paolo Ponzetto has
been supported by the Klaus Tschira Foundation
(grant 09.003.2004).
</bodyText>
<sectionHeader confidence="0.962011" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.970871125">
Charniak, E. and Johnson, M. (2005). Coarse-to-fine n-best
parsing and maxent discriminative reranking. In Proc. ACL
2005.
Culotta, A., Wick, M., and McCallum, A. (2007). First-order
probabilistic models for coreference resolution. In Proc.
HLT/NAACL 2007.
Denis, P. and Baldridge, J. (2007). A ranking approach to pro-
noun resolution. In Proc. IJCAI 2007.
Finkel, J. R., Grenager, T., and Manning, C. (2005). Incorpo-
rating non-local information into information extraction sys-
tems by Gibbs sampling. In Proc. ACL 2005, pages 363370.
Joachims, T. (1999). Making large-scale SVM learning prac-
tical. In Scholkopf, B., Burges, C., and Smola, A., editors,
Advances in Kernel Methods - Support Vector Learning.
Kudoh, T. and Matsumoto, Y. (2000). Use of Support Vector
Machines for chunk identification. In Proc. CoNLL 2000.
Liu, D. C. and Nocedal, J. (1989). On the limited memory
method for large scale optimization. Mathematical Program-
ming B, 45(3):503528.
McCarthy, J. F. and Lehnert, W. G. (1995). Using decision trees
for coreference resolution. In Proc. IJCAI 1995.
Morton, T. S. (2000). Coreference for NLP applications. In
Proc. ACL 2000.
Moschitti, A. (2006). Making tree kernels practical for natural
language learning. In Proc. EACL 2006.
Muller, C. and Strube, M. (2006). Multi-level annotation of
linguistic data with MMAX2. In Braun, S., Kohn, K., and
Mukherjee, J., editors, Corpus Technology and Language
Pedagogy: New Resources, New Tools, New Methods. Peter
Lang, Frankfurt a.M., Germany.
Ng, V. (2007). Shallow semantics for coreference resolution. In
Proc. IJCAI 2007.
Petrov, S., Barett, L., Thibaux, R., and Klein, D. (2006). Learn-
ing accurate, compact, and interpretable tree annotation. In
COLING-ACL 2006.
Ponzetto, S. P. and Strube, M. (2006). Exploiting semantic role
labeling, WordNet and Wikipedia for coreference resolution.
In Proc. HLT/NAACL 2006.
Qiu, L., Kan, M.-Y., and Chua, T.-S. (2004). A public reference
implementation of the RAP anaphora resolution algorithm.
In Proc. LREC 2004.
Soon, W. M., Ng, H. T., and Lim, D. C. Y. (2001). A machine
learning approach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521544.
Steinberger, J., Poesio, M., Kabadjov, M., and Jezek, K. (2007).
Two uses of anaphora resolution in summarization. Informa-
tion Processing and Management, 43:16631680. Special
issue on Summarization.
Toutanova, K., Klein, D., Manning, C. D., and Singer, Y.
(2003). Feature-rich part-of-speech tagging with a cyclic de-
pendency network. In Proc. NAACL 2003, pages 252259.
Uryupina, O. (2006). Coreference resolution with and without
linguistic knowledge. In Proc. LREC 2006.
Versley, Y. (2006). A constraint-based approach to noun phrase
coreference resolution in German newspaper text. In Kon-
ferenz zur Verarbeitung Naturlicher Sprache (KONVENS
2006).
Wellner, B. and Vilain, M. (2006). Leveraging machine read-
able dictionaries in discriminative sequence models. In Proc.
LREC 2006.
Witten, I. and Frank, E. (2005). Data Mining: Practical ma-
chine learning tools and techniques. Morgan Kaufmann.
Yang, X., Su, J., and Tan, C. L. (2006). Kernel-based pronoun
resolution with structured syntactic knowledge. In Proc.
</reference>
<figure confidence="0.549204666666667">
CoLing/ACL-2006.
12
\x0c&amp;apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.189881">
<note confidence="0.715346333333333">b&amp;apos;Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 912, Columbus, June 2008. c 2008 Association for Computational Linguistics</note>
<title confidence="0.924037">BART: A Modular Toolkit for Coreference Resolution</title>
<author confidence="0.979677">Yannick Versley</author>
<affiliation confidence="0.997047">University of Tubingen</affiliation>
<email confidence="0.927839">versley@sfs.uni-tuebingen.de</email>
<author confidence="0.994452">Simone Paolo Ponzetto</author>
<affiliation confidence="0.828563">EML Research gGmbH</affiliation>
<email confidence="0.743906">ponzetto@eml-research.de</email>
<author confidence="0.999705">Massimo Poesio</author>
<affiliation confidence="0.999591">University of Essex</affiliation>
<email confidence="0.991998">poesio@essex.ac.uk</email>
<author confidence="0.981271">Vladimir Eidelman</author>
<affiliation confidence="0.999989">Columbia University</affiliation>
<email confidence="0.990943">vae2101@columbia.edu</email>
<author confidence="0.999848">Alan Jern</author>
<affiliation confidence="0.886324">UCLA</affiliation>
<email confidence="0.996851">ajern@ucla.edu</email>
<author confidence="0.999962">Jason Smith</author>
<affiliation confidence="0.999483">Johns Hopkins University</affiliation>
<email confidence="0.998604">jsmith@jhu.edu</email>
<author confidence="0.989982">Xiaofeng Yang</author>
<affiliation confidence="0.996695">Inst. for Infocomm Research</affiliation>
<email confidence="0.806371">xiaofengy@i2r.a-star.edu.sg</email>
<author confidence="0.998857">Alessandro Moschitti</author>
<affiliation confidence="0.999892">University of Trento</affiliation>
<email confidence="0.997323">moschitti@dit.unitn.it</email>
<abstract confidence="0.997116526315789">Developing a full coreference system able to run all the way from raw text to semantic interpretation is a considerable engineering effort, yet there is very limited availability of off-the shelf tools for researchers whose interests are not in coreference, or for researchers who want to concentrate on a specific aspect of the problem. We present BART, a highly modular toolkit for developing coreference applications. In the Johns Hopkins workshop on using lexical and encyclopedic knowledge for entity disambiguation, the toolkit was used to extend a reimplementation of the Soon et al. (2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes, preprocessing tools, and classifiers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Coarse-to-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proc. ACL</booktitle>
<contexts>
<context position="6034" citStr="Charniak and Johnson, 2005" startWordPosition="888" endWordPosition="891">l as additional information such as part-of-speech tags and merging these information into markables that are the starting point for the mentions used by the coreference resolution proper. Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the ACE corpora, the Carafe pipeline uses an ACE mention tagger provided by MITRE (Wellner and Vilain, 2006). A specialized merger then discards any base NP that was not detected to be an ACE mention. To perform coreference resolution proper, the mention-building module uses the markables c</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Charniak, E. and Johnson, M. (2005). Coarse-to-fine n-best parsing and maxent discriminative reranking. In Proc. ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>M Wick</author>
<author>A McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proc.</booktitle>
<contexts>
<context position="2017" citStr="Culotta et al. 2007" startWordPosition="279" endWordPosition="282">s, preprocessing tools, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution, as well as provide a component that can be easily integrated into other NLP applications. A number of systems that perform coreference resolution are publicly available, such as GUITAR (Steinberger et al</context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Culotta, A., Wick, M., and McCallum, A. (2007). First-order probabilistic models for coreference resolution. In Proc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HLTNAACL</author>
</authors>
<date>2007</date>
<marker>HLTNAACL, 2007</marker>
<rawString>HLT/NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>A ranking approach to pronoun resolution.</title>
<date>2007</date>
<booktitle>In Proc. IJCAI</booktitle>
<contexts>
<context position="2044" citStr="Denis and Baldridge 2007" startWordPosition="283" endWordPosition="286">s, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution, as well as provide a component that can be easily integrated into other NLP applications. A number of systems that perform coreference resolution are publicly available, such as GUITAR (Steinberger et al., 2007), which handles the</context>
<context position="3785" citStr="Denis and Baldridge, 2007" startWordPosition="547" endWordPosition="550">ing a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference system at the Johns Hopkins Summer Workshop 2007. It is based on code and ideas from the system of Ponzetto and Strube (2006), but also includes some ideas from GUITAR (Steinberger et al., 2007) and other coreference systems (Versley, 2006; Yang et al., 2006). 1 The goal of bringing together state-of-the-art approaches to different aspects of coreference resolution, including specialized preprocessing and syntax</context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Denis, P. and Baldridge, J. (2007). A ranking approach to pronoun resolution. In Proc. IJCAI 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proc. ACL</booktitle>
<pages>363370</pages>
<contexts>
<context position="5857" citStr="Finkel et al., 2005" startWordPosition="861" endWordPosition="864"> BART is available from http://www.sfs.uni-tuebingen.de/ versley/BART/. diff, visual display). Preprocessing consists in marking up noun chunks and named entities, as well as additional information such as part-of-speech tags and merging these information into markables that are the starting point for the mentions used by the coreference resolution proper. Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the ACE corpora, the Carafe pipeline uses an ACE mention tagger provided by MITRE (Wellner and Vilain, 2006). A sp</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, J. R., Grenager, T., and Manning, C. (2005). Incorporating non-local information into information extraction systems by Gibbs sampling. In Proc. ACL 2005, pages 363370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning.</booktitle>
<editor>In Scholkopf, B., Burges, C., and Smola, A., editors,</editor>
<contexts>
<context position="8095" citStr="Joachims, 1999" startWordPosition="1206" endWordPosition="1207">g for their independent develop10 \x0cFigure 2: Example system configuration ment. The set of feature extractors that the system uses is set in an XML description file, which allows for straightforward prototyping and experimentation with different feature sets. Learning BART provides a generic abstraction layer that maps application-internal representations to a suitable format for several machine learning toolkits: One module exposes the functionality of the the WEKA machine learning toolkit (Witten and Frank, 2005), while others interface to specialized state-of-the art learners. SVMLight (Joachims, 1999), in the SVMLight/TK (Moschitti, 2006) variant, allows to use tree-valued features. SVM Classification uses a Java Native Interface-based wrapper replacing SVMLight/TKs svm classify program to improve the classification speed. Also included is a Maximum entropy classifier that is based upon Robert Dodiers translation of Liu and Nocedals (1989) L-BFGS optimization code, with a function for programmatic feature combination.2 Training/Testing The training and testing phases slightly differ from each other. In the training phase, the pairs that are to be used as training examples have to be select</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Joachims, T. (1999). Making large-scale SVM learning practical. In Scholkopf, B., Burges, C., and Smola, A., editors, Advances in Kernel Methods - Support Vector Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudoh</author>
<author>Y Matsumoto</author>
</authors>
<title>Use of Support Vector Machines for chunk identification.</title>
<date>2000</date>
<booktitle>In Proc. CoNLL</booktitle>
<contexts>
<context position="5794" citStr="Kudoh and Matsumoto, 2000" startWordPosition="849" endWordPosition="853">ntegrated MMAX2 functionality (annotation 1 An open source version of BART is available from http://www.sfs.uni-tuebingen.de/ versley/BART/. diff, visual display). Preprocessing consists in marking up noun chunks and named entities, as well as additional information such as part-of-speech tags and merging these information into markables that are the starting point for the mentions used by the coreference resolution proper. Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the ACE corpora, the Carafe pipeline uses an ACE me</context>
</contexts>
<marker>Kudoh, Matsumoto, 2000</marker>
<rawString>Kudoh, T. and Matsumoto, Y. (2000). Use of Support Vector Machines for chunk identification. In Proc. CoNLL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Liu</author>
<author>J Nocedal</author>
</authors>
<title>On the limited memory method for large scale optimization.</title>
<date>1989</date>
<journal>Mathematical Programming B,</journal>
<volume>45</volume>
<issue>3</issue>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Liu, D. C. and Nocedal, J. (1989). On the limited memory method for large scale optimization. Mathematical Programming B, 45(3):503528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F McCarthy</author>
<author>W G Lehnert</author>
</authors>
<title>Using decision trees for coreference resolution.</title>
<date>1995</date>
<booktitle>In Proc. IJCAI</booktitle>
<contexts>
<context position="1732" citStr="McCarthy and Lehnert, 1995" startWordPosition="237" endWordPosition="240">Hopkins workshop on using lexical and encyclopedic knowledge for entity disambiguation, the toolkit was used to extend a reimplementation of the Soon et al. (2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes, preprocessing tools, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly</context>
</contexts>
<marker>McCarthy, Lehnert, 1995</marker>
<rawString>McCarthy, J. F. and Lehnert, W. G. (1995). Using decision trees for coreference resolution. In Proc. IJCAI 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T S Morton</author>
</authors>
<title>Coreference for NLP applications. In</title>
<date>2000</date>
<booktitle>Proc. ACL</booktitle>
<contexts>
<context position="1767" citStr="Morton, 2000" startWordPosition="243" endWordPosition="244">c knowledge for entity disambiguation, the toolkit was used to extend a reimplementation of the Soon et al. (2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes, preprocessing tools, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for res</context>
</contexts>
<marker>Morton, 2000</marker>
<rawString>Morton, T. S. (2000). Coreference for NLP applications. In Proc. ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proc. EACL</booktitle>
<contexts>
<context position="8133" citStr="Moschitti, 2006" startWordPosition="1211" endWordPosition="1212">cFigure 2: Example system configuration ment. The set of feature extractors that the system uses is set in an XML description file, which allows for straightforward prototyping and experimentation with different feature sets. Learning BART provides a generic abstraction layer that maps application-internal representations to a suitable format for several machine learning toolkits: One module exposes the functionality of the the WEKA machine learning toolkit (Witten and Frank, 2005), while others interface to specialized state-of-the art learners. SVMLight (Joachims, 1999), in the SVMLight/TK (Moschitti, 2006) variant, allows to use tree-valued features. SVM Classification uses a Java Native Interface-based wrapper replacing SVMLight/TKs svm classify program to improve the classification speed. Also included is a Maximum entropy classifier that is based upon Robert Dodiers translation of Liu and Nocedals (1989) L-BFGS optimization code, with a function for programmatic feature combination.2 Training/Testing The training and testing phases slightly differ from each other. In the training phase, the pairs that are to be used as training examples have to be selected in a process of sample selection, w</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Moschitti, A. (2006). Making tree kernels practical for natural language learning. In Proc. EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Muller</author>
<author>M Strube</author>
</authors>
<title>Multi-level annotation of linguistic data with MMAX2.</title>
<date>2006</date>
<booktitle>Corpus Technology and Language Pedagogy: New Resources,</booktitle>
<editor>In Braun, S., Kohn, K., and Mukherjee, J., editors,</editor>
<location>New Tools, New Methods. Peter Lang, Frankfurt a.M., Germany.</location>
<contexts>
<context position="4905" citStr="Muller and Strube, 2006" startWordPosition="716" endWordPosition="719">pproaches to different aspects of coreference resolution, including specialized preprocessing and syntax-based features has led to a design that is very modular. This design provides effective separation of concerns across several several tasks/roles, including engineering new features that exploit different sources of knowledge, designing improved or specialized preprocessing methods, and improving the way that coreference resolution is mapped to a machine learning problem. Preprocessing To store results of preprocessing components, BART uses the standoff format of the MMAX2 annotation tool (Muller and Strube, 2006) with MiniDiscourse, a library that efficiently implements a subset of MMAX2s functions. Using a generic format for standoff annotation allows the use of the coreference resolution as part of a larger system, but also performing qualitative error analysis using integrated MMAX2 functionality (annotation 1 An open source version of BART is available from http://www.sfs.uni-tuebingen.de/ versley/BART/. diff, visual display). Preprocessing consists in marking up noun chunks and named entities, as well as additional information such as part-of-speech tags and merging these information into markabl</context>
</contexts>
<marker>Muller, Strube, 2006</marker>
<rawString>Muller, C. and Strube, M. (2006). Multi-level annotation of linguistic data with MMAX2. In Braun, S., Kohn, K., and Mukherjee, J., editors, Corpus Technology and Language Pedagogy: New Resources, New Tools, New Methods. Peter Lang, Frankfurt a.M., Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Shallow semantics for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proc. IJCAI</booktitle>
<contexts>
<context position="3627" citStr="Ng (2007)" startWordPosition="526" endWordPosition="527"> using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference system at the Johns Hopkins Summer Workshop 2007. It is based on code and ideas from the system of Ponzetto and Strube (2006), but also includes some ideas from GUITAR (Steinberger et al., 2007) and other coreference systems (Versley, 2006; Yang et al., 200</context>
<context position="10603" citStr="Ng 2007" startWordPosition="1603" endWordPosition="1604">as the selection and fine-tuning of classifier and features. While it is possible to make radical changes in the preprocessing by re-engineering complete pipeline components, it is usually possible to achieve the bulk of the task by simply mixing and matching existing components for preprocessing and feature extraction, which is possible by modifying only configuration settings and an XML11 \x0cBNews NPaper NWire Recl Prec F Recl Prec F Recl Prec F basic feature set 0.594 0.522 0.556 0.663 0.526 0.586 0.608 0.474 0.533 extended feature set 0.607 0.654 0.630 0.641 0.677 0.658 0.604 0.652 0.627 Ng 2007 0.561 0.763 0.647 0.544 0.797 0.646 0.535 0.775 0.633 : expanded feature set in Ng 2007; Ng trains on the entire ACE training corpus. Table 1: Performance on ACE-2 corpora, basic vs. extended feature set based description of the feature set and learner(s) used. Several research groups focusing on coreference resolution, including two not involved in the initial creation of BART, are using it as a platform for research including the use of new information sources (which can be easily incorporated into the coreference resolution process as features), different resolution algorithms that aim at </context>
</contexts>
<marker>Ng, 2007</marker>
<rawString>Ng, V. (2007). Shallow semantics for coreference resolution. In Proc. IJCAI 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>L Barett</author>
<author>R Thibaux</author>
<author>D Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In COLING-ACL</booktitle>
<contexts>
<context position="6237" citStr="Petrov et al., 2006" startWordPosition="923" endWordPosition="926">hunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the ACE corpora, the Carafe pipeline uses an ACE mention tagger provided by MITRE (Wellner and Vilain, 2006). A specialized merger then discards any base NP that was not detected to be an ACE mention. To perform coreference resolution proper, the mention-building module uses the markables created by the pipeline to create mention objects, which provide an interface more appropriate for coreference resolution than the MiniDiscourse markables. These objects are grouped into equivalence class</context>
</contexts>
<marker>Petrov, Barett, Thibaux, Klein, 2006</marker>
<rawString>Petrov, S., Barett, L., Thibaux, R., and Klein, D. (2006). Learning accurate, compact, and interpretable tree annotation. In COLING-ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P Ponzetto</author>
<author>M Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<contexts>
<context position="4095" citStr="Ponzetto and Strube (2006)" startWordPosition="600" endWordPosition="603">paration), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference system at the Johns Hopkins Summer Workshop 2007. It is based on code and ideas from the system of Ponzetto and Strube (2006), but also includes some ideas from GUITAR (Steinberger et al., 2007) and other coreference systems (Versley, 2006; Yang et al., 2006). 1 The goal of bringing together state-of-the-art approaches to different aspects of coreference resolution, including specialized preprocessing and syntax-based features has led to a design that is very modular. This design provides effective separation of concerns across several several tasks/roles, including engineering new features that exploit different sources of knowledge, designing improved or specialized preprocessing methods, and improving the way tha</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Ponzetto, S. P. and Strube, M. (2006). Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>In Proc. HLT/NAACL</booktitle>
<contexts>
<context position="3155" citStr="(2006)" startWordPosition="456" endWordPosition="456">resolution are publicly available, such as GUITAR (Steinberger et al., 2007), which handles the full coreference task, and JAVARAP (Qiu et al., 2004), which only resolves pronouns. However, literature on coreference resolution, if providing a baseline, usually uses the algorithm and feature set of Soon et al. (2001) for this purpose. Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such </context>
</contexts>
<marker>2006</marker>
<rawString>In Proc. HLT/NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Qiu</author>
<author>M-Y Kan</author>
<author>T-S Chua</author>
</authors>
<title>A public reference implementation of the RAP anaphora resolution algorithm.</title>
<date>2004</date>
<contexts>
<context position="2698" citStr="Qiu et al., 2004" startWordPosition="384" endWordPosition="387">ting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution, as well as provide a component that can be easily integrated into other NLP applications. A number of systems that perform coreference resolution are publicly available, such as GUITAR (Steinberger et al., 2007), which handles the full coreference task, and JAVARAP (Qiu et al., 2004), which only resolves pronouns. However, literature on coreference resolution, if providing a baseline, usually uses the algorithm and feature set of Soon et al. (2001) for this purpose. Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent th</context>
</contexts>
<marker>Qiu, Kan, Chua, 2004</marker>
<rawString>Qiu, L., Kan, M.-Y., and Chua, T.-S. (2004). A public reference implementation of the RAP anaphora resolution algorithm.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>In Proc. LREC</booktitle>
<marker>2004</marker>
<rawString>In Proc. LREC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Soon</author>
<author>H T Ng</author>
<author>D C Y Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1268" citStr="Soon et al. (2001)" startWordPosition="170" endWordPosition="173">it.unitn.it Abstract Developing a full coreference system able to run all the way from raw text to semantic interpretation is a considerable engineering effort, yet there is very limited availability of off-the shelf tools for researchers whose interests are not in coreference, or for researchers who want to concentrate on a specific aspect of the problem. We present BART, a highly modular toolkit for developing coreference applications. In the Johns Hopkins workshop on using lexical and encyclopedic knowledge for entity disambiguation, the toolkit was used to extend a reimplementation of the Soon et al. (2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes, preprocessing tools, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a co</context>
<context position="2866" citStr="Soon et al. (2001)" startWordPosition="409" endWordPosition="412">elieve that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution, as well as provide a component that can be easily integrated into other NLP applications. A number of systems that perform coreference resolution are publicly available, such as GUITAR (Steinberger et al., 2007), which handles the full coreference task, and JAVARAP (Qiu et al., 2004), which only resolves pronouns. However, literature on coreference resolution, if providing a baseline, usually uses the algorithm and feature set of Soon et al. (2001) for this purpose. Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in </context>
<context position="7125" citStr="Soon et al. (2001)" startWordPosition="1062" endWordPosition="1065">s not detected to be an ACE mention. To perform coreference resolution proper, the mention-building module uses the markables created by the pipeline to create mention objects, which provide an interface more appropriate for coreference resolution than the MiniDiscourse markables. These objects are grouped into equivalence classes by the resolution process and a coreference layer is written into the document, which can be used for detailed error analysis. Feature Extraction BARTs default resolver goes through all mentions and looks for possible antecedents in previous mentions as described by Soon et al. (2001). Each pair of anaphor and candidate is represented as a PairInstance object, which is enriched with classification features by feature extractors, and then handed over to a machine learning-based classifier that decides, given the features, whether anaphor and candidate are coreferent or not. Feature extractors are realized as separate classes, allowing for their independent develop10 \x0cFigure 2: Example system configuration ment. The set of feature extractors that the system uses is set in an XML description file, which allows for straightforward prototyping and experimentation with differ</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Soon, W. M., Ng, H. T., and Lim, D. C. Y. (2001). A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>M Poesio</author>
<author>M Kabadjov</author>
<author>K Jezek</author>
</authors>
<title>Two uses of anaphora resolution in summarization.</title>
<date>2007</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>43--16631680</pages>
<note>Special issue on Summarization.</note>
<contexts>
<context position="1812" citStr="Steinberger et al., 2007" startWordPosition="247" endWordPosition="250">tion, the toolkit was used to extend a reimplementation of the Soon et al. (2001) proposal with a variety of additional syntactic and knowledge-based features, and experiment with alternative resolution processes, preprocessing tools, and classifiers. 1 Introduction Coreference resolution refers to the task of identifying noun phrases that refer to the same extralinguistic entity in a text. Using coreference information has been shown to be beneficial in a number of other tasks, including information extraction (McCarthy and Lehnert, 1995), question answering (Morton, 2000) and summarization (Steinberger et al., 2007). Developing a full coreference system, however, is a considerable engineering effort, which is why a large body of research concerned with feature engineering or learning methods (e.g. Culotta et al. 2007; Denis and Baldridge 2007) uses a simpler but non-realistic setting, using pre-identified mentions, and the use of coreference information in summarization or question answering techniques is not as widespread as it could be. We believe that the availability of a modular toolkit for coreference will significantly lower the entrance barrier for researchers interested in coreference resolution</context>
<context position="4164" citStr="Steinberger et al., 2007" startWordPosition="611" endWordPosition="614">pares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference system at the Johns Hopkins Summer Workshop 2007. It is based on code and ideas from the system of Ponzetto and Strube (2006), but also includes some ideas from GUITAR (Steinberger et al., 2007) and other coreference systems (Versley, 2006; Yang et al., 2006). 1 The goal of bringing together state-of-the-art approaches to different aspects of coreference resolution, including specialized preprocessing and syntax-based features has led to a design that is very modular. This design provides effective separation of concerns across several several tasks/roles, including engineering new features that exploit different sources of knowledge, designing improved or specialized preprocessing methods, and improving the way that coreference resolution is mapped to a machine learning problem. Pre</context>
</contexts>
<marker>Steinberger, Poesio, Kabadjov, Jezek, 2007</marker>
<rawString>Steinberger, J., Poesio, M., Kabadjov, M., and Jezek, K. (2007). Two uses of anaphora resolution in summarization. Information Processing and Management, 43:16631680. Special issue on Summarization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C D Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>Proc. NAACL</booktitle>
<pages>252259</pages>
<contexts>
<context position="5746" citStr="Toutanova et al., 2003" startWordPosition="842" endWordPosition="845">performing qualitative error analysis using integrated MMAX2 functionality (annotation 1 An open source version of BART is available from http://www.sfs.uni-tuebingen.de/ versley/BART/. diff, visual display). Preprocessing consists in marking up noun chunks and named entities, as well as additional information such as part-of-speech tags and merging these information into markables that are the starting point for the mentions used by the coreference resolution proper. Starting out with a chunking pipeline, which uses a classical combination of tagger and chunker, with the Stanford POS tagger (Toutanova et al., 2003), the YamCha chunker (Kudoh and Matsumoto, 2000) and the Stanford Named Entity Recognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Toutanova, K., Klein, D., Manning, C. D., and Singer, Y. (2003). Feature-rich part-of-speech tagging with a cyclic dependency network. In Proc. NAACL 2003, pages 252259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uryupina</author>
</authors>
<title>Coreference resolution with and without linguistic knowledge.</title>
<date>2006</date>
<booktitle>In Proc. LREC</booktitle>
<contexts>
<context position="3155" citStr="Uryupina (2006)" startWordPosition="455" endWordPosition="456">eference resolution are publicly available, such as GUITAR (Steinberger et al., 2007), which handles the full coreference task, and JAVARAP (Qiu et al., 2004), which only resolves pronouns. However, literature on coreference resolution, if providing a baseline, usually uses the algorithm and feature set of Soon et al. (2001) for this purpose. Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such </context>
</contexts>
<marker>Uryupina, 2006</marker>
<rawString>Uryupina, O. (2006). Coreference resolution with and without linguistic knowledge. In Proc. LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Versley</author>
</authors>
<title>A constraint-based approach to noun phrase coreference resolution in German newspaper text.</title>
<date>2006</date>
<booktitle>In Konferenz zur Verarbeitung Naturlicher Sprache (KONVENS</booktitle>
<contexts>
<context position="4209" citStr="Versley, 2006" startWordPosition="619" endWordPosition="620">et, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference system at the Johns Hopkins Summer Workshop 2007. It is based on code and ideas from the system of Ponzetto and Strube (2006), but also includes some ideas from GUITAR (Steinberger et al., 2007) and other coreference systems (Versley, 2006; Yang et al., 2006). 1 The goal of bringing together state-of-the-art approaches to different aspects of coreference resolution, including specialized preprocessing and syntax-based features has led to a design that is very modular. This design provides effective separation of concerns across several several tasks/roles, including engineering new features that exploit different sources of knowledge, designing improved or specialized preprocessing methods, and improving the way that coreference resolution is mapped to a machine learning problem. Preprocessing To store results of preprocessing </context>
</contexts>
<marker>Versley, 2006</marker>
<rawString>Versley, Y. (2006). A constraint-based approach to noun phrase coreference resolution in German newspaper text. In Konferenz zur Verarbeitung Naturlicher Sprache (KONVENS 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wellner</author>
<author>M Vilain</author>
</authors>
<title>Leveraging machine readable dictionaries in discriminative sequence models.</title>
<date>2006</date>
<booktitle>In Proc.</booktitle>
<contexts>
<context position="6451" citStr="Wellner and Vilain, 2006" startWordPosition="957" endWordPosition="960">ecognizer (Finkel et al., 2005), the desire to use richer syntactic representations led to the development of a parsing pipeline, which uses Charniak and Johnsons reranking parser (Charniak and Johnson, 2005) to assign POS tags and uses base NPs as chunk equivalents, while also providing syntactic trees that can be used by feature extractors. BART also supports using the Berkeley parser (Petrov et al., 2006), yielding an easy-to-use Java-only solution. To provide a better starting point for mention detection on the ACE corpora, the Carafe pipeline uses an ACE mention tagger provided by MITRE (Wellner and Vilain, 2006). A specialized merger then discards any base NP that was not detected to be an ACE mention. To perform coreference resolution proper, the mention-building module uses the markables created by the pipeline to create mention objects, which provide an interface more appropriate for coreference resolution than the MiniDiscourse markables. These objects are grouped into equivalence classes by the resolution process and a coreference layer is written into the document, which can be used for detailed error analysis. Feature Extraction BARTs default resolver goes through all mentions and looks for po</context>
</contexts>
<marker>Wellner, Vilain, 2006</marker>
<rawString>Wellner, B. and Vilain, M. (2006). Leveraging machine readable dictionaries in discriminative sequence models. In Proc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LREC</author>
</authors>
<date>2006</date>
<marker>LREC, 2006</marker>
<rawString>LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="8003" citStr="Witten and Frank, 2005" startWordPosition="1192" endWordPosition="1195">or and candidate are coreferent or not. Feature extractors are realized as separate classes, allowing for their independent develop10 \x0cFigure 2: Example system configuration ment. The set of feature extractors that the system uses is set in an XML description file, which allows for straightforward prototyping and experimentation with different feature sets. Learning BART provides a generic abstraction layer that maps application-internal representations to a suitable format for several machine learning toolkits: One module exposes the functionality of the the WEKA machine learning toolkit (Witten and Frank, 2005), while others interface to specialized state-of-the art learners. SVMLight (Joachims, 1999), in the SVMLight/TK (Moschitti, 2006) variant, allows to use tree-valued features. SVM Classification uses a Java Native Interface-based wrapper replacing SVMLight/TKs svm classify program to improve the classification speed. Also included is a Maximum entropy classifier that is based upon Robert Dodiers translation of Liu and Nocedals (1989) L-BFGS optimization code, with a function for programmatic feature combination.2 Training/Testing The training and testing phases slightly differ from each other.</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Witten, I. and Frank, E. (2005). Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>Kernel-based pronoun resolution with structured syntactic knowledge.</title>
<date>2006</date>
<booktitle>In Proc.</booktitle>
<contexts>
<context position="3372" citStr="Yang et al. 2006" startWordPosition="486" endWordPosition="489">reference resolution, if providing a baseline, usually uses the algorithm and feature set of Soon et al. (2001) for this purpose. Using the built-in maximum entropy learner with feature combination, BART reaches 65.8% F-measure on MUC6 and 62.9% F-measure on MUC7 using Soon et al.s features, outperforming JAVARAP on pronoun resolution, as well as the Soon et al. reimplementation of Uryupina (2006). Using a specialized tagger for ACE mentions and an extended feature set including syntactic features (e.g. using tree kernels to represent the syntactic relation between anaphor and antecedent, cf. Yang et al. 2006), as well as features based on knowledge extracted from Wikipedia (cf. Ponzetto and Smith, in preparation), BART reaches state-of-the-art results on ACE-2. Table 1 compares our results, obtained using this extended feature set, with results from Ng (2007). Pronoun resolution using the extended feature set gives 73.4% recall, coming near specialized pronoun resolution systems such as (Denis and Baldridge, 2007). 9 \x0cFigure 1: Results analysis in MMAX2 2 System Architecture The BART toolkit has been developed as a tool to explore the integration of knowledge-rich features into a coreference sy</context>
</contexts>
<marker>Yang, Su, Tan, 2006</marker>
<rawString>Yang, X., Su, J., and Tan, C. L. (2006). Kernel-based pronoun resolution with structured syntactic knowledge. In Proc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>