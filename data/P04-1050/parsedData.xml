<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<bodyText confidence="0.789879">
b&apos;Evaluating Centering-based metrics of coherence for text
structuring using a reliably annotated corpus
</bodyText>
<subsectionHeader confidence="0.356825">
Nikiforos Karamanis,
</subsectionHeader>
<author confidence="0.7391895">
Massimo Poesio,
Chris Mellish,
</author>
<affiliation confidence="0.83950025">
and Jon Oberlander
School of Informatics, University of Edinburgh, UK, {nikiforo,jon}@ed.ac.uk
Dept. of Computer Science, University of Essex, UK, poesio at essex dot ac dot uk
Dept. of Computing Science, University of Aberdeen, UK, cmellish@csd.abdn.ac.uk
</affiliation>
<sectionHeader confidence="0.974708" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999205846153846">
We use a reliably annotated corpus to compare
metrics of coherence based on Centering The-
ory with respect to their potential usefulness for
text structuring in natural language generation.
Previous corpus-based evaluations of the coher-
ence of text according to Centering did not com-
pare the coherence of the chosen text structure
with that of the possible alternatives. A corpus-
based methodology is presented which distin-
guishes between Centering-based metrics taking
these alternatives into account, and represents
therefore a more appropriate way to evaluate
Centering from a text structuring perspective.
</bodyText>
<sectionHeader confidence="0.983506" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.932089571428571">
Our research area is descriptive text generation
(ODonnell et al., 2001; Isard et al., 2003), i.e.
the generation of descriptions of objects, typi-
cally museum artefacts, depicted in a picture.
Text (1), from the gnome corpus (Poesio et al.,
2004), is an example of short human-authored
text from this genre:
</bodyText>
<listItem confidence="0.929081">
(1) (a) 144 is a torc. (b) Its present arrangement,
</listItem>
<bodyText confidence="0.996527385416667">
twisted into three rings, may be a modern al-
teration; (c) it should probably be a single ring,
worn around the neck. (d) The terminals are
in the form of goats heads.
According to Centering Theory (Grosz et al.,
1995; Walker et al., 1998a), an important fac-
tor for the felicity of (1) is its entity coherence:
the way centers (discourse entities), such as
the referent of the NPs 144 in clause (a) and
its in clause (b), are introduced and discussed
in subsequent clauses. It is often claimed in
current work on in natural language generation
that the constraints on felicitous text proposed
by the theory are useful to guide text struc-
turing, in combination with other factors (see
(Karamanis, 2003) for an overview). However,
how successful Centerings constraints are on
their own in generating a felicitous text struc-
ture is an open question, already raised by the
seminal papers of the theory (Brennan et al.,
1987; Grosz et al., 1995). In this work, we ex-
plored this question by developing an approach
to text structuring purely based on Centering,
in which the role of other factors is deliberately
ignored.
In accordance with recent work in the emerg-
ing field of text-to-text generation (Barzilay et
al., 2002; Lapata, 2003), we assume that the in-
put to text structuring is a set of clauses. The
output of text structuring is merely an order-
ing of these clauses, rather than the tree-like
structure of database facts often used in tradi-
tional deep generation (Reiter and Dale, 2000).
Our approach is further characterized by two
key insights. The first distinguishing feature is
that we assume a search-based approach to text
structuring (Mellish et al., 1998; Kibble and
Power, 2000; Karamanis and Manurung, 2002)
in which many candidate orderings of clauses
are evaluated according to scores assigned by
a given metric, and the best-scoring ordering
among the candidate solutions is chosen. The
second novel aspect is that our approach is
based on the position that the most straight-
forward way of using Centering for text struc-
turing is by defining a Centering-based metric
of coherence Karamanis (2003). Together, these
two assumptions lead to a view of text planning
in which the constraints of Centering act not
as filters, but as ranking factors, and the text
planner may be forced to choose a sub-optimal
solution.
However, Karamanis (2003) pointed out that
many metrics of coherence can be derived from
the claims of Centering, all of which could be
used for the type of text structuring assumed in
this paper. Hence, a general methodology for
identifying which of these metrics represent the
most promising candidates for text structuring
is required, so that at least some of them can
\x0cbe compared empirically. This is the second re-
search question that this paper addresses, build-
ing upon previous work on corpus-based evalu-
ations of Centering, and particularly the meth-
ods used by Poesio et al. (2004). We use the
gnome corpus (Poesio et al., 2004) as the do-
main of our experiments because it is reliably
annotated with features relevant to Centering
and contains the genre that we are mainly in-
terested in.
To sum up, in this paper we try to iden-
tify the most promising Centering-based metric
for text structuring, and to evaluate how useful
this metric is for that purpose, using corpus-
based methods instead of generally more expen-
sive psycholinguistic techniques. The paper is
structured as follows. After discussing how the
gnome corpus has been used in previous work
to evaluate the coherence of a text according to
Centering we discuss why such evaluations are
not sufficient for text structuring. We continue
by showing how Centering can be used to define
different metrics of coherence which might be
useful to drive a text planner. We then outline
a corpus-based methodology to choose among
these metrics, estimating how well they are ex-
pected to do when used by a text planner. We
conclude by discussing our experiments in which
this methodology is applied using a subset of the
gnome corpus.
2 Evaluating the coherence of a
corpus text according to Centering
In this section we briefly introduce Centering,
as well as the methodology developed in Poesio
et al. (2004) to evaluate the coherence of a text
according to Centering.
</bodyText>
<subsectionHeader confidence="0.856045">
2.1 Computing CF lists, CPs and CBs
</subsectionHeader>
<bodyText confidence="0.9856978">
According to Grosz et al. (1995), each utter-
ance in a discourse is assigned a list of for-
ward looking centers (CF list) each of which is
realised by at least one NP in the utterance.
The members of the CF list are ranked in or-
der of prominence, the first element being the
preferred center CP.
In this paper, we used what we considered to
be the most common definitions of the central
notions of Centering (its parameters). Poe-
sio et al. (2004) point out that there are many
definitions of parameters such as utterance,
ranking or realisation, and that the setting
of these parameters greatly affects the predic-
tions of the theory;1 however, they found viola-
tions of the Centering constraints with any way
of setting the parameters (for instance, at least
25% of utterances have no CB under any such
setting), so that the questions addressed by our
work arise for all other settings as well.
Following most mainstream work on Center-
ing for English, we assume that an utterance
corresponds to what is annotated as a finite unit
in the gnome corpus.2 The spans of text with
the indexes (a) to (d) in example (1) are exam-
ples. This definition of utterance is not optimal
from the point of view of minimizing Centering
violations (Poesio et al., 2004), but in this way
most utterances are the realization of a single
proposition; i.e., the impact of aggregation is
greatly reduced. Similarly, we use grammatical
function (gf) combined with linear order within
the unit (what Poesio et al. (2004) call gfthere-
lin) for CF ranking. In this configuration, the
CP is the referent of the first NP within the unit
that is annotated as a subject for its gf.3
Example (2) shows the relevant annotation
features of unit u210 which corresponds to
utterance (a) in example (1). According to
gftherelin, the CP of (a) is the referent of ne410
144.
(2) &lt;unit finite=finite-yes id=u210&amp;gt;
&lt;ne id=&amp;quot;ne410&amp;quot; gf=&amp;quot;subj&amp;quot;&amp;gt;144&lt;/ne&amp;gt;
is
&lt;ne id=&amp;quot;ne411&amp;quot; gf=&amp;quot;predicate&amp;quot;&amp;gt;
a torc&lt;/ne&amp;gt; &lt;/unit&amp;gt;.
The ranking of the CFs other than the
CP is defined according to the following pref-
erence on their gf (Brennan et al., 1987):
obj&amp;gt;iobj&amp;gt;other. CFs with the same gf are
ranked according to the linear order of the cor-
responding NPs in the utterance. The second
column of Table 1 shows how the utterances in
example (1) are automatically translated by the
scripts developed by Poesio et al. (2004) into a
</bodyText>
<page confidence="0.937038">
1
</page>
<bodyText confidence="0.9975626">
For example, one could equate utterance with sen-
tence (Strube and Hahn, 1999; Miltsakaki, 2002), use
indirect realisation for the computation of the CF list
(Grosz et al., 1995), rank the CFs according to their
information status (Strube and Hahn, 1999), etc.
</bodyText>
<page confidence="0.980989">
2
</page>
<bodyText confidence="0.99776">
Our definition includes titles which are not always
finite units, but excludes finite relative clauses, the sec-
ond element of coordinated VPs and clause complements
which are often taken as not having their own CF lists
in the literature.
</bodyText>
<page confidence="0.98916">
3
</page>
<bodyText confidence="0.498878">
Or as a post-copular subject in a there-clause.
</bodyText>
<listItem confidence="0.740993923076923">
\x0cCF list: cheapness
U {CP, other CFs} CB Transition CBn=CPn1
(a) {de374, de375} n.a. n.a. n.a.
(b) {de376, de374, de377} de374 retain +
(c) {de374, de379} de374 continue
(d) {de380, de381, de382} - nocb +
Table 1: CP, CFs other than CP, CB, nocb or standard (see Table 2) transition and violations of
cheapness (denoted with an asterisk) for each utterance (U) in example (1)
coherence: coherence:
CBn=CBn1 CBn 6=CBn1
or nocb in CFn1
salience: CBn=CPn continue smooth-shift
salience: CBn 6=CPn retain rough-shift
</listItem>
<tableCaption confidence="0.828064">
Table 2: coherence, salience and the table of standard transitions
</tableCaption>
<bodyText confidence="0.922397933333333">
sequence of CF lists, each decomposed into the
CP and the CFs other than the CP, according
to the chosen setting of the Centering param-
eters. Note that the CP of (a) is the center
de374 and that the same center is used as the
referent of the other NPs which are annotated
as coreferring with ne410.
Given two subsequent utterances Un1 and
Un, with CF lists CFn1 and CFn respectively,
the backward looking center of Un, CBn, is de-
fined as the highest ranked element of CFn1
which also appears in CFn (Centerings Con-
straint 3). For instance, the CB of (b) is de374.
The third column of Table 1 shows the CB for
each utterance in (1).4
</bodyText>
<subsectionHeader confidence="0.998223">
2.2 Computing transitions
</subsectionHeader>
<bodyText confidence="0.988912428571429">
As the fourth column of Table 1 shows, each
utterance, with the exception of (a), is also
marked with a transition from the previous one.
When CFn and CFn1 do not have any cen-
ters in common, we compute the nocb transi-
tion (Kibble and Power, 2000) (Poesio et als
null transition) for Un (e.g., utterance (d) in
</bodyText>
<tableCaption confidence="0.607702">
Table 1).5
</tableCaption>
<page confidence="0.985591">
4
</page>
<bodyText confidence="0.994304">
In accordance with Centering, no CB is computed
for (a), the first utterance in the sequence.
</bodyText>
<page confidence="0.974454">
5
</page>
<bodyText confidence="0.997369724137931">
In this study we do not take indirect realisation into
account, i.e., we ignore the bridging reference (anno-
tated in the corpus) between the referent of it de374
in (c) and the referent of the terminals de380 in (d),
by virtue of which de374 might be thought as being a
member of the CF list of (d). Poesio et al. (2004) showed
that hypothesizing indirect realization eliminates many
violations of entity continuity, the part of Constraint
1 that rules out nocb transitions. However, in this work
we are treating CF lists as an abstract representation
Following again the terminology in Kibble
and Power (2000), we call the requirement that
CBn be the same as CBn1 the principle of co-
herence and the requirement that CBn be the
same as CPn the principle of salience. Each
of these principles can be satisfied or violated
while their various combinations give rise to the
standard transitions of Centering shown in Ta-
ble 2; Poesio et als scripts compute these vio-
lations.6 We also make note of the preference
between these transitions, known as Centerings
Rule 2 (Brennan et al., 1987): continue is pre-
ferred to retain, which is preferred to smooth-
shift, which is preferred to rough-shift.
Finally, the scripts determine whether CBn
is the same as CPn1, known as the principle
of cheapness (Strube and Hahn, 1999). The
last column of Table 1 shows the violations of
cheapness (denoted with an asterisk) in (1).7
</bodyText>
<subsectionHeader confidence="0.641791">
2.3 Evaluating the coherence of a text
</subsectionHeader>
<bodyText confidence="0.9977508">
and text structuring
The statistics about transitions computed as
just discussed can be used to determine the de-
gree to which a text conforms with, or violates,
Centerings principles. Poesio et al. (2004)
found that nocbs account for more than 50%
of the atomic facts the algorithm has to structure, i.e.,
we are assuming that CFs are arguments of such facts;
including indirectly realized entities in CF lists would
violate this assumption.
</bodyText>
<page confidence="0.987458">
6
</page>
<bodyText confidence="0.867582666666667">
If the second utterance in a sequence U2 has a CB,
then it is taken to be either a continue or a retain,
although U1 is not classified as a nocb.
</bodyText>
<page confidence="0.996097">
7
</page>
<bodyText confidence="0.9937485">
As for the other two principles, no violation of
cheapness is computed for (a) or when Un is marked as
a nocb.
\x0cof the transitions in the gnome corpus in con-
figurations such as the one used in this pa-
per. More generally, a significant percentage of
nocbs (at least 20%) and other dispreferred
transitions was found with all parameter config-
urations tested by Poesio et al. (2004) and in-
deed by all previous corpus-based evaluations of
Centering such as Passoneau (1998), Di Eugenio
(1998), Strube and Hahn (1999) among others.
These results led Poesio et al. (2004) to the
conclusion that the entity coherence as formal-
ized in Centering should be supplemented with
an account of other coherence inducing factors
to explain what makes texts coherent.
These studies, however, do not investigate
the question that is most important from the
text structuring perspective adopted in this pa-
per: whether there would be alternative ways of
structuring the text that would result in fewer
violations of Centerings constraints (Kibble,
2001). Consider the nocb utterance (d) in (1).
Simply observing that this transition is dispre-
ferred ignores the fact that every other ordering
of utterances (b) to (d) would result in more
nocbs than those found in (1). Even a text-
structuring algorithm functioning solely on the
basis of the Centering constraints might there-
fore still choose the particular order in (1). In
other words, a metric of text coherence purely
based on Centering principlestrying to mini-
mize the number of nocbsmay be sufficient to
explain why this order of clauses was chosen,
at least in this particular genre, without need
to involve more complex explanations. In the
rest of the paper, we consider several such met-
rics, and use the texts in the gnome corpus to
choose among them. We return to the issue of
coherence (i.e., whether additional coherence-
inducing factors need to be stipulated in addi-
tion to those assumed in Centering) in the Dis-
cussion.
</bodyText>
<sectionHeader confidence="0.822305" genericHeader="introduction">
3 Centering-based metrics of
</sectionHeader>
<bodyText confidence="0.954020875">
coherence
As said previously, we assume a text structuring
system taking as input a set of utterances rep-
resented in terms of their CF lists. The system
orders these utterances by applying a bias in
favour of the best scoring ordering among the
candidate solutions for the preferred output.8
In this section, we discuss how the Centering
</bodyText>
<page confidence="0.984854">
8
</page>
<bodyText confidence="0.988450315789474">
Additional assumptions for choosing between the or-
derings that are assigned the best score are presented in
the next section.
concepts just described can be used to define
metrics of coherence which might be useful for
text structuring.
The simplest way to define a metric of coher-
ence using notions from Centering is to classify
each ordering of propositions according to the
number of nocbs it contains, and pick the or-
dering with the fewest nocbs. We call this met-
ric M.NOCB, following (Karamanis and Manu-
rung, 2002). Because of its simplicity, M.NOCB
serves as the baseline metric in our experiments.
We consider three more metrics. M.CHEAP
is biased in favour of the ordering with the
fewest violations of cheapness. M.KP sums
up the nocbs and the violations of cheapness,
coherence and salience, preferring the or-
dering with the lowest total cost (Kibble and
Power, 2000). Finally, M.BFP employs the
preferences between standard transitions as ex-
pressed by Rule 2. More specifically, M.BFP
selects the ordering with the highest number
of continues. If there exist several orderings
which have the most continues, the one which
has the most retains is favoured. The number
of smooth-shifts is used only to distinguish
between the orderings that score best for con-
tinues as well as for retains, etc.
In the next section, we present a general
methodology to compare these metrics, using
the actual ordering of clauses in real texts of
a corpus to identify the metric whose behav-
ior mimics more closely the way these actual
orderings were chosen. This methodology was
implemented in a program called the System for
Evaluating Entity Coherence (seec).
</bodyText>
<sectionHeader confidence="0.777543" genericHeader="method">
4 Exploring the space of possible
</sectionHeader>
<bodyText confidence="0.966333928571429">
orderings
In section 2, we discussed how an ordering of
utterances in a text like (1) can be translated
into a sequence of CF lists, which is the repre-
sentation that the Centering-based metrics op-
erate on. We use the term Basis for Comparison
(BfC) to indicate this sequence of CF lists. In
this section, we discuss how the BfC is used in
our search-oriented evaluation methodology to
calculate a performance measure for each metric
and compare them with each other. In the next
section, we will see how our corpus was used
to identify the most promising Centering-based
metric for a text classifier.
</bodyText>
<subsectionHeader confidence="0.996839">
4.1 Computing the classification rate
</subsectionHeader>
<bodyText confidence="0.996766352941177">
The performance measure we employ is called
the classification rate of a metric M on a cer-
\x0ctain BfC B. The classification rate estimates
the ability of M to produce B as the output of
text structuring according to a specific genera-
tion scenario.
The first step of seec is to search through
the space of possible orderings defined by the
permutations of the CF lists that B consists of,
and to divide the explored search space into sets
of orderings that score better, equal, or worse
than B according to M.
Then, the classification rate is defined accord-
ing to the following generation scenario. We
assume that an ordering has higher chances of
being selected as the output of text structuring
the better it scores for M. This is turn means
that the fewer the members of the set of better
scoring orderings, the better the chances of B
to be the chosen output.
Moreover, we assume that additional factors
play a role in the selection of one of the order-
ings that score the same for M. On average, B
is expected to sit in the middle of the set of
equally scoring orderings with respect to these
additional factors. Hence, half of the orderings
with the same score will have better chances
than B to be selected by M.
The classification rate of a metric M on
B expresses the expected percentage of order-
ings with a higher probability of being gener-
ated than B according to the scores assigned
by M and the additional biases assumed by the
generation scenario as follows:
</bodyText>
<figure confidence="0.5095995">
(3) Classification rate:
(M, B) = Better(M) + Equal(M)
</figure>
<page confidence="0.735835">
2
</page>
<bodyText confidence="0.987826">
Better(M) stands for the percentage of order-
ings that score better than B according to M,
whilst Equal(M) is the percentage of order-
ings that score equal to B according to M. If
(Mx, B) is the classification rate of Mx on B,
and (My, B) is the classification rate of My on
B, My is a more suitable candidate than Mx
for generating B if (My, B) is smaller than
(Mx, B).
</bodyText>
<subsectionHeader confidence="0.934347">
4.2 Generalising across many BfCs
</subsectionHeader>
<bodyText confidence="0.9506072">
In order for the experimental results to be re-
liable and generalisable, Mx and My should be
compared on more than one BfC from a corpus
C. In our standard analysis, the BfCs B1, ..., Bm
from C are treated as the random factor in a
repeated measures design since each BfC con-
tributes a score for each metric. Then, the clas-
sification rates for Mx and My on the BfCs are
compared with each other and significance is
tested using the Sign Test. After calculating the
number of BfCs that return a lower classifica-
tion rate for Mx than for My and vice versa, the
Sign Test reports whether the difference in the
number of BfCs is significant, that is, whether
there are significantly more BfCs with a lower
classification rate for Mx than the BfCs with a
lower classification rate for My (or vice versa).9
Finally, we summarise the performance of M
on m BfCs from C in terms of the average clas-
sification rate Y :
</bodyText>
<listItem confidence="0.919545">
(4) Average classification rate:
</listItem>
<equation confidence="0.9646345">
Y (M, C) = (M,B1)+...+(M,Bm)
m
</equation>
<bodyText confidence="0.975001529411765">
5 Using the gnome corpus for a
search-based comparison of
metrics
We will now discuss how the methodology
discussed above was used to compare the
Centering-based metrics discussed in Section
3, using the original ordering of texts in the
gnome corpus to compute the average classi-
fication rate of each metric.
The gnome corpus contains texts from differ-
ent genres, not all of which are of interest to us.
In order to restrict the scope of the experiment
to the text-type most relevant to our study, we
selected 20 museum labels, i.e., short texts
that describe a concrete artefact, which served
as the input to seec together with the metrics
in section 3.10
</bodyText>
<subsectionHeader confidence="0.999205">
5.1 Permutation and search strategy
</subsectionHeader>
<bodyText confidence="0.994386555555556">
In specifying the performance of the metrics we
made use of a simple permutation heuristic ex-
ploiting a piece of domain-specific communica-
tion knowledge (Kittredge et al., 1991). Like
Dimitromanolaki and Androutsopoulos (2003),
we noticed that utterances like (a) in exam-
ple (1), should always appear at the beginning
of a felicitous museum label. Hence, we re-
stricted the orderings considered by the seec
</bodyText>
<page confidence="0.976433">
9
</page>
<bodyText confidence="0.9909294">
The Sign Test was chosen over its parametric al-
ternatives to test significance because it does not carry
specific assumptions about population distributions and
variance. It is also more appropriate for small samples
like the one used in this study.
</bodyText>
<page confidence="0.993819">
10
</page>
<bodyText confidence="0.935898">
Note that example (1) is characteristic of the genre,
not the length, of the texts in our subcorpus. The num-
</bodyText>
<table confidence="0.8836">
ber of CF lists that the BfCs consist of ranges from 4 to
16 (average cardinality: 8.35 CF lists).
\x0cPair M.NOCB p Winner
lower greater ties
M.NOCB vs M.CHEAP 18 2 0 0.000 M.NOCB
M.NOCB vs M.KP 16 2 2 0.001 M.NOCB
M.NOCB vs M.BFP 12 3 5 0.018 M.NOCB
N 20
</table>
<tableCaption confidence="0.999321">
Table 3: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP in gnome
</tableCaption>
<bodyText confidence="0.988897769230769">
to those in which the first CF list of B, CF1,
appears in first position.11
For very short texts like (1), which give rise to
a small BfC, the search space of possible order-
ings can be enumerated exhaustively. However,
when B consists of many more CF lists, it is im-
practical to explore the search space in this way.
Elsewhere we show that even in these cases it
is possible to estimate (M, B) reliably for the
whole population of orderings using a large ran-
dom sample. In the experiments reported here,
we had to resort to random sampling only once,
for a BfC with 16 CF lists.
</bodyText>
<subsectionHeader confidence="0.993348">
5.2 Comparing M.NOCB with other
</subsectionHeader>
<bodyText confidence="0.98306896">
metrics
The experimental results of the comparisons of
the metrics from section 3, computed using the
methodology in section 4, are reported in Ta-
ble 3.
In this table, the baseline metric M.NOCB is
compared with each of M.CHEAP, M.KP and
M.BFP. The first column of the Table identifies
the comparison in question, e.g. M.NOCB ver-
sus M.CHEAP. The exact number of BfCs for
which the classification rate of M.NOCB is lower
than its competitor for each comparison is re-
ported in the next column of the Table. For ex-
ample, M.NOCB has a lower classification rate
than M.CHEAP for 18 (out of 20) BfCs from
the gnome corpus. M.CHEAP only achieves a
lower classification rate for 2 BfCs, and there
are no ties, i.e. cases where the classification
rate of the two metrics is the same. The p value
returned by the Sign Test for the difference in
the number of BfCs, rounded to the third deci-
mal place, is reported in the fifth column of the
Table. The last column of the Table 3 shows
M.NOCB as the winner of the comparison
with M.CHEAP since it has a lower classifica-
</bodyText>
<page confidence="0.99851">
11
</page>
<bodyText confidence="0.999379666666666">
Thus, we assume that when the set of CF lists serves
as the input to text structuring, CF1 will be identified
as the initial CF list of the ordering to be generated
using annotation features such as the unit type which
distinguishes (a) from the other utterances in (1).
tion rate than its competitor for significantly
more BfCs in the corpus.12
Overall, the Table shows that M.NOCB does
significantly better than the other three metrics
which employ additional Centering concepts.
This result means that there exist proportion-
ally fewer orderings with a higher probability of
being selected than the BfC when M.NOCB is
used to guide the hypothetical text structuring
algorithm instead of the other metrics.
Hence, M.NOCB is the most suitable among
the investigated metrics for structuring the CF
lists in gnome. This in turn indicates that sim-
ply avoiding nocb transitions is more relevant
to text structuring than the combinations of the
other Centering notions that the more compli-
cated metrics make use of. (However, these no-
tions might still be appropriate for other tasks,
such as anaphora resolution.)
</bodyText>
<sectionHeader confidence="0.503908" genericHeader="method">
6 Discussion: the performance of
M.NOCB
</sectionHeader>
<bodyText confidence="0.9994205">
We already saw that Poesio et al. (2004) found
that the majority of the recorded transitions in
the configuration of Centering used in this study
are nocbs. However, we also explained in sec-
tion 2.3 that what really matters when trying
to determine whether a text might have been
generated only paying attention to Centering
constraints is the extent to which it would be
possible to improve upon the ordering chosen
in that text, given the information that the text
structuring algorithm had to convey. The av-
erage classification rate of M.NOCB is an esti-
</bodyText>
<page confidence="0.994352">
12
</page>
<bodyText confidence="0.9871633">
No winner is reported for a comparison when the p
value returned by the Sign Test is not significant (ns),
i.e. greater than 0.05. Note also that despite conduct-
ing more than one pairwise comparison simultaneously
we refrain from further adjusting the overall threshold
of significance (e.g. according to the Bonferroni method,
typically used for multiple planned comparisons that em-
ploy parametric statistics) since it is assumed that choos-
ing a conservative statistic such as the Sign Test already
provides substantial protection against the possibility of
</bodyText>
<table confidence="0.883438428571428">
a type I error.
\x0cPair M.NOCB p Winner
lower greater ties
M.NOCB vs M.CHEAP 110 12 0 0.000 M.NOCB
M.NOCB vs M.KP 103 16 3 0.000 M.NOCB
M.NOCB vs M.BFP 41 31 49 0.121 ns
N 122
</table>
<tableCaption confidence="0.997763">
Table 4: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP using the novel methodology
</tableCaption>
<bodyText confidence="0.991693714285715">
in MPIRO
mate of exactly this variable, indicating whether
M.NOCB is likely to arrive at the BfC during
text structuring.
The average classification rate Y for
M.NOCB on the subcorpus of gnome studied
here, for the parameter configuration of Cen-
tering we have assumed, is 19.95%. This means
that on average the BfC is close to the top 20%
of alternative orderings when these orderings
are ranked according to their probability of
being selected as the output of the algorithm.
On the one hand, this result shows that al-
though the ordering of CF lists in the BfC
might not completely minimise the number of
observed nocb transitions, the BfC tends to
be in greater agreement with the preference to
avoid nocbs than most of the alternative or-
derings. In this sense, it appears that the BfC
optimises with respect to the number of poten-
tial nocbs to a certain extent. On the other
hand, this result indicates that there are quite
a few orderings which would appear more likely
to be selected than the BfC.
We believe this finding can be interpreted in
two ways. One possibility is that M.NOCB
needs to be supplemented by other features in
order to explain why the original text was struc-
tured this way. This is the conclusion arrived at
by Poesio et al. (2004) and those text structur-
ing practitioners who use notions derived from
Centering in combination with other coherence
constraints in the definitions of their metrics.
There is also a second possibility, however: we
might want to reconsider the assumption that
human text planners are trying to ensure that
each utterance in a text is locally coherent.
They might do all of their planning just on the
basis of Centering constraints, at least in this
genre perhaps because of resource limitations
and simply accept a certain degree of incoher-
ence. Further research on this issue will require
psycholinguistic methods; our analysis never-
theless sheds more light on two previously un-
addressed questions in the corpus-based evalu-
ation of Centering a) which of the Centering
notions are most relevant to the text structur-
ing task, and b) to which extent Centering on
its own can be useful for this purpose.
</bodyText>
<sectionHeader confidence="0.974082" genericHeader="conclusions">
7 Further results
</sectionHeader>
<bodyText confidence="0.99613111627907">
In related work, we applied the methodology
discussed here to a larger set of existing data
(122 BfCs) derived from the MPIRO system
and ordered by a domain expert (Dimitro-
manolaki and Androutsopoulos, 2003). As Ta-
ble 4 shows, the results from MPIRO verify the
ones reported here, especially with respect to
M.KP and M.CHEAP which are overwhelm-
ingly beaten by the baseline in the new do-
main as well. Also note that since M.BFP fails
to overtake M.NOCB in MPIRO, the baseline
can be considered the most promising solution
among the ones investigated in both domains
by applying Occams logical principle.
We also tried to account for some additional
constraints on coherence, namely local rhetor-
ical relations, based on some of the assump-
tions in Knott et al. (2001), and what Kara-
manis (2003) calls the PageFocus which cor-
responds to the main entity described in a text,
in our example de374. These results, reported
in (Karamanis, 2003), indicate that these con-
straints conflict with Centering as formulated in
this paper, by increasing - instead of reducing
- the classification rate of the metrics. Hence,
it remains unclear to us how to improve upon
M.NOCB.
In our future work, we would like to experi-
ment with more metrics. Moreover, although we
consider the parameter configuration of Center-
ing used here a plausible choice, we intend to ap-
ply our methodology to study different instan-
tiations of the Centering parameters, e.g. by
investigating whether indirect realisation re-
duces the classification rate for M.NOCB com-
pared to direct realisation, etc.
\x0cAcknowledgements
Special thanks to James Soutter for writing the
program which translates the output produced by
gnomes scripts into a format appropriate for seec.
The first author was able to engage in this research
thanks to a scholarship from the Greek State Schol-
arships Foundation (IKY).
</bodyText>
<sectionHeader confidence="0.986714" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998209575757576">
Regina Barzilay, Noemie Elhadad, and Kath-
leen McKeown. 2002. Inferring strategies
for sentence ordering in multidocument news
summarization. Journal of Artificial Intelli-
gence Research, 17:3555.
Susan E. Brennan, Marilyn A. Fried-
man [Walker], and Carl J. Pollard. 1987. A
centering approach to pronouns. In Proceed-
ings of ACL 1987, pages 155162, Stanford,
California.
Barbara Di Eugenio. 1998. Centering in Italian.
In Walker et al. (Walker et al., 1998b), pages
115137.
Aggeliki Dimitromanolaki and Ion Androut-
sopoulos. 2003. Learning to order facts for
discourse planning in natural language gen-
eration. In Proceedings of the 9th European
Workshop on Natural Language Generation,
Budapest, Hungary.
Barbara J. Grosz, Aravind K. Joshi, and Scott
Weinstein. 1995. Centering: A framework
for modeling the local coherence of discourse.
Computational Linguistics, 21(2):203225.
Amy Isard, Jon Oberlander, Ion Androutsopou-
los, and Colin Matheson. 2003. Speaking the
users languages. IEEE Intelligent Systems
Magazine, 18(1):4045.
Nikiforos Karamanis and Hisar Maruli Manu-
rung. 2002. Stochastic text structuring us-
ing the principle of continuity. In Proceedings
of INLG 2002, pages 8188, Harriman, NY,
USA, July.
Nikiforos Karamanis. 2003. Entity Coherence
for Descriptive Text Structuring. Ph.D. the-
sis, Division of Informatics, University of Ed-
inburgh.
Rodger Kibble and Richard Power. 2000. An
integrated framework for text planning and
pronominalisation. In Proceedings of INLG
2000, pages 7784, Israel.
Rodger Kibble. 2001. A reformulation of Rule
2 of Centering Theory. Computational Lin-
guistics, 27(4):579587.
Richard Kittredge, Tanya Korelsky, and Owen
Rambow. 1991. On the need for domain com-
munication knowledge. Computational Intel-
ligence, 7:305314.
Alistair Knott, Jon Oberlander, Mick
ODonnell, and Chris Mellish. 2001. Beyond
elaboration: The interaction of relations
and focus in coherent text. In T. Sanders,
J. Schilperoord, and W. Spooren, edi-
tors, Text Representation: Linguistic and
Psycholinguistic Aspects, chapter 7, pages
181196. John Benjamins.
Mirella Lapata. 2003. Probabilistic text struc-
turing: Experiments with sentence ordering.
In Proceedings of ACL 2003, Saporo, Japan,
July.
Chris Mellish, Alistair Knott, Jon Oberlander,
and Mick ODonnell. 1998. Experiments us-
ing stochastic search for text planning. In
Proceedings of the 9th International Work-
shop on NLG, pages 98107, Niagara-on-the-
Lake, Ontario, Canada.
Eleni Miltsakaki. 2002. Towards an aposyn-
thesis of topic continuity and intrasenten-
tial anaphora. Computational Linguistics,
28(3):319355.
Mick ODonnell, Chris Mellish, Jon Oberlan-
der, and Alistair Knott. 2001. ILEX: An ar-
chitecture for a dynamic hypertext genera-
tion system. Natural Language Engineering,
7(3):225250.
Rebecca J. Passoneau. 1998. Interaction of dis-
course structure with explicitness of discourse
anaphoric phrases. In Walker et al. (Walker
et al., 1998b), pages 327358.
Massimo Poesio, Rosemary Stevenson, Barbara
Di Eugenio, and Janet Hitzeman. 2004. Cen-
tering: a parametric theory and its instantia-
tions. Computational Linguistics, 30(3).
Ehud Reiter and Robert Dale. 2000. Building
Natural Language Generation Systems. Cam-
bridge.
Michael Strube and Udo Hahn. 1999. Func-
tional centering: Grounding referential coher-
ence in information structure. Computational
Linguistics, 25(3):309344.
Marilyn A. Walker, Aravind K. Joshi, and
Ellen F. Prince. 1998a. Centering in nat-
urally occuring discourse: An overview. In
Walker et al. (Walker et al., 1998b), pages
130.
Marilyn A. Walker, Aravind K. Joshi, and
Ellen F. Prince, editors. 1998b. Centering
Theory in Discourse. Clarendon Press, Ox-
ford.
\x0c&apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.883378666666667">b&apos;Evaluating Centering-based metrics of coherence for text structuring using a reliably annotated corpus Nikiforos Karamanis,</title>
<author confidence="0.994183333333333">Massimo Poesio</author>
<author confidence="0.994183333333333">Chris Mellish</author>
<author confidence="0.994183333333333">Jon Oberlander</author>
<affiliation confidence="0.610149666666667">School of Informatics, University of Edinburgh, UK, {nikiforo,jon}@ed.ac.uk Dept. of Computer Science, University of Essex, UK, poesio at essex dot ac dot uk Dept. of Computing Science, University of Aberdeen, UK, cmellish@csd.abdn.ac.uk</affiliation>
<abstract confidence="0.993124394775039">We use a reliably annotated corpus to compare metrics of coherence based on Centering Theory with respect to their potential usefulness for text structuring in natural language generation. Previous corpus-based evaluations of the coherence of text according to Centering did not compare the coherence of the chosen text structure with that of the possible alternatives. A corpusbased methodology is presented which distinguishes between Centering-based metrics taking these alternatives into account, and represents therefore a more appropriate way to evaluate Centering from a text structuring perspective. 1 Motivation Our research area is descriptive text generation (ODonnell et al., 2001; Isard et al., 2003), i.e. the generation of descriptions of objects, typically museum artefacts, depicted in a picture. Text (1), from the gnome corpus (Poesio et al., 2004), is an example of short human-authored text from this genre: (1) (a) 144 is a torc. (b) Its present arrangement, twisted into three rings, may be a modern alteration; (c) it should probably be a single ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the NPs 144 in clause (a) and its in clause (b), are introduced and discussed in subsequent clauses. It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory (Brennan et al., 1987; Grosz et al., 1995). In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of coherence Karamanis (2003). Together, these two assumptions lead to a view of text planning in which the constraints of Centering act not as filters, but as ranking factors, and the text planner may be forced to choose a sub-optimal solution. However, Karamanis (2003) pointed out that many metrics of coherence can be derived from the claims of Centering, all of which could be used for the type of text structuring assumed in this paper. Hence, a general methodology for identifying which of these metrics represent the most promising candidates for text structuring is required, so that at least some of them can \x0cbe compared empirically. This is the second research question that this paper addresses, building upon previous work on corpus-based evaluations of Centering, and particularly the methods used by Poesio et al. (2004). We use the gnome corpus (Poesio et al., 2004) as the domain of our experiments because it is reliably annotated with features relevant to Centering and contains the genre that we are mainly interested in. To sum up, in this paper we try to identify the most promising Centering-based metric for text structuring, and to evaluate how useful this metric is for that purpose, using corpusbased methods instead of generally more expensive psycholinguistic techniques. The paper is structured as follows. After discussing how the gnome corpus has been used in previous work to evaluate the coherence of a text according to Centering we discuss why such evaluations are not sufficient for text structuring. We continue by showing how Centering can be used to define different metrics of coherence which might be useful to drive a text planner. We then outline a corpus-based methodology to choose among these metrics, estimating how well they are expected to do when used by a text planner. We conclude by discussing our experiments in which this methodology is applied using a subset of the gnome corpus. 2 Evaluating the coherence of a corpus text according to Centering In this section we briefly introduce Centering, as well as the methodology developed in Poesio et al. (2004) to evaluate the coherence of a text according to Centering. 2.1 Computing CF lists, CPs and CBs According to Grosz et al. (1995), each utterance in a discourse is assigned a list of forward looking centers (CF list) each of which is realised by at least one NP in the utterance. The members of the CF list are ranked in order of prominence, the first element being the preferred center CP. In this paper, we used what we considered to be the most common definitions of the central notions of Centering (its parameters). Poesio et al. (2004) point out that there are many definitions of parameters such as utterance, ranking or realisation, and that the setting of these parameters greatly affects the predictions of the theory;1 however, they found violations of the Centering constraints with any way of setting the parameters (for instance, at least 25% of utterances have no CB under any such setting), so that the questions addressed by our work arise for all other settings as well. Following most mainstream work on Centering for English, we assume that an utterance corresponds to what is annotated as a finite unit in the gnome corpus.2 The spans of text with the indexes (a) to (d) in example (1) are examples. This definition of utterance is not optimal from the point of view of minimizing Centering violations (Poesio et al., 2004), but in this way most utterances are the realization of a single proposition; i.e., the impact of aggregation is greatly reduced. Similarly, we use grammatical function (gf) combined with linear order within the unit (what Poesio et al. (2004) call gftherelin) for CF ranking. In this configuration, the CP is the referent of the first NP within the unit that is annotated as a subject for its gf.3 Example (2) shows the relevant annotation features of unit u210 which corresponds to utterance (a) in example (1). According to gftherelin, the CP of (a) is the referent of ne410 144. (2) &lt;unit finite=finite-yes id=u210&amp;gt; &lt;ne id=&amp;quot;ne410&amp;quot; gf=&amp;quot;subj&amp;quot;&amp;gt;144&lt;/ne&amp;gt; is &lt;ne id=&amp;quot;ne411&amp;quot; gf=&amp;quot;predicate&amp;quot;&amp;gt; a torc&lt;/ne&amp;gt; &lt;/unit&amp;gt;. The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al., 1987): obj&amp;gt;iobj&amp;gt;other. CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance. The second column of Table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by Poesio et al. (2004) into a 1 For example, one could equate utterance with sentence (Strube and Hahn, 1999; Miltsakaki, 2002), use indirect realisation for the computation of the CF list (Grosz et al., 1995), rank the CFs according to their information status (Strube and Hahn, 1999), etc. 2 Our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated VPs and clause complements which are often taken as not having their own CF lists in the literature. 3 Or as a post-copular subject in a there-clause. \x0cCF list: cheapness U {CP, other CFs} CB Transition CBn=CPn1 (a) {de374, de375} n.a. n.a. n.a. (b) {de376, de374, de377} de374 retain + (c) {de374, de379} de374 continue (d) {de380, de381, de382} nocb + Table 1: CP, CFs other than CP, CB, nocb or standard (see Table 2) transition and violations of cheapness (denoted with an asterisk) for each utterance (U) in example (1) coherence: coherence: CBn=CBn1 CBn 6=CBn1 or nocb in CFn1 salience: CBn=CPn continue smooth-shift salience: CBn 6=CPn retain rough-shift Table 2: coherence, salience and the table of standard transitions sequence of CF lists, each decomposed into the CP and the CFs other than the CP, according to the chosen setting of the Centering parameters. Note that the CP of (a) is the center de374 and that the same center is used as the referent of the other NPs which are annotated as coreferring with ne410. Given two subsequent utterances Un1 and Un, with CF lists CFn1 and CFn respectively, the backward looking center of Un, CBn, is defined as the highest ranked element of CFn1 which also appears in CFn (Centerings Constraint 3). For instance, the CB of (b) is de374. The third column of Table 1 shows the CB for each utterance in (1).4 2.2 Computing transitions As the fourth column of Table 1 shows, each utterance, with the exception of (a), is also marked with a transition from the previous one. When CFn and CFn1 do not have any centers in common, we compute the nocb transition (Kibble and Power, 2000) (Poesio et als null transition) for Un (e.g., utterance (d) in Table 1).5 4 In accordance with Centering, no CB is computed for (a), the first utterance in the sequence. 5 In this study we do not take indirect realisation into account, i.e., we ignore the bridging reference (annotated in the corpus) between the referent of it de374 in (c) and the referent of the terminals de380 in (d), by virtue of which de374 might be thought as being a member of the CF list of (d). Poesio et al. (2004) showed that hypothesizing indirect realization eliminates many violations of entity continuity, the part of Constraint 1 that rules out nocb transitions. However, in this work we are treating CF lists as an abstract representation Following again the terminology in Kibble and Power (2000), we call the requirement that CBn be the same as CBn1 the principle of coherence and the requirement that CBn be the same as CPn the principle of salience. Each of these principles can be satisfied or violated while their various combinations give rise to the standard transitions of Centering shown in Table 2; Poesio et als scripts compute these violations.6 We also make note of the preference between these transitions, known as Centerings Rule 2 (Brennan et al., 1987): continue is preferred to retain, which is preferred to smoothshift, which is preferred to rough-shift. Finally, the scripts determine whether CBn is the same as CPn1, known as the principle of cheapness (Strube and Hahn, 1999). The last column of Table 1 shows the violations of cheapness (denoted with an asterisk) in (1).7 2.3 Evaluating the coherence of a text and text structuring The statistics about transitions computed as just discussed can be used to determine the degree to which a text conforms with, or violates, Centerings principles. Poesio et al. (2004) found that nocbs account for more than 50% of the atomic facts the algorithm has to structure, i.e., we are assuming that CFs are arguments of such facts; including indirectly realized entities in CF lists would violate this assumption. 6 If the second utterance in a sequence U2 has a CB, then it is taken to be either a continue or a retain, although U1 is not classified as a nocb. 7 As for the other two principles, no violation of cheapness is computed for (a) or when Un is marked as a nocb. \x0cof the transitions in the gnome corpus in configurations such as the one used in this paper. More generally, a significant percentage of nocbs (at least 20%) and other dispreferred transitions was found with all parameter configurations tested by Poesio et al. (2004) and indeed by all previous corpus-based evaluations of Centering such as Passoneau (1998), Di Eugenio (1998), Strube and Hahn (1999) among others. These results led Poesio et al. (2004) to the conclusion that the entity coherence as formalized in Centering should be supplemented with an account of other coherence inducing factors to explain what makes texts coherent. These studies, however, do not investigate the question that is most important from the text structuring perspective adopted in this paper: whether there would be alternative ways of structuring the text that would result in fewer violations of Centerings constraints (Kibble, 2001). Consider the nocb utterance (d) in (1). Simply observing that this transition is dispreferred ignores the fact that every other ordering of utterances (b) to (d) would result in more nocbs than those found in (1). Even a textstructuring algorithm functioning solely on the basis of the Centering constraints might therefore still choose the particular order in (1). In other words, a metric of text coherence purely based on Centering principlestrying to minimize the number of nocbsmay be sufficient to explain why this order of clauses was chosen, at least in this particular genre, without need to involve more complex explanations. In the rest of the paper, we consider several such metrics, and use the texts in the gnome corpus to choose among them. We return to the issue of coherence (i.e., whether additional coherenceinducing factors need to be stipulated in addition to those assumed in Centering) in the Discussion. 3 Centering-based metrics of coherence As said previously, we assume a text structuring system taking as input a set of utterances represented in terms of their CF lists. The system orders these utterances by applying a bias in favour of the best scoring ordering among the candidate solutions for the preferred output.8 In this section, we discuss how the Centering 8 Additional assumptions for choosing between the orderings that are assigned the best score are presented in the next section. concepts just described can be used to define metrics of coherence which might be useful for text structuring. The simplest way to define a metric of coherence using notions from Centering is to classify each ordering of propositions according to the number of nocbs it contains, and pick the ordering with the fewest nocbs. We call this metric M.NOCB, following (Karamanis and Manurung, 2002). Because of its simplicity, M.NOCB serves as the baseline metric in our experiments. We consider three more metrics. M.CHEAP is biased in favour of the ordering with the fewest violations of cheapness. M.KP sums up the nocbs and the violations of cheapness, coherence and salience, preferring the ordering with the lowest total cost (Kibble and Power, 2000). Finally, M.BFP employs the preferences between standard transitions as expressed by Rule 2. More specifically, M.BFP selects the ordering with the highest number of continues. If there exist several orderings which have the most continues, the one which has the most retains is favoured. The number of smooth-shifts is used only to distinguish between the orderings that score best for continues as well as for retains, etc. In the next section, we present a general methodology to compare these metrics, using the actual ordering of clauses in real texts of a corpus to identify the metric whose behavior mimics more closely the way these actual orderings were chosen. This methodology was implemented in a program called the System for Evaluating Entity Coherence (seec). 4 Exploring the space of possible orderings In section 2, we discussed how an ordering of utterances in a text like (1) can be translated into a sequence of CF lists, which is the representation that the Centering-based metrics operate on. We use the term Basis for Comparison (BfC) to indicate this sequence of CF lists. In this section, we discuss how the BfC is used in our search-oriented evaluation methodology to calculate a performance measure for each metric and compare them with each other. In the next section, we will see how our corpus was used to identify the most promising Centering-based metric for a text classifier. 4.1 Computing the classification rate The performance measure we employ is called the classification rate of a metric M on a cer- \x0ctain BfC B. The classification rate estimates the ability of M to produce B as the output of text structuring according to a specific generation scenario. The first step of seec is to search through the space of possible orderings defined by the permutations of the CF lists that B consists of, and to divide the explored search space into sets of orderings that score better, equal, or worse than B according to M. Then, the classification rate is defined according to the following generation scenario. We assume that an ordering has higher chances of being selected as the output of text structuring the better it scores for M. This is turn means that the fewer the members of the set of better scoring orderings, the better the chances of B to be the chosen output. Moreover, we assume that additional factors play a role in the selection of one of the orderings that score the same for M. On average, B is expected to sit in the middle of the set of equally scoring orderings with respect to these additional factors. Hence, half of the orderings with the same score will have better chances than B to be selected by M. The classification rate of a metric M on B expresses the expected percentage of orderings with a higher probability of being generated than B according to the scores assigned by M and the additional biases assumed by the generation scenario as follows: (3) Classification rate: (M, B) = Better(M) + Equal(M) 2 Better(M) stands for the percentage of orderings that score better than B according to M, whilst Equal(M) is the percentage of orderings that score equal to B according to M. If (Mx, B) is the classification rate of Mx on B, and (My, B) is the classification rate of My on B, My is a more suitable candidate than Mx for generating B if (My, B) is smaller than (Mx, B). 4.2 Generalising across many BfCs In order for the experimental results to be reliable and generalisable, Mx and My should be compared on more than one BfC from a corpus C. In our standard analysis, the BfCs B1, ..., Bm from C are treated as the random factor in a repeated measures design since each BfC contributes a score for each metric. Then, the classification rates for Mx and My on the BfCs are compared with each other and significance is tested using the Sign Test. After calculating the number of BfCs that return a lower classification rate for Mx than for My and vice versa, the Sign Test reports whether the difference in the number of BfCs is significant, that is, whether there are significantly more BfCs with a lower classification rate for Mx than the BfCs with a lower classification rate for My (or vice versa).9 Finally, we summarise the performance of M on m BfCs from C in terms of the average classification rate Y : (4) Average classification rate: Y (M, C) = (M,B1)+...+(M,Bm) m 5 Using the gnome corpus for a search-based comparison of metrics We will now discuss how the methodology discussed above was used to compare the Centering-based metrics discussed in Section 3, using the original ordering of texts in the gnome corpus to compute the average classification rate of each metric. The gnome corpus contains texts from different genres, not all of which are of interest to us. In order to restrict the scope of the experiment to the text-type most relevant to our study, we selected 20 museum labels, i.e., short texts that describe a concrete artefact, which served as the input to seec together with the metrics in section 3.10 5.1 Permutation and search strategy In specifying the performance of the metrics we made use of a simple permutation heuristic exploiting a piece of domain-specific communication knowledge (Kittredge et al., 1991). Like Dimitromanolaki and Androutsopoulos (2003), we noticed that utterances like (a) in example (1), should always appear at the beginning of a felicitous museum label. Hence, we restricted the orderings considered by the seec 9 The Sign Test was chosen over its parametric alternatives to test significance because it does not carry specific assumptions about population distributions and variance. It is also more appropriate for small samples like the one used in this study. 10 Note that example (1) is characteristic of the genre, not the length, of the texts in our subcorpus. The number of CF lists that the BfCs consist of ranges from 4 to 16 (average cardinality: 8.35 CF lists). \x0cPair M.NOCB p Winner lower greater ties M.NOCB vs M.CHEAP 18 2 0 0.000 M.NOCB M.NOCB vs M.KP 16 2 2 0.001 M.NOCB M.NOCB vs M.BFP 12 3 5 0.018 M.NOCB N 20 Table 3: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP in gnome to those in which the first CF list of B, CF1, appears in first position.11 For very short texts like (1), which give rise to a small BfC, the search space of possible orderings can be enumerated exhaustively. However, when B consists of many more CF lists, it is impractical to explore the search space in this way. Elsewhere we show that even in these cases it is possible to estimate (M, B) reliably for the whole population of orderings using a large random sample. In the experiments reported here, we had to resort to random sampling only once, for a BfC with 16 CF lists. 5.2 Comparing M.NOCB with other metrics The experimental results of the comparisons of the metrics from section 3, computed using the methodology in section 4, are reported in Table 3. In this table, the baseline metric M.NOCB is compared with each of M.CHEAP, M.KP and M.BFP. The first column of the Table identifies the comparison in question, e.g. M.NOCB versus M.CHEAP. The exact number of BfCs for which the classification rate of M.NOCB is lower than its competitor for each comparison is reported in the next column of the Table. For example, M.NOCB has a lower classification rate than M.CHEAP for 18 (out of 20) BfCs from the gnome corpus. M.CHEAP only achieves a lower classification rate for 2 BfCs, and there are no ties, i.e. cases where the classification rate of the two metrics is the same. The p value returned by the Sign Test for the difference in the number of BfCs, rounded to the third decimal place, is reported in the fifth column of the Table. The last column of the Table 3 shows M.NOCB as the winner of the comparison with M.CHEAP since it has a lower classifica- 11 Thus, we assume that when the set of CF lists serves as the input to text structuring, CF1 will be identified as the initial CF list of the ordering to be generated using annotation features such as the unit type which distinguishes (a) from the other utterances in (1). tion rate than its competitor for significantly more BfCs in the corpus.12 Overall, the Table shows that M.NOCB does significantly better than the other three metrics which employ additional Centering concepts. This result means that there exist proportionally fewer orderings with a higher probability of being selected than the BfC when M.NOCB is used to guide the hypothetical text structuring algorithm instead of the other metrics. Hence, M.NOCB is the most suitable among the investigated metrics for structuring the CF lists in gnome. This in turn indicates that simply avoiding nocb transitions is more relevant to text structuring than the combinations of the other Centering notions that the more complicated metrics make use of. (However, these notions might still be appropriate for other tasks, such as anaphora resolution.) 6 Discussion: the performance of M.NOCB We already saw that Poesio et al. (2004) found that the majority of the recorded transitions in the configuration of Centering used in this study are nocbs. However, we also explained in section 2.3 that what really matters when trying to determine whether a text might have been generated only paying attention to Centering constraints is the extent to which it would be possible to improve upon the ordering chosen in that text, given the information that the text structuring algorithm had to convey. The average classification rate of M.NOCB is an esti- 12 No winner is reported for a comparison when the p value returned by the Sign Test is not significant (ns), i.e. greater than 0.05. Note also that despite conducting more than one pairwise comparison simultaneously we refrain from further adjusting the overall threshold of significance (e.g. according to the Bonferroni method, typically used for multiple planned comparisons that employ parametric statistics) since it is assumed that choosing a conservative statistic such as the Sign Test already provides substantial protection against the possibility of a type I error. \x0cPair M.NOCB p Winner lower greater ties M.NOCB vs M.CHEAP 110 12 0 0.000 M.NOCB M.NOCB vs M.KP 103 16 3 0.000 M.NOCB M.NOCB vs M.BFP 41 31 49 0.121 ns N 122 Table 4: Comparing M.NOCB with M.CHEAP, M.KP and M.BFP using the novel methodology in MPIRO mate of exactly this variable, indicating whether M.NOCB is likely to arrive at the BfC during text structuring. The average classification rate Y for M.NOCB on the subcorpus of gnome studied here, for the parameter configuration of Centering we have assumed, is 19.95%. This means that on average the BfC is close to the top 20% of alternative orderings when these orderings are ranked according to their probability of being selected as the output of the algorithm. On the one hand, this result shows that although the ordering of CF lists in the BfC might not completely minimise the number of observed nocb transitions, the BfC tends to be in greater agreement with the preference to avoid nocbs than most of the alternative orderings. In this sense, it appears that the BfC optimises with respect to the number of potential nocbs to a certain extent. On the other hand, this result indicates that there are quite a few orderings which would appear more likely to be selected than the BfC. We believe this finding can be interpreted in two ways. One possibility is that M.NOCB needs to be supplemented by other features in order to explain why the original text was structured this way. This is the conclusion arrived at by Poesio et al. (2004) and those text structuring practitioners who use notions derived from Centering in combination with other coherence constraints in the definitions of their metrics. There is also a second possibility, however: we might want to reconsider the assumption that human text planners are trying to ensure that each utterance in a text is locally coherent. They might do all of their planning just on the basis of Centering constraints, at least in this genre perhaps because of resource limitations and simply accept a certain degree of incoherence. Further research on this issue will require psycholinguistic methods; our analysis nevertheless sheds more light on two previously unaddressed questions in the corpus-based evaluation of Centering a) which of the Centering notions are most relevant to the text structuring task, and b) to which extent Centering on its own can be useful for this purpose. 7 Further results In related work, we applied the methodology discussed here to a larger set of existing data (122 BfCs) derived from the MPIRO system and ordered by a domain expert (Dimitromanolaki and Androutsopoulos, 2003). As Table 4 shows, the results from MPIRO verify the ones reported here, especially with respect to M.KP and M.CHEAP which are overwhelmingly beaten by the baseline in the new domain as well. Also note that since M.BFP fails to overtake M.NOCB in MPIRO, the baseline can be considered the most promising solution among the ones investigated in both domains by applying Occams logical principle. We also tried to account for some additional constraints on coherence, namely local rhetorical relations, based on some of the assumptions in Knott et al. (2001), and what Karamanis (2003) calls the PageFocus which corresponds to the main entity described in a text, in our example de374. These results, reported in (Karamanis, 2003), indicate that these constraints conflict with Centering as formulated in this paper, by increasing instead of reducing the classification rate of the metrics. Hence, it remains unclear to us how to improve upon M.NOCB. In our future work, we would like to experiment with more metrics. Moreover, although we consider the parameter configuration of Centering used here a plausible choice, we intend to apply our methodology to study different instantiations of the Centering parameters, e.g. by investigating whether indirect realisation reduces the classification rate for M.NOCB compared to direct realisation, etc. \x0cAcknowledgements Special thanks to James Soutter for writing the program which translates the output produced by gnomes scripts into a format appropriate for seec. The first author was able to engage in this research thanks to a scholarship from the Greek State Scholarships Foundation (IKY).</abstract>
<note confidence="0.725846105263158">References Regina Barzilay, Noemie Elhadad, and Kathleen McKeown. 2002. Inferring strategies for sentence ordering in multidocument news summarization. Journal of Artificial Intelligence Research, 17:3555. Susan E. Brennan, Marilyn A. Friedman [Walker], and Carl J. Pollard. 1987. A centering approach to pronouns. In Proceedings of ACL 1987, pages 155162, Stanford, California. Barbara Di Eugenio. 1998. Centering in Italian. In Walker et al. (Walker et al., 1998b), pages 115137. Aggeliki Dimitromanolaki and Ion Androutsopoulos. 2003. Learning to order facts for discourse planning in natural language generation. In Proceedings of the 9th European Workshop on Natural Language Generation,</note>
<address confidence="0.986648">Budapest, Hungary.</address>
<author confidence="0.836971">Centering A framework</author>
<note confidence="0.671133615384615">for modeling the local coherence of discourse. Computational Linguistics, 21(2):203225. Amy Isard, Jon Oberlander, Ion Androutsopoulos, and Colin Matheson. 2003. Speaking the users languages. IEEE Intelligent Systems Magazine, 18(1):4045. Nikiforos Karamanis and Hisar Maruli Manurung. 2002. Stochastic text structuring using the principle of continuity. In Proceedings of INLG 2002, pages 8188, Harriman, NY, USA, July. Nikiforos Karamanis. 2003. Entity Coherence for Descriptive Text Structuring. Ph.D. thesis, Division of Informatics, University of Edinburgh. Rodger Kibble and Richard Power. 2000. An integrated framework for text planning and pronominalisation. In Proceedings of INLG 2000, pages 7784, Israel. Rodger Kibble. 2001. A reformulation of Rule 2 of Centering Theory. Computational Linguistics, 27(4):579587. Richard Kittredge, Tanya Korelsky, and Owen Rambow. 1991. On the need for domain communication knowledge. Computational Intelligence, 7:305314. Alistair Knott, Jon Oberlander, Mick ODonnell, and Chris Mellish. 2001. Beyond elaboration: The interaction of relations and focus in coherent text. In T. Sanders, J. Schilperoord, and W. Spooren, editors, Text Representation: Linguistic and Psycholinguistic Aspects, chapter 7, pages 181196. John Benjamins. Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL 2003, Saporo, Japan, July. Chris Mellish, Alistair Knott, Jon Oberlander, and Mick ODonnell. 1998. Experiments using stochastic search for text planning. In Proceedings of the 9th International Workshop on NLG, pages 98107, Niagara-on-the- Lake, Ontario, Canada. Eleni Miltsakaki. 2002. Towards an aposynthesis of topic continuity and intrasentential anaphora. Computational Linguistics, 28(3):319355. Mick ODonnell, Chris Mellish, Jon Oberlander, and Alistair Knott. 2001. ILEX: An architecture for a dynamic hypertext generation system. Natural Language Engineering, 7(3):225250. Rebecca J. Passoneau. 1998. Interaction of discourse structure with explicitness of discourse anaphoric phrases. In Walker et al. (Walker et al., 1998b), pages 327358. Massimo Poesio, Rosemary Stevenson, Barbara Di Eugenio, and Janet Hitzeman. 2004. Centering: a parametric theory and its instantiations. Computational Linguistics, 30(3). Ehud Reiter and Robert Dale. 2000. Building Natural Language Generation Systems. Cambridge. Michael Strube and Udo Hahn. 1999. Functional centering: Grounding referential coherence in information structure. Computational Linguistics, 25(3):309344. Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince. 1998a. Centering in naturally occuring discourse: An overview. In Walker et al. (Walker et al., 1998b), pages 130. Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors. 1998b. Centering Theory in Discourse. Clarendon Press, Oxford. \x0c&apos;</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument news summarization.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>17--3555</pages>
<contexts>
<context position="2620" citStr="Barzilay et al., 2002" startWordPosition="411" endWordPosition="414">the theory are useful to guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory (Brennan et al., 1987; Grosz et al., 1995). In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a g</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen McKeown. 2002. Inferring strategies for sentence ordering in multidocument news summarization. Journal of Artificial Intelligence Research, 17:3555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Marilyn A Friedman</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of ACL 1987,</booktitle>
<pages>155162</pages>
<location>Stanford, California.</location>
<marker>Brennan, Friedman, 1987</marker>
<rawString>Susan E. Brennan, Marilyn A. Friedman [Walker], and Carl J. Pollard. 1987. A centering approach to pronouns. In Proceedings of ACL 1987, pages 155162, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
</authors>
<date>1998</date>
<note>Centering in Italian.</note>
<marker>Di Eugenio, 1998</marker>
<rawString>Barbara Di Eugenio. 1998. Centering in Italian.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In Walker</author>
</authors>
<date>1998</date>
<pages>115137</pages>
<marker>Walker, 1998</marker>
<rawString>In Walker et al. (Walker et al., 1998b), pages 115137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aggeliki Dimitromanolaki</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Learning to order facts for discourse planning in natural language generation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 9th European Workshop on Natural Language Generation,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="20799" citStr="Dimitromanolaki and Androutsopoulos (2003)" startWordPosition="3533" endWordPosition="3536">sification rate of each metric. The gnome corpus contains texts from different genres, not all of which are of interest to us. In order to restrict the scope of the experiment to the text-type most relevant to our study, we selected 20 museum labels, i.e., short texts that describe a concrete artefact, which served as the input to seec together with the metrics in section 3.10 5.1 Permutation and search strategy In specifying the performance of the metrics we made use of a simple permutation heuristic exploiting a piece of domain-specific communication knowledge (Kittredge et al., 1991). Like Dimitromanolaki and Androutsopoulos (2003), we noticed that utterances like (a) in example (1), should always appear at the beginning of a felicitous museum label. Hence, we restricted the orderings considered by the seec 9 The Sign Test was chosen over its parametric alternatives to test significance because it does not carry specific assumptions about population distributions and variance. It is also more appropriate for small samples like the one used in this study. 10 Note that example (1) is characteristic of the genre, not the length, of the texts in our subcorpus. The number of CF lists that the BfCs consist of ranges from 4 to</context>
<context position="28243" citStr="Dimitromanolaki and Androutsopoulos, 2003" startWordPosition="4820" endWordPosition="4824">imitations and simply accept a certain degree of incoherence. Further research on this issue will require psycholinguistic methods; our analysis nevertheless sheds more light on two previously unaddressed questions in the corpus-based evaluation of Centering a) which of the Centering notions are most relevant to the text structuring task, and b) to which extent Centering on its own can be useful for this purpose. 7 Further results In related work, we applied the methodology discussed here to a larger set of existing data (122 BfCs) derived from the MPIRO system and ordered by a domain expert (Dimitromanolaki and Androutsopoulos, 2003). As Table 4 shows, the results from MPIRO verify the ones reported here, especially with respect to M.KP and M.CHEAP which are overwhelmingly beaten by the baseline in the new domain as well. Also note that since M.BFP fails to overtake M.NOCB in MPIRO, the baseline can be considered the most promising solution among the ones investigated in both domains by applying Occams logical principle. We also tried to account for some additional constraints on coherence, namely local rhetorical relations, based on some of the assumptions in Knott et al. (2001), and what Karamanis (2003) calls the PageF</context>
</contexts>
<marker>Dimitromanolaki, Androutsopoulos, 2003</marker>
<rawString>Aggeliki Dimitromanolaki and Ion Androutsopoulos. 2003. Learning to order facts for discourse planning in natural language generation. In Proceedings of the 9th European Workshop on Natural Language Generation, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1620" citStr="Grosz et al., 1995" startWordPosition="243" endWordPosition="246">ext structuring perspective. 1 Motivation Our research area is descriptive text generation (ODonnell et al., 2001; Isard et al., 2003), i.e. the generation of descriptions of objects, typically museum artefacts, depicted in a picture. Text (1), from the gnome corpus (Poesio et al., 2004), is an example of short human-authored text from this genre: (1) (a) 144 is a torc. (b) Its present arrangement, twisted into three rings, may be a modern alteration; (c) it should probably be a single ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the NPs 144 in clause (a) and its in clause (b), are introduced and discussed in subsequent clauses. It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text s</context>
<context position="5733" citStr="Grosz et al. (1995)" startWordPosition="931" endWordPosition="934">rence which might be useful to drive a text planner. We then outline a corpus-based methodology to choose among these metrics, estimating how well they are expected to do when used by a text planner. We conclude by discussing our experiments in which this methodology is applied using a subset of the gnome corpus. 2 Evaluating the coherence of a corpus text according to Centering In this section we briefly introduce Centering, as well as the methodology developed in Poesio et al. (2004) to evaluate the coherence of a text according to Centering. 2.1 Computing CF lists, CPs and CBs According to Grosz et al. (1995), each utterance in a discourse is assigned a list of forward looking centers (CF list) each of which is realised by at least one NP in the utterance. The members of the CF list are ranked in order of prominence, the first element being the preferred center CP. In this paper, we used what we considered to be the most common definitions of the central notions of Centering (its parameters). Poesio et al. (2004) point out that there are many definitions of parameters such as utterance, ranking or realisation, and that the setting of these parameters greatly affects the predictions of the theory;1</context>
<context position="8238" citStr="Grosz et al., 1995" startWordPosition="1363" endWordPosition="1366">&amp;quot; gf=&amp;quot;predicate&amp;quot;&amp;gt; a torc&lt;/ne&amp;gt; &lt;/unit&amp;gt;. The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al., 1987): obj&amp;gt;iobj&amp;gt;other. CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance. The second column of Table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by Poesio et al. (2004) into a 1 For example, one could equate utterance with sentence (Strube and Hahn, 1999; Miltsakaki, 2002), use indirect realisation for the computation of the CF list (Grosz et al., 1995), rank the CFs according to their information status (Strube and Hahn, 1999), etc. 2 Our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated VPs and clause complements which are often taken as not having their own CF lists in the literature. 3 Or as a post-copular subject in a there-clause. \x0cCF list: cheapness U {CP, other CFs} CB Transition CBn=CPn1 (a) {de374, de375} n.a. n.a. n.a. (b) {de376, de374, de377} de374 retain + (c) {de374, de379} de374 continue (d) {de380, de381, de382} - nocb + Table 1: CP, CFs o</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Isard</author>
<author>Jon Oberlander</author>
<author>Ion Androutsopoulos</author>
<author>Colin Matheson</author>
</authors>
<title>Speaking the users languages.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems Magazine,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="1136" citStr="Isard et al., 2003" startWordPosition="158" endWordPosition="161">ith respect to their potential usefulness for text structuring in natural language generation. Previous corpus-based evaluations of the coherence of text according to Centering did not compare the coherence of the chosen text structure with that of the possible alternatives. A corpusbased methodology is presented which distinguishes between Centering-based metrics taking these alternatives into account, and represents therefore a more appropriate way to evaluate Centering from a text structuring perspective. 1 Motivation Our research area is descriptive text generation (ODonnell et al., 2001; Isard et al., 2003), i.e. the generation of descriptions of objects, typically museum artefacts, depicted in a picture. Text (1), from the gnome corpus (Poesio et al., 2004), is an example of short human-authored text from this genre: (1) (a) 144 is a torc. (b) Its present arrangement, twisted into three rings, may be a modern alteration; (c) it should probably be a single ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (disco</context>
</contexts>
<marker>Isard, Oberlander, Androutsopoulos, Matheson, 2003</marker>
<rawString>Amy Isard, Jon Oberlander, Ion Androutsopoulos, and Colin Matheson. 2003. Speaking the users languages. IEEE Intelligent Systems Magazine, 18(1):4045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
<author>Hisar Maruli Manurung</author>
</authors>
<title>Stochastic text structuring using the principle of continuity.</title>
<date>2002</date>
<booktitle>In Proceedings of INLG 2002,</booktitle>
<pages>8188</pages>
<location>Harriman, NY, USA,</location>
<contexts>
<context position="3125" citStr="Karamanis and Manurung, 2002" startWordPosition="494" endWordPosition="497">deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of coherence Karamanis (2003). Together, these two assumptions lead to a view of text planning in which the constraints of Centering act not as filters, but as ranking factors, and the text planner may be forced to choose a sub-optimal s</context>
<context position="15168" citStr="Karamanis and Manurung, 2002" startWordPosition="2549" endWordPosition="2553">ring among the candidate solutions for the preferred output.8 In this section, we discuss how the Centering 8 Additional assumptions for choosing between the orderings that are assigned the best score are presented in the next section. concepts just described can be used to define metrics of coherence which might be useful for text structuring. The simplest way to define a metric of coherence using notions from Centering is to classify each ordering of propositions according to the number of nocbs it contains, and pick the ordering with the fewest nocbs. We call this metric M.NOCB, following (Karamanis and Manurung, 2002). Because of its simplicity, M.NOCB serves as the baseline metric in our experiments. We consider three more metrics. M.CHEAP is biased in favour of the ordering with the fewest violations of cheapness. M.KP sums up the nocbs and the violations of cheapness, coherence and salience, preferring the ordering with the lowest total cost (Kibble and Power, 2000). Finally, M.BFP employs the preferences between standard transitions as expressed by Rule 2. More specifically, M.BFP selects the ordering with the highest number of continues. If there exist several orderings which have the most continues, </context>
</contexts>
<marker>Karamanis, Manurung, 2002</marker>
<rawString>Nikiforos Karamanis and Hisar Maruli Manurung. 2002. Stochastic text structuring using the principle of continuity. In Proceedings of INLG 2002, pages 8188, Harriman, NY, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
</authors>
<title>Entity Coherence for Descriptive Text Structuring.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Division of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="2104" citStr="Karamanis, 2003" startWordPosition="327" endWordPosition="328">ngle ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the NPs 144 in clause (a) and its in clause (b), are introduced and discussed in subsequent clauses. It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory (Brennan et al., 1987; Grosz et al., 1995). In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. T</context>
<context position="3517" citStr="Karamanis (2003)" startWordPosition="559" endWordPosition="560">proach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of coherence Karamanis (2003). Together, these two assumptions lead to a view of text planning in which the constraints of Centering act not as filters, but as ranking factors, and the text planner may be forced to choose a sub-optimal solution. However, Karamanis (2003) pointed out that many metrics of coherence can be derived from the claims of Centering, all of which could be used for the type of text structuring assumed in this paper. Hence, a general methodology for identifying which of these metrics represent the most promising candidates for text structuring is required, so that at least some of them can \x0cbe com</context>
<context position="28827" citStr="Karamanis (2003)" startWordPosition="4923" endWordPosition="4925">olaki and Androutsopoulos, 2003). As Table 4 shows, the results from MPIRO verify the ones reported here, especially with respect to M.KP and M.CHEAP which are overwhelmingly beaten by the baseline in the new domain as well. Also note that since M.BFP fails to overtake M.NOCB in MPIRO, the baseline can be considered the most promising solution among the ones investigated in both domains by applying Occams logical principle. We also tried to account for some additional constraints on coherence, namely local rhetorical relations, based on some of the assumptions in Knott et al. (2001), and what Karamanis (2003) calls the PageFocus which corresponds to the main entity described in a text, in our example de374. These results, reported in (Karamanis, 2003), indicate that these constraints conflict with Centering as formulated in this paper, by increasing - instead of reducing - the classification rate of the metrics. Hence, it remains unclear to us how to improve upon M.NOCB. In our future work, we would like to experiment with more metrics. Moreover, although we consider the parameter configuration of Centering used here a plausible choice, we intend to apply our methodology to study different instant</context>
</contexts>
<marker>Karamanis, 2003</marker>
<rawString>Nikiforos Karamanis. 2003. Entity Coherence for Descriptive Text Structuring. Ph.D. thesis, Division of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodger Kibble</author>
<author>Richard Power</author>
</authors>
<title>An integrated framework for text planning and pronominalisation.</title>
<date>2000</date>
<booktitle>In Proceedings of INLG</booktitle>
<pages>7784</pages>
<contexts>
<context position="3094" citStr="Kibble and Power, 2000" startWordPosition="490" endWordPosition="493">ole of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of coherence Karamanis (2003). Together, these two assumptions lead to a view of text planning in which the constraints of Centering act not as filters, but as ranking factors, and the text planner may be f</context>
<context position="10100" citStr="Kibble and Power, 2000" startWordPosition="1687" endWordPosition="1690">ring with ne410. Given two subsequent utterances Un1 and Un, with CF lists CFn1 and CFn respectively, the backward looking center of Un, CBn, is defined as the highest ranked element of CFn1 which also appears in CFn (Centerings Constraint 3). For instance, the CB of (b) is de374. The third column of Table 1 shows the CB for each utterance in (1).4 2.2 Computing transitions As the fourth column of Table 1 shows, each utterance, with the exception of (a), is also marked with a transition from the previous one. When CFn and CFn1 do not have any centers in common, we compute the nocb transition (Kibble and Power, 2000) (Poesio et als null transition) for Un (e.g., utterance (d) in Table 1).5 4 In accordance with Centering, no CB is computed for (a), the first utterance in the sequence. 5 In this study we do not take indirect realisation into account, i.e., we ignore the bridging reference (annotated in the corpus) between the referent of it de374 in (c) and the referent of the terminals de380 in (d), by virtue of which de374 might be thought as being a member of the CF list of (d). Poesio et al. (2004) showed that hypothesizing indirect realization eliminates many violations of entity continuity, the part o</context>
<context position="15526" citStr="Kibble and Power, 2000" startWordPosition="2608" endWordPosition="2611">to define a metric of coherence using notions from Centering is to classify each ordering of propositions according to the number of nocbs it contains, and pick the ordering with the fewest nocbs. We call this metric M.NOCB, following (Karamanis and Manurung, 2002). Because of its simplicity, M.NOCB serves as the baseline metric in our experiments. We consider three more metrics. M.CHEAP is biased in favour of the ordering with the fewest violations of cheapness. M.KP sums up the nocbs and the violations of cheapness, coherence and salience, preferring the ordering with the lowest total cost (Kibble and Power, 2000). Finally, M.BFP employs the preferences between standard transitions as expressed by Rule 2. More specifically, M.BFP selects the ordering with the highest number of continues. If there exist several orderings which have the most continues, the one which has the most retains is favoured. The number of smooth-shifts is used only to distinguish between the orderings that score best for continues as well as for retains, etc. In the next section, we present a general methodology to compare these metrics, using the actual ordering of clauses in real texts of a corpus to identify the metric whose b</context>
</contexts>
<marker>Kibble, Power, 2000</marker>
<rawString>Rodger Kibble and Richard Power. 2000. An integrated framework for text planning and pronominalisation. In Proceedings of INLG 2000, pages 7784, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodger Kibble</author>
</authors>
<title>A reformulation of Rule 2 of Centering Theory.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="13350" citStr="Kibble, 2001" startWordPosition="2244" endWordPosition="2245"> evaluations of Centering such as Passoneau (1998), Di Eugenio (1998), Strube and Hahn (1999) among others. These results led Poesio et al. (2004) to the conclusion that the entity coherence as formalized in Centering should be supplemented with an account of other coherence inducing factors to explain what makes texts coherent. These studies, however, do not investigate the question that is most important from the text structuring perspective adopted in this paper: whether there would be alternative ways of structuring the text that would result in fewer violations of Centerings constraints (Kibble, 2001). Consider the nocb utterance (d) in (1). Simply observing that this transition is dispreferred ignores the fact that every other ordering of utterances (b) to (d) would result in more nocbs than those found in (1). Even a textstructuring algorithm functioning solely on the basis of the Centering constraints might therefore still choose the particular order in (1). In other words, a metric of text coherence purely based on Centering principlestrying to minimize the number of nocbsmay be sufficient to explain why this order of clauses was chosen, at least in this particular genre, without need </context>
</contexts>
<marker>Kibble, 2001</marker>
<rawString>Rodger Kibble. 2001. A reformulation of Rule 2 of Centering Theory. Computational Linguistics, 27(4):579587.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Kittredge</author>
<author>Tanya Korelsky</author>
<author>Owen Rambow</author>
</authors>
<title>On the need for domain communication knowledge.</title>
<date>1991</date>
<journal>Computational Intelligence,</journal>
<pages>7--305314</pages>
<contexts>
<context position="20750" citStr="Kittredge et al., 1991" startWordPosition="3528" endWordPosition="3531">us to compute the average classification rate of each metric. The gnome corpus contains texts from different genres, not all of which are of interest to us. In order to restrict the scope of the experiment to the text-type most relevant to our study, we selected 20 museum labels, i.e., short texts that describe a concrete artefact, which served as the input to seec together with the metrics in section 3.10 5.1 Permutation and search strategy In specifying the performance of the metrics we made use of a simple permutation heuristic exploiting a piece of domain-specific communication knowledge (Kittredge et al., 1991). Like Dimitromanolaki and Androutsopoulos (2003), we noticed that utterances like (a) in example (1), should always appear at the beginning of a felicitous museum label. Hence, we restricted the orderings considered by the seec 9 The Sign Test was chosen over its parametric alternatives to test significance because it does not carry specific assumptions about population distributions and variance. It is also more appropriate for small samples like the one used in this study. 10 Note that example (1) is characteristic of the genre, not the length, of the texts in our subcorpus. The number of C</context>
</contexts>
<marker>Kittredge, Korelsky, Rambow, 1991</marker>
<rawString>Richard Kittredge, Tanya Korelsky, and Owen Rambow. 1991. On the need for domain communication knowledge. Computational Intelligence, 7:305314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
<author>Jon Oberlander</author>
<author>Mick ODonnell</author>
<author>Chris Mellish</author>
</authors>
<title>Beyond elaboration: The interaction of relations and focus in coherent text. In</title>
<date>2001</date>
<booktitle>Text Representation: Linguistic and Psycholinguistic Aspects, chapter 7,</booktitle>
<pages>181196</pages>
<editor>T. Sanders, J. Schilperoord, and W. Spooren, editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="28800" citStr="Knott et al. (2001)" startWordPosition="4917" endWordPosition="4920">by a domain expert (Dimitromanolaki and Androutsopoulos, 2003). As Table 4 shows, the results from MPIRO verify the ones reported here, especially with respect to M.KP and M.CHEAP which are overwhelmingly beaten by the baseline in the new domain as well. Also note that since M.BFP fails to overtake M.NOCB in MPIRO, the baseline can be considered the most promising solution among the ones investigated in both domains by applying Occams logical principle. We also tried to account for some additional constraints on coherence, namely local rhetorical relations, based on some of the assumptions in Knott et al. (2001), and what Karamanis (2003) calls the PageFocus which corresponds to the main entity described in a text, in our example de374. These results, reported in (Karamanis, 2003), indicate that these constraints conflict with Centering as formulated in this paper, by increasing - instead of reducing - the classification rate of the metrics. Hence, it remains unclear to us how to improve upon M.NOCB. In our future work, we would like to experiment with more metrics. Moreover, although we consider the parameter configuration of Centering used here a plausible choice, we intend to apply our methodology</context>
</contexts>
<marker>Knott, Oberlander, ODonnell, Mellish, 2001</marker>
<rawString>Alistair Knott, Jon Oberlander, Mick ODonnell, and Chris Mellish. 2001. Beyond elaboration: The interaction of relations and focus in coherent text. In T. Sanders, J. Schilperoord, and W. Spooren, editors, Text Representation: Linguistic and Psycholinguistic Aspects, chapter 7, pages 181196. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<contexts>
<context position="2635" citStr="Lapata, 2003" startWordPosition="415" endWordPosition="416">o guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open question, already raised by the seminal papers of the theory (Brennan et al., 1987; Grosz et al., 1995). In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, an</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>In Proceedings of ACL 2003,</booktitle>
<location>Saporo, Japan,</location>
<marker></marker>
<rawString>In Proceedings of ACL 2003, Saporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Mellish</author>
<author>Alistair Knott</author>
<author>Jon Oberlander</author>
<author>Mick ODonnell</author>
</authors>
<title>Experiments using stochastic search for text planning.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on NLG,</booktitle>
<pages>98107</pages>
<location>Niagara-on-theLake, Ontario, Canada.</location>
<contexts>
<context position="3070" citStr="Mellish et al., 1998" startWordPosition="486" endWordPosition="489">tering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of coherence Karamanis (2003). Together, these two assumptions lead to a view of text planning in which the constraints of Centering act not as filters, but as ranking factors, and t</context>
</contexts>
<marker>Mellish, Knott, Oberlander, ODonnell, 1998</marker>
<rawString>Chris Mellish, Alistair Knott, Jon Oberlander, and Mick ODonnell. 1998. Experiments using stochastic search for text planning. In Proceedings of the 9th International Workshop on NLG, pages 98107, Niagara-on-theLake, Ontario, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
</authors>
<title>Towards an aposynthesis of topic continuity and intrasentential anaphora.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="8156" citStr="Miltsakaki, 2002" startWordPosition="1351" endWordPosition="1352">it finite=finite-yes id=u210&amp;gt; &lt;ne id=&amp;quot;ne410&amp;quot; gf=&amp;quot;subj&amp;quot;&amp;gt;144&lt;/ne&amp;gt; is &lt;ne id=&amp;quot;ne411&amp;quot; gf=&amp;quot;predicate&amp;quot;&amp;gt; a torc&lt;/ne&amp;gt; &lt;/unit&amp;gt;. The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al., 1987): obj&amp;gt;iobj&amp;gt;other. CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance. The second column of Table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by Poesio et al. (2004) into a 1 For example, one could equate utterance with sentence (Strube and Hahn, 1999; Miltsakaki, 2002), use indirect realisation for the computation of the CF list (Grosz et al., 1995), rank the CFs according to their information status (Strube and Hahn, 1999), etc. 2 Our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated VPs and clause complements which are often taken as not having their own CF lists in the literature. 3 Or as a post-copular subject in a there-clause. \x0cCF list: cheapness U {CP, other CFs} CB Transition CBn=CPn1 (a) {de374, de375} n.a. n.a. n.a. (b) {de376, de374, de377} de374 retain + (c) {</context>
</contexts>
<marker>Miltsakaki, 2002</marker>
<rawString>Eleni Miltsakaki. 2002. Towards an aposynthesis of topic continuity and intrasentential anaphora. Computational Linguistics, 28(3):319355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mick ODonnell</author>
<author>Chris Mellish</author>
<author>Jon Oberlander</author>
<author>Alistair Knott</author>
</authors>
<title>ILEX: An architecture for a dynamic hypertext generation system.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="1115" citStr="ODonnell et al., 2001" startWordPosition="154" endWordPosition="157">d on Centering Theory with respect to their potential usefulness for text structuring in natural language generation. Previous corpus-based evaluations of the coherence of text according to Centering did not compare the coherence of the chosen text structure with that of the possible alternatives. A corpusbased methodology is presented which distinguishes between Centering-based metrics taking these alternatives into account, and represents therefore a more appropriate way to evaluate Centering from a text structuring perspective. 1 Motivation Our research area is descriptive text generation (ODonnell et al., 2001; Isard et al., 2003), i.e. the generation of descriptions of objects, typically museum artefacts, depicted in a picture. Text (1), from the gnome corpus (Poesio et al., 2004), is an example of short human-authored text from this genre: (1) (a) 144 is a torc. (b) Its present arrangement, twisted into three rings, may be a modern alteration; (c) it should probably be a single ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: t</context>
</contexts>
<marker>ODonnell, Mellish, Oberlander, Knott, 2001</marker>
<rawString>Mick ODonnell, Chris Mellish, Jon Oberlander, and Alistair Knott. 2001. ILEX: An architecture for a dynamic hypertext generation system. Natural Language Engineering, 7(3):225250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passoneau</author>
</authors>
<title>Interaction of discourse structure with explicitness of discourse anaphoric phrases.</title>
<date>1998</date>
<booktitle>In Walker</booktitle>
<pages>327358</pages>
<contexts>
<context position="12787" citStr="Passoneau (1998)" startWordPosition="2156" endWordPosition="2157">he second utterance in a sequence U2 has a CB, then it is taken to be either a continue or a retain, although U1 is not classified as a nocb. 7 As for the other two principles, no violation of cheapness is computed for (a) or when Un is marked as a nocb. \x0cof the transitions in the gnome corpus in configurations such as the one used in this paper. More generally, a significant percentage of nocbs (at least 20%) and other dispreferred transitions was found with all parameter configurations tested by Poesio et al. (2004) and indeed by all previous corpus-based evaluations of Centering such as Passoneau (1998), Di Eugenio (1998), Strube and Hahn (1999) among others. These results led Poesio et al. (2004) to the conclusion that the entity coherence as formalized in Centering should be supplemented with an account of other coherence inducing factors to explain what makes texts coherent. These studies, however, do not investigate the question that is most important from the text structuring perspective adopted in this paper: whether there would be alternative ways of structuring the text that would result in fewer violations of Centerings constraints (Kibble, 2001). Consider the nocb utterance (d) in </context>
</contexts>
<marker>Passoneau, 1998</marker>
<rawString>Rebecca J. Passoneau. 1998. Interaction of discourse structure with explicitness of discourse anaphoric phrases. In Walker et al. (Walker et al., 1998b), pages 327358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Rosemary Stevenson</author>
<author>Barbara Di Eugenio</author>
<author>Janet Hitzeman</author>
</authors>
<title>Centering: a parametric theory and its instantiations.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<marker>Poesio, Stevenson, Di Eugenio, Hitzeman, 2004</marker>
<rawString>Massimo Poesio, Rosemary Stevenson, Barbara Di Eugenio, and Janet Hitzeman. 2004. Centering: a parametric theory and its instantiations. Computational Linguistics, 30(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<location>Cambridge.</location>
<contexts>
<context position="2893" citStr="Reiter and Dale, 2000" startWordPosition="459" endWordPosition="462"> seminal papers of the theory (Brennan et al., 1987; Grosz et al., 1995). In this work, we explored this question by developing an approach to text structuring purely based on Centering, in which the role of other factors is deliberately ignored. In accordance with recent work in the emerging field of text-to-text generation (Barzilay et al., 2002; Lapata, 2003), we assume that the input to text structuring is a set of clauses. The output of text structuring is merely an ordering of these clauses, rather than the tree-like structure of database facts often used in traditional deep generation (Reiter and Dale, 2000). Our approach is further characterized by two key insights. The first distinguishing feature is that we assume a search-based approach to text structuring (Mellish et al., 1998; Kibble and Power, 2000; Karamanis and Manurung, 2002) in which many candidate orderings of clauses are evaluated according to scores assigned by a given metric, and the best-scoring ordering among the candidate solutions is chosen. The second novel aspect is that our approach is based on the position that the most straightforward way of using Centering for text structuring is by defining a Centering-based metric of co</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building Natural Language Generation Systems. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Udo Hahn</author>
</authors>
<title>Functional centering: Grounding referential coherence in information structure.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="8137" citStr="Strube and Hahn, 1999" startWordPosition="1347" endWordPosition="1350">t of ne410 144. (2) &lt;unit finite=finite-yes id=u210&amp;gt; &lt;ne id=&amp;quot;ne410&amp;quot; gf=&amp;quot;subj&amp;quot;&amp;gt;144&lt;/ne&amp;gt; is &lt;ne id=&amp;quot;ne411&amp;quot; gf=&amp;quot;predicate&amp;quot;&amp;gt; a torc&lt;/ne&amp;gt; &lt;/unit&amp;gt;. The ranking of the CFs other than the CP is defined according to the following preference on their gf (Brennan et al., 1987): obj&amp;gt;iobj&amp;gt;other. CFs with the same gf are ranked according to the linear order of the corresponding NPs in the utterance. The second column of Table 1 shows how the utterances in example (1) are automatically translated by the scripts developed by Poesio et al. (2004) into a 1 For example, one could equate utterance with sentence (Strube and Hahn, 1999; Miltsakaki, 2002), use indirect realisation for the computation of the CF list (Grosz et al., 1995), rank the CFs according to their information status (Strube and Hahn, 1999), etc. 2 Our definition includes titles which are not always finite units, but excludes finite relative clauses, the second element of coordinated VPs and clause complements which are often taken as not having their own CF lists in the literature. 3 Or as a post-copular subject in a there-clause. \x0cCF list: cheapness U {CP, other CFs} CB Transition CBn=CPn1 (a) {de374, de375} n.a. n.a. n.a. (b) {de376, de374, de377} d</context>
<context position="11585" citStr="Strube and Hahn, 1999" startWordPosition="1943" endWordPosition="1946">e and the requirement that CBn be the same as CPn the principle of salience. Each of these principles can be satisfied or violated while their various combinations give rise to the standard transitions of Centering shown in Table 2; Poesio et als scripts compute these violations.6 We also make note of the preference between these transitions, known as Centerings Rule 2 (Brennan et al., 1987): continue is preferred to retain, which is preferred to smoothshift, which is preferred to rough-shift. Finally, the scripts determine whether CBn is the same as CPn1, known as the principle of cheapness (Strube and Hahn, 1999). The last column of Table 1 shows the violations of cheapness (denoted with an asterisk) in (1).7 2.3 Evaluating the coherence of a text and text structuring The statistics about transitions computed as just discussed can be used to determine the degree to which a text conforms with, or violates, Centerings principles. Poesio et al. (2004) found that nocbs account for more than 50% of the atomic facts the algorithm has to structure, i.e., we are assuming that CFs are arguments of such facts; including indirectly realized entities in CF lists would violate this assumption. 6 If the second utte</context>
<context position="12830" citStr="Strube and Hahn (1999)" startWordPosition="2161" endWordPosition="2164">has a CB, then it is taken to be either a continue or a retain, although U1 is not classified as a nocb. 7 As for the other two principles, no violation of cheapness is computed for (a) or when Un is marked as a nocb. \x0cof the transitions in the gnome corpus in configurations such as the one used in this paper. More generally, a significant percentage of nocbs (at least 20%) and other dispreferred transitions was found with all parameter configurations tested by Poesio et al. (2004) and indeed by all previous corpus-based evaluations of Centering such as Passoneau (1998), Di Eugenio (1998), Strube and Hahn (1999) among others. These results led Poesio et al. (2004) to the conclusion that the entity coherence as formalized in Centering should be supplemented with an account of other coherence inducing factors to explain what makes texts coherent. These studies, however, do not investigate the question that is most important from the text structuring perspective adopted in this paper: whether there would be alternative ways of structuring the text that would result in fewer violations of Centerings constraints (Kibble, 2001). Consider the nocb utterance (d) in (1). Simply observing that this transition </context>
</contexts>
<marker>Strube, Hahn, 1999</marker>
<rawString>Michael Strube and Udo Hahn. 1999. Functional centering: Grounding referential coherence in information structure. Computational Linguistics, 25(3):309344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Aravind K Joshi</author>
<author>Ellen F Prince</author>
</authors>
<title>Centering in naturally occuring discourse: An overview.</title>
<date>1998</date>
<booktitle>In Walker et</booktitle>
<pages>130</pages>
<contexts>
<context position="1641" citStr="Walker et al., 1998" startWordPosition="247" endWordPosition="250">pective. 1 Motivation Our research area is descriptive text generation (ODonnell et al., 2001; Isard et al., 2003), i.e. the generation of descriptions of objects, typically museum artefacts, depicted in a picture. Text (1), from the gnome corpus (Poesio et al., 2004), is an example of short human-authored text from this genre: (1) (a) 144 is a torc. (b) Its present arrangement, twisted into three rings, may be a modern alteration; (c) it should probably be a single ring, worn around the neck. (d) The terminals are in the form of goats heads. According to Centering Theory (Grosz et al., 1995; Walker et al., 1998a), an important factor for the felicity of (1) is its entity coherence: the way centers (discourse entities), such as the referent of the NPs 144 in clause (a) and its in clause (b), are introduced and discussed in subsequent clauses. It is often claimed in current work on in natural language generation that the constraints on felicitous text proposed by the theory are useful to guide text structuring, in combination with other factors (see (Karamanis, 2003) for an overview). However, how successful Centerings constraints are on their own in generating a felicitous text structure is an open q</context>
</contexts>
<marker>Walker, Joshi, Prince, 1998</marker>
<rawString>Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince. 1998a. Centering in naturally occuring discourse: An overview. In Walker et al. (Walker et al., 1998b), pages 130.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marilyn A Walker</author>
<author>Aravind K Joshi</author>
</authors>
<booktitle>1998b. Centering Theory in Discourse.</booktitle>
<editor>and Ellen F. Prince, editors.</editor>
<publisher>Clarendon Press,</publisher>
<location>Oxford. \x0c&apos;</location>
<marker>Walker, Joshi, </marker>
<rawString>Marilyn A. Walker, Aravind K. Joshi, and Ellen F. Prince, editors. 1998b. Centering Theory in Discourse. Clarendon Press, Oxford. \x0c&apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>