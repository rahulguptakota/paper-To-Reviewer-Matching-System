<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<bodyText confidence="0.439507">
b&apos;Proceedings of the ACL-HLT 2011 Student Session, pages 105110,
Portland, OR, USA 19-24 June 2011. c
</bodyText>
<sectionHeader confidence="0.358771" genericHeader="abstract">
2011 Association for Computational Linguistics
</sectionHeader>
<title confidence="0.820093">
Exploiting Morphology in Turkish Named Entity Recognition System
</title>
<author confidence="0.824561">
Reyyan Yeniterzi
</author>
<affiliation confidence="0.917928">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.937284">
Pittsburgh, PA, 15213, USA
</address>
<email confidence="0.997038">
reyyan@cs.cmu.edu
</email>
<sectionHeader confidence="0.990721" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999151625">
Turkish is an agglutinative language with
complex morphological structures, therefore
using only word forms is not enough for many
computational tasks. In this paper we an-
alyze the effect of morphology in a Named
Entity Recognition system for Turkish. We
start with the standard word-level representa-
tion and incrementally explore the effect of
capturing syntactic and contextual properties
of tokens. Furthermore, we also explore a new
representation in which roots and morphologi-
cal features are represented as separate tokens
instead of representing only words as tokens.
Using syntactic and contextual properties with
the new representation provide an 7.6% rela-
tive improvement over the baseline.
</bodyText>
<sectionHeader confidence="0.998293" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99892735">
One of the main tasks of information extraction is
the Named Entity Recognition (NER) which aims to
locate and classify the named entities of an unstruc-
tured text. State-of-the-art NER systems have been
produced for several languages, but despite all these
recent improvements, developing a NER system for
Turkish is still a challenging task due to the structure
of the language.
Turkish is a morphologically complex language
with very productive inflectional and derivational
processes. Many local and non-local syntactic struc-
tures are represented as morphemes which at the
The author is also affiliated with iLab and the Center for the
Future of Work of Heinz College, Carnegie Mellon University
end produces Turkish words with complex morpho-
logical structures. For instance, the following En-
glish phrase if we are going to be able to make
[something] acquire flavor which contains the nec-
essary function words to represent the meaning can
be translated into Turkish with only one token tat-
landrabileceksek which is produced from the root
tat (flavor) with additional morphemes +lan (ac-
quire), +dr (to make), +abil (to be able), +ecek (are
going), +se (if) and +k (we).
This productive nature of the Turkish results in
production of thousands of words from a given root,
which cause data sparseness problems in model
training. In order to prevent this behavior in our
NER system, we propose several features which
capture the meaning and syntactic properties of the
token in addition to the contextual properties. We
also propose using a sequence of morphemes repre-
sentation which uses roots and morphological fea-
tures as tokens instead of words.
The rest of this paper is organized as follows:
Section 2 summarizes some previous related works,
Section 3 describes our approach, Section 4 details
the data sets used in the paper, Section 5 reports
the experiments and results and Section 6 concludes
with possible future work.
</bodyText>
<sectionHeader confidence="0.999534" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.993120833333333">
The first paper (Cucerzan and Yarowski, 1999)
on Turkish NER describes a language independent
bootstrapping algorithm that learns from word inter-
nal and contextual information of entities. Turkish
was one of the five languages the authors experi-
mented with. In another work (Tur et al., 2003),
</bodyText>
<page confidence="0.99929">
105
</page>
<bodyText confidence="0.999727764705882">
\x0cthe authors followed a statistical approach (HMMs)
for NER task together with some other Information
Extraction related tasks. In order to deal with the
agglutinative structure of the Turkish, the authors
worked with the root-morpheme level of the word
instead of the surface form. A recent work (Kucuk
and Yazici, 2009) presents the first rule-based NER
system for Turkish. The authors used several in-
formation sources such as dictionaries, list of well
known entities and context patterns.
Our work is different from these previous works
in terms of the approach. In this paper, we present
the first CRF-based NER system for Turkish. Fur-
thermore, all these systems used word-level tok-
enization but in this paper we present a new to-
kenization method which represents each root and
morphological feature as separate tokens.
</bodyText>
<sectionHeader confidence="0.996771" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.99949">
In this work, we used two tokenization methods. Ini-
tially we started with the sequence of words rep-
resentation which will be referred as word-level
model. We also introduced morpheme-level model
in which morphological features are represented as
states. We used several features which were cre-
ated from deep and shallow analysis of the words.
During our experiments we used Conditional Ran-
dom Fields (CRF) which provides advantages over
HMMs and enables the use of any number of fea-
tures.
</bodyText>
<subsectionHeader confidence="0.973008">
3.1 Word-Level Model
</subsectionHeader>
<bodyText confidence="0.999253">
Word-level tokenization is very commonly used in
NER systems. In this model, each word is repre-
sented with one state. Since CRF can use any num-
ber of features to infer the hidden state, we develop
several feature sets which allow us to represent more
about the word.
</bodyText>
<subsubsectionHeader confidence="0.966007">
3.1.1 Lexical Model
</subsubsectionHeader>
<bodyText confidence="0.999838571428571">
In this model, only the word tokens are used in
their surface form. This model is effective for many
languages which do not have complex morpholog-
ical structures. However for morphologically rich
languages, further analysis of words is required in
order to prevent data sparseness problems and pro-
duce more accurate NER systems.
</bodyText>
<subsubsectionHeader confidence="0.969368">
3.1.2 Root Feature
</subsubsectionHeader>
<bodyText confidence="0.9986415">
An analysis (Hakkani-Tur, 2000) on English and
Turkish news articles with around 10 million words
showed that on the average 5 different Turkish word
forms are produced from the same root. In order to
decrease this high variation of words we use the root
forms of the words as an additional feature.
</bodyText>
<subsectionHeader confidence="0.816362">
3.1.3 Part-of-Speech and Proper-Noun
Features
</subsectionHeader>
<bodyText confidence="0.9783844">
Named entities are mostly noun phrases, such as
first name and last name or organization name and
the type of organization. This property has been
used widely in NER systems as a hint to determine
the possible named entities.
Part-of-Speech tags of the words depend highly
on the language and the available Part-of-Speech
tagger. Taggers may distinguish the proper nouns
with or without their types. We used a Turkish mor-
phological analyzer (Of lazer, 1994) which analyzes
words into roots and morphological features. An ex-
ample to the output of the analyzer is given in Ta-
ble 1. The part-of-speech tag of each word is also
reported by the tool 1. We use these tags as addi-
tional features and call them part-of-speech (POS)
features.
The morphological analyzer has a proper name
database, which is used to tag Turkish person, lo-
cation and organization names as proper nouns. An
example name entity with this +Prop tag is given
in Table 1. Although, the use of this tag is limited
to the given database and not all named entities are
tagged with it, we use it as a feature to distinguish
named entities. This feature is referred as proper-
noun (Prop) feature.
</bodyText>
<subsubsectionHeader confidence="0.939307">
3.1.4 Case Feature
</subsubsectionHeader>
<bodyText confidence="0.9950645">
As the last feature, we use the orthographic case
information of the words. The initial letter of most
named entities is in upper case, which makes case
feature a very common feature in NER tasks. We
also use this feature and mark each token as UC or
LC depending on the initial letter of it. We dont do
</bodyText>
<page confidence="0.753452">
1
</page>
<bodyText confidence="0.99428">
The meanings of various Part-of-Speech tags are as fol-
lows: +A3pl - 3rd person plural; +P3sg - 3rd person singular
</bodyText>
<listItem confidence="0.703321">
possessive; +Gen - Genitive case; +Prop - Proper Noun; +A3sg
- 3rd person singular; +Pnon - No possesive agreement; +Nom
- Nominative case.
</listItem>
<page confidence="0.99136">
106
</page>
<tableCaption confidence="0.60149">
\x0cTable 1: Examples to the output of the Turkish morphological analyzer
</tableCaption>
<table confidence="0.731465333333333">
WORD + ROOT + POS + MORPHEMES
beyinlerinin (of their brains) + beyin + Noun + A3pl+P3sg+Gen
Amerika (America) + Amerika + Noun + Prop+A3sg+Pnon+Nom
</table>
<bodyText confidence="0.997120333333333">
anything special for the first words in sentences.
An example phase in word-level model is given in
Table 2 2. In the figure each row represents a state.
The first column is the lexical form of the word and
the rest of the columns are the features and the tag is
in the last column.
</bodyText>
<subsectionHeader confidence="0.925591">
3.2 Morpheme-Level Model
</subsectionHeader>
<bodyText confidence="0.982323166666667">
Using Part-of-Speech tags as features introduces
some syntactic properties of the word to the model,
but still there is missing information of other mor-
phological tags such as number/person agreements,
possessive agreements or cases. In order to see the
effect of these morphological tags in NER, we pro-
pose a morpheme-level tokenization method which
represents a word in several states; one state for a
root and one state for each morphological feature.
In a setting like this, the model has to be restricted
from assigning different labels to different parts of
the word. In order to do this, we use an additional
feature called root-morph feature. The root-morph
is a feature which is assigned the value root for
states containing a root and the value morph for
states containing a morpheme. Since there are no
prefixes in Turkish, a model trained with this feature
will give zero probability (or close to zero probabil-
ity if there is any smoothing) for assigning any B-*
(Begin any NE) tag to a morph state. Similarly, tran-
sition from a state with B-* or I-* (Inside any NE)
tag to a morph state with O (Other) tag will get zero
probability from the model.
In morpheme-level model, we use the following
features:
the actual root of the word for root and mor-
phemes of the token
the Part-of-speech tag of the word for the root
part and the morphological tag for the mor-
phemes
</bodyText>
<page confidence="0.931962">
2
</page>
<bodyText confidence="0.995419">
One can see that Ilias which is Person NE is not tagged as
Prop (Proper Noun) in the example, mainly because it is missing
in the proper noun database of the morphological analyzer.
the root-morph feature which assigns root to
the roots and morph to the morphemes
the proper-noun feature
the case feature
An example phrase in root-morpheme-based
chunking is given in Table 3. In the figure each row
represents a state and each word is represented with
several states. The first row of each word contains
the root, POS tag and Root value for the root-morph
feature. The rest of the rows of the same word con-
tains the morphemes and Morph value for the root-
morph feature.
</bodyText>
<sectionHeader confidence="0.977385" genericHeader="method">
4 Data Set
</sectionHeader>
<bodyText confidence="0.997230636363636">
We used training set of the newspaper articles data
set that has been used in (Tur et al., 2003). Since we
do not have the test set they have used in their paper,
we had to come up with our own test set. We used
only 90% of the train data for training and left the
remaining for testing.
Three types of named entities; person, organiza-
tion and location, were tagged in this dataset. If the
word is not a proper name, then it is tagged with
other. The number of words and named entities for
each NE type from train and tests sets are given in
</bodyText>
<tableCaption confidence="0.99993">
Table 4.
Table 4: The number of words and named entities in train
</tableCaption>
<table confidence="0.90747825">
and test set
#WORDS #PER. #ORG. #LOC.
TRAIN 445,498 21,701 14,510 12,138
TEST 47,344 2,400 1,595 1,402
</table>
<sectionHeader confidence="0.96074" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.997857">
Before using our data in the experiments we applied
the Turkish morphological analyzer tool (Of lazer,
1994) and then used Morphological disambiguator
(Sak et al., 2008) in order to choose the correct mor-
phological analysis of the word depending on the
</bodyText>
<page confidence="0.999429">
107
</page>
<tableCaption confidence="0.588667">
\x0cTable 2: An example phrase in word-level model with all features
</tableCaption>
<table confidence="0.9598516">
LEXICAL ROOT POS PROP CASE TAG
Ayvalk Ayvalk Noun Prop UC B-LOCATION
dogumlu dogum (birth) Noun NotProp LC O
yazar yazar (author) Noun NotProp LC O
Ilias ilias Noun NotProp UC B-PERSON
</table>
<tableCaption confidence="0.973001">
Table 3: An example phrase in morpheme-level model with all features
</tableCaption>
<table confidence="0.982874470588235">
ROOT POS ROOT-MORPH PROP CASE TAG
Ayvalk Noun Root Prop UC B-LOCATION
Ayvalk Prop Morph Prop UC I-LOCATION
Ayvalk A3sg Morph Prop UC I-LOCATION
Ayvalk Pnon Morph Prop UC I-LOCATION
Ayvalk Nom Morph Prop UC I-LOCATION
dogum Noun Root NotProp LC O
dogum Adj Morph NotProp LC O
dogum With Morph NotProp LC O
yazar Noun Root NotProp LC O
yazar A3sg Morph NotProp LC O
yazar Pnon Morph NotProp LC O
yazar Nom Morph NotProp LC O
Ilias Noun Root NotProp UC B-PERSON
Ilias A3sg Morph NotProp UC I-PERSON
Ilias Pnon Morph NotProp UC I-PERSON
Ilias Nom Morph NotProp UC I-PERSON
</table>
<bodyText confidence="0.994244">
context. In experiments, we used CRF++ 3, which
is an open source CRF sequence labeling toolkit and
we used the conlleval 4 evaluation script to report
F-measure, precision and recall values.
</bodyText>
<subsectionHeader confidence="0.788588">
5.1 Word-level Model
</subsectionHeader>
<bodyText confidence="0.999175285714286">
In order to see the effects of the features individu-
ally, we inserted them to the model one by one it-
eratively and applied the model to the test set. The
F-measures of these models are given in Table 5. We
can observe that each feature is improving the per-
formance of the system. Overall the F-measure was
increased by 6 points when all the features are used.
</bodyText>
<subsectionHeader confidence="0.921589">
5.2 Morpheme-level Model
</subsectionHeader>
<bodyText confidence="0.999954833333333">
In order to make a fair comparison between the
word-level and morpheme-level models, we used all
the features in both models. The results of these
experiments are given in Table 6. According to
the table, morpheme-level model achieved better re-
sults than word-level model in person and location
</bodyText>
<page confidence="0.89943">
3
</page>
<figure confidence="0.161457666666667">
CRF++: Yet Another CRF toolkit
4
www.cnts.ua.ac.be/conll2000/chunking/conlleval.txt
</figure>
<bodyText confidence="0.981454956521739">
entities. Even though word-level model got better
F-Measure score in organization entity, morpheme-
level is much better than word-level model in terms
of recall.
Using morpheme-level tokenization to introduce
morphological information to the model did not hurt
the system, but it also did not produce a signifi-
cant improvement. There may be several reasons for
this. One can be that morphological information is
not helpful in NER tasks. Morphemes in Turkish
words are giving the necessary syntactic meaning to
the word which may not be useful in named entity
finding. Another reason for not seeing a significant
change with morpheme usage can be our represen-
tation. Dividing the word into root and morphemes
and using them as separate tokens may not be the
best way of using morphemes in the model. Other
ways of representing morphemes in the model may
produce more effective results.
As mentioned in Section 4, we do not have the
same test set that has been used in Tur et al. (Tur
et al., 2003). Even though it is impossible to make a
fair comparison between these two systems, it would
</bodyText>
<page confidence="0.998839">
108
</page>
<table confidence="0.968499857142857">
\x0cTable 5: F-measure Results of Word-level Model
PERSON ORGANIZATION LOCATION OVERALL
LEXICAL MODEL (LM) 80.88 77.05 88.40 82.60
LM + ROOT 83.32 80.00 90.30 84.96
LM + ROOT + POS 84.91 81.63 90.18 85.98
LM + ROOT + POS + PROP 86.82 82.66 90.52 87.18
LM + ROOT + POS + PROP + CASE 88.58 84.71 91.47 88.71
</table>
<tableCaption confidence="0.992645">
Table 6: Results of Morpheme-Level (Morp) and Word-Level Models (Word)
</tableCaption>
<table confidence="0.856603272727273">
PRECISION RECALL F-MEASURE
MORP WORD MORP WORD MORP WORD
PERSON 91.87% 91.41% 86.92% 85.92% 89.32 88.58
ORGANIZATION 85.23% 91.00% 81.84% 79.23% 83.50 84.71
LOCATION 94.15% 92.83% 90.23% 90.14% 92.15 91.47
OVERALL 91.12% 91.81% 86.87% 85.81% 88.94 88.71
Table 7: F-measure Comparison of two systems
OURS (TUR ET AL., 2003)
BASELINE MODEL 82.60 86.01
BEST MODEL 88.94 91.56
IMPROVEMENT 7.6% 6.4%
</table>
<bodyText confidence="0.989085">
be good to note how these systems performed with
respect to their baselines which is lexical model in
both. As it can be seen from Table 7, both models
improved upon their baselines significantly.
</bodyText>
<sectionHeader confidence="0.992829" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9997974375">
In this paper, we explored the effects of using fea-
tures like root, POS tag, proper noun and case to the
performance of NER task. All these features seem to
improve the system significantly. We also explored
a new way of including morphological information
of words to the system by using several tokens for a
word. This method produced compatible results to
the regular word-level tokenization but did not pro-
duce a significant improvement.
As future work we are going to explore other ways
of representing morphemes in the model. Here we
represented morphemes as separate states, but in-
cluding them as features together with the root state
may produce better models. Another approach we
will also focus is dividing words into characters and
applying character-level models (Klein et al., 2003).
</bodyText>
<sectionHeader confidence="0.978334" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998987888888889">
The author would like to thank William W. Cohen,
Kemal Of lazer, Gokhan Tur and Behrang Mohit for
their valuable feedback and helpful discussions. The
author also thank Kemal Of lazer for providing the
data set and the morphological analyzer. This publi-
cation was made possible by the generous support of
the iLab and the Center for the Future of Work. The
statements made herein are solely the responsibility
of the author.
</bodyText>
<sectionHeader confidence="0.991701" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997880263157895">
Silviu Cucerzan and David Yarowski. 1999. Language
independent named entity recognition combining mor-
phological and contextual evidence. In Proceedings of
the Joint SIGDAT Conference on EMNLP and VLC,
pages 9099.
Dilek Z. Hakkani-Tur. 2000. Statistical Language Mod-
elling for Turkish. Ph.D. thesis, Department of Com-
puter Engineering, Bilkent University.
Dan Klein, Joseph Smarr, Huy Nguyen, and Christo-
pher D. Manning. 2003. Named entity recognition
with character-level models. In Proceedings of the
seventh conference on Natural language learning at
HLT-NAACL 2003 - Volume 4, pages 180183.
Dilek Kucuk and Adnan Yazici. 2009. Named entity
recognition experiments on Turkish texts. In Proceed-
ings of the 8th International Conference on Flexible
Query Answering Systems, FQAS 09, pages 524535,
Berlin, Heidelberg. Springer-Verlag.
Kemal Of lazer. 1994. Two-level description of Turk-
</reference>
<page confidence="0.982202">
109
</page>
<reference confidence="0.992768090909091">
\x0cish morphology. Literary and Linguistic Computing,
9(2):137148.
Hasim Sak, Tunga Gungor, and Murat Saraclar. 2008.
Turkish language resources: Morphological parser,
morphological disambiguator and web corpus. In Ad-
vances in Natural Language Processing, volume 5221
of Lecture Notes in Computer Science, pages 417427.
Gokhan Tur, Dilek Z. Hakkani-Tur, and Kemal Of lazer.
2003. A statistical information extraction system for
Turkish. In Natural Language Engineering, pages
181210.
</reference>
<page confidence="0.874708">
110
</page>
<figure confidence="0.330554">
\x0c&apos;
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.894856">
<note confidence="0.976188333333333">b&apos;Proceedings of the ACL-HLT 2011 Student Session, pages 105110, Portland, OR, USA 19-24 June 2011. c 2011 Association for Computational Linguistics</note>
<title confidence="0.998254">Exploiting Morphology in Turkish Named Entity Recognition System</title>
<author confidence="0.992338">Reyyan Yeniterzi</author>
<affiliation confidence="0.997401">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.998395">Pittsburgh, PA, 15213, USA</address>
<email confidence="0.999867">reyyan@cs.cmu.edu</email>
<abstract confidence="0.998372823529412">Turkish is an agglutinative language with complex morphological structures, therefore using only word forms is not enough for many computational tasks. In this paper we analyze the effect of morphology in a Named Entity Recognition system for Turkish. We start with the standard word-level representation and incrementally explore the effect of capturing syntactic and contextual properties of tokens. Furthermore, we also explore a new representation in which roots and morphological features are represented as separate tokens instead of representing only words as tokens. Using syntactic and contextual properties with the new representation provide an 7.6% relative improvement over the baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
<author>David Yarowski</author>
</authors>
<title>Language independent named entity recognition combining morphological and contextual evidence.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on EMNLP and VLC,</booktitle>
<pages>9099</pages>
<contexts>
<context position="3050" citStr="Cucerzan and Yarowski, 1999" startWordPosition="466" endWordPosition="469">r in our NER system, we propose several features which capture the meaning and syntactic properties of the token in addition to the contextual properties. We also propose using a sequence of morphemes representation which uses roots and morphological features as tokens instead of words. The rest of this paper is organized as follows: Section 2 summarizes some previous related works, Section 3 describes our approach, Section 4 details the data sets used in the paper, Section 5 reports the experiments and results and Section 6 concludes with possible future work. 2 Related Work The first paper (Cucerzan and Yarowski, 1999) on Turkish NER describes a language independent bootstrapping algorithm that learns from word internal and contextual information of entities. Turkish was one of the five languages the authors experimented with. In another work (Tur et al., 2003), 105 \x0cthe authors followed a statistical approach (HMMs) for NER task together with some other Information Extraction related tasks. In order to deal with the agglutinative structure of the Turkish, the authors worked with the root-morpheme level of the word instead of the surface form. A recent work (Kucuk and Yazici, 2009) presents the first rul</context>
</contexts>
<marker>Cucerzan, Yarowski, 1999</marker>
<rawString>Silviu Cucerzan and David Yarowski. 1999. Language independent named entity recognition combining morphological and contextual evidence. In Proceedings of the Joint SIGDAT Conference on EMNLP and VLC, pages 9099.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Z Hakkani-Tur</author>
</authors>
<title>Statistical Language Modelling for Turkish.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Engineering, Bilkent University.</institution>
<contexts>
<context position="5318" citStr="Hakkani-Tur, 2000" startWordPosition="836" endWordPosition="837"> NER systems. In this model, each word is represented with one state. Since CRF can use any number of features to infer the hidden state, we develop several feature sets which allow us to represent more about the word. 3.1.1 Lexical Model In this model, only the word tokens are used in their surface form. This model is effective for many languages which do not have complex morphological structures. However for morphologically rich languages, further analysis of words is required in order to prevent data sparseness problems and produce more accurate NER systems. 3.1.2 Root Feature An analysis (Hakkani-Tur, 2000) on English and Turkish news articles with around 10 million words showed that on the average 5 different Turkish word forms are produced from the same root. In order to decrease this high variation of words we use the root forms of the words as an additional feature. 3.1.3 Part-of-Speech and Proper-Noun Features Named entities are mostly noun phrases, such as first name and last name or organization name and the type of organization. This property has been used widely in NER systems as a hint to determine the possible named entities. Part-of-Speech tags of the words depend highly on the langu</context>
</contexts>
<marker>Hakkani-Tur, 2000</marker>
<rawString>Dilek Z. Hakkani-Tur. 2000. Statistical Language Modelling for Turkish. Ph.D. thesis, Department of Computer Engineering, Bilkent University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Joseph Smarr</author>
<author>Huy Nguyen</author>
<author>Christopher D Manning</author>
</authors>
<title>Named entity recognition with character-level models.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL</booktitle>
<volume>4</volume>
<pages>180183</pages>
<marker>Klein, Smarr, Nguyen, Manning, 2003</marker>
<rawString>Dan Klein, Joseph Smarr, Huy Nguyen, and Christopher D. Manning. 2003. Named entity recognition with character-level models. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003 - Volume 4, pages 180183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Kucuk</author>
<author>Adnan Yazici</author>
</authors>
<title>Named entity recognition experiments on Turkish texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the 8th International Conference on Flexible Query Answering Systems, FQAS 09,</booktitle>
<pages>524535</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="3627" citStr="Kucuk and Yazici, 2009" startWordPosition="557" endWordPosition="560"> The first paper (Cucerzan and Yarowski, 1999) on Turkish NER describes a language independent bootstrapping algorithm that learns from word internal and contextual information of entities. Turkish was one of the five languages the authors experimented with. In another work (Tur et al., 2003), 105 \x0cthe authors followed a statistical approach (HMMs) for NER task together with some other Information Extraction related tasks. In order to deal with the agglutinative structure of the Turkish, the authors worked with the root-morpheme level of the word instead of the surface form. A recent work (Kucuk and Yazici, 2009) presents the first rule-based NER system for Turkish. The authors used several information sources such as dictionaries, list of well known entities and context patterns. Our work is different from these previous works in terms of the approach. In this paper, we present the first CRF-based NER system for Turkish. Furthermore, all these systems used word-level tokenization but in this paper we present a new tokenization method which represents each root and morphological feature as separate tokens. 3 Approach In this work, we used two tokenization methods. Initially we started with the sequenc</context>
</contexts>
<marker>Kucuk, Yazici, 2009</marker>
<rawString>Dilek Kucuk and Adnan Yazici. 2009. Named entity recognition experiments on Turkish texts. In Proceedings of the 8th International Conference on Flexible Query Answering Systems, FQAS 09, pages 524535, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Of lazer</author>
</authors>
<date>1994</date>
<booktitle>Two-level description of Turk\x0cish morphology. Literary and Linguistic Computing,</booktitle>
<pages>9--2</pages>
<contexts>
<context position="6090" citStr="lazer, 1994" startWordPosition="964" endWordPosition="965"> order to decrease this high variation of words we use the root forms of the words as an additional feature. 3.1.3 Part-of-Speech and Proper-Noun Features Named entities are mostly noun phrases, such as first name and last name or organization name and the type of organization. This property has been used widely in NER systems as a hint to determine the possible named entities. Part-of-Speech tags of the words depend highly on the language and the available Part-of-Speech tagger. Taggers may distinguish the proper nouns with or without their types. We used a Turkish morphological analyzer (Of lazer, 1994) which analyzes words into roots and morphological features. An example to the output of the analyzer is given in Table 1. The part-of-speech tag of each word is also reported by the tool 1. We use these tags as additional features and call them part-of-speech (POS) features. The morphological analyzer has a proper name database, which is used to tag Turkish person, location and organization names as proper nouns. An example name entity with this +Prop tag is given in Table 1. Although, the use of this tag is limited to the given database and not all named entities are tagged with it, we use i</context>
<context position="10810" citStr="lazer, 1994" startWordPosition="1811" endWordPosition="1812"> data for training and left the remaining for testing. Three types of named entities; person, organization and location, were tagged in this dataset. If the word is not a proper name, then it is tagged with other. The number of words and named entities for each NE type from train and tests sets are given in Table 4. Table 4: The number of words and named entities in train and test set #WORDS #PER. #ORG. #LOC. TRAIN 445,498 21,701 14,510 12,138 TEST 47,344 2,400 1,595 1,402 5 Experiments and Results Before using our data in the experiments we applied the Turkish morphological analyzer tool (Of lazer, 1994) and then used Morphological disambiguator (Sak et al., 2008) in order to choose the correct morphological analysis of the word depending on the 107 \x0cTable 2: An example phrase in word-level model with all features LEXICAL ROOT POS PROP CASE TAG Ayvalk Ayvalk Noun Prop UC B-LOCATION dogumlu dogum (birth) Noun NotProp LC O yazar yazar (author) Noun NotProp LC O Ilias ilias Noun NotProp UC B-PERSON Table 3: An example phrase in morpheme-level model with all features ROOT POS ROOT-MORPH PROP CASE TAG Ayvalk Noun Root Prop UC B-LOCATION Ayvalk Prop Morph Prop UC I-LOCATION Ayvalk A3sg Morph Pro</context>
</contexts>
<marker>lazer, 1994</marker>
<rawString>Kemal Of lazer. 1994. Two-level description of Turk\x0cish morphology. Literary and Linguistic Computing, 9(2):137148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasim Sak</author>
<author>Tunga Gungor</author>
<author>Murat Saraclar</author>
</authors>
<title>Turkish language resources: Morphological parser, morphological disambiguator and web corpus.</title>
<date>2008</date>
<booktitle>In Advances in Natural Language Processing,</booktitle>
<volume>5221</volume>
<pages>417427</pages>
<contexts>
<context position="10871" citStr="Sak et al., 2008" startWordPosition="1818" endWordPosition="1821">hree types of named entities; person, organization and location, were tagged in this dataset. If the word is not a proper name, then it is tagged with other. The number of words and named entities for each NE type from train and tests sets are given in Table 4. Table 4: The number of words and named entities in train and test set #WORDS #PER. #ORG. #LOC. TRAIN 445,498 21,701 14,510 12,138 TEST 47,344 2,400 1,595 1,402 5 Experiments and Results Before using our data in the experiments we applied the Turkish morphological analyzer tool (Of lazer, 1994) and then used Morphological disambiguator (Sak et al., 2008) in order to choose the correct morphological analysis of the word depending on the 107 \x0cTable 2: An example phrase in word-level model with all features LEXICAL ROOT POS PROP CASE TAG Ayvalk Ayvalk Noun Prop UC B-LOCATION dogumlu dogum (birth) Noun NotProp LC O yazar yazar (author) Noun NotProp LC O Ilias ilias Noun NotProp UC B-PERSON Table 3: An example phrase in morpheme-level model with all features ROOT POS ROOT-MORPH PROP CASE TAG Ayvalk Noun Root Prop UC B-LOCATION Ayvalk Prop Morph Prop UC I-LOCATION Ayvalk A3sg Morph Prop UC I-LOCATION Ayvalk Pnon Morph Prop UC I-LOCATION Ayvalk N</context>
</contexts>
<marker>Sak, Gungor, Saraclar, 2008</marker>
<rawString>Hasim Sak, Tunga Gungor, and Murat Saraclar. 2008. Turkish language resources: Morphological parser, morphological disambiguator and web corpus. In Advances in Natural Language Processing, volume 5221 of Lecture Notes in Computer Science, pages 417427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Dilek Z Hakkani-Tur</author>
<author>Kemal Of lazer</author>
</authors>
<title>A statistical information extraction system for Turkish. In Natural Language Engineering,</title>
<date>2003</date>
<pages>181210</pages>
<contexts>
<context position="3297" citStr="Tur et al., 2003" startWordPosition="505" endWordPosition="508">s as tokens instead of words. The rest of this paper is organized as follows: Section 2 summarizes some previous related works, Section 3 describes our approach, Section 4 details the data sets used in the paper, Section 5 reports the experiments and results and Section 6 concludes with possible future work. 2 Related Work The first paper (Cucerzan and Yarowski, 1999) on Turkish NER describes a language independent bootstrapping algorithm that learns from word internal and contextual information of entities. Turkish was one of the five languages the authors experimented with. In another work (Tur et al., 2003), 105 \x0cthe authors followed a statistical approach (HMMs) for NER task together with some other Information Extraction related tasks. In order to deal with the agglutinative structure of the Turkish, the authors worked with the root-morpheme level of the word instead of the surface form. A recent work (Kucuk and Yazici, 2009) presents the first rule-based NER system for Turkish. The authors used several information sources such as dictionaries, list of well known entities and context patterns. Our work is different from these previous works in terms of the approach. In this paper, we presen</context>
<context position="10061" citStr="Tur et al., 2003" startWordPosition="1670" endWordPosition="1673">orphological analyzer. the root-morph feature which assigns root to the roots and morph to the morphemes the proper-noun feature the case feature An example phrase in root-morpheme-based chunking is given in Table 3. In the figure each row represents a state and each word is represented with several states. The first row of each word contains the root, POS tag and Root value for the root-morph feature. The rest of the rows of the same word contains the morphemes and Morph value for the rootmorph feature. 4 Data Set We used training set of the newspaper articles data set that has been used in (Tur et al., 2003). Since we do not have the test set they have used in their paper, we had to come up with our own test set. We used only 90% of the train data for training and left the remaining for testing. Three types of named entities; person, organization and location, were tagged in this dataset. If the word is not a proper name, then it is tagged with other. The number of words and named entities for each NE type from train and tests sets are given in Table 4. Table 4: The number of words and named entities in train and test set #WORDS #PER. #ORG. #LOC. TRAIN 445,498 21,701 14,510 12,138 TEST 47,344 2,4</context>
<context position="13826" citStr="Tur et al., 2003" startWordPosition="2320" endWordPosition="2323">at morphological information is not helpful in NER tasks. Morphemes in Turkish words are giving the necessary syntactic meaning to the word which may not be useful in named entity finding. Another reason for not seeing a significant change with morpheme usage can be our representation. Dividing the word into root and morphemes and using them as separate tokens may not be the best way of using morphemes in the model. Other ways of representing morphemes in the model may produce more effective results. As mentioned in Section 4, we do not have the same test set that has been used in Tur et al. (Tur et al., 2003). Even though it is impossible to make a fair comparison between these two systems, it would 108 \x0cTable 5: F-measure Results of Word-level Model PERSON ORGANIZATION LOCATION OVERALL LEXICAL MODEL (LM) 80.88 77.05 88.40 82.60 LM + ROOT 83.32 80.00 90.30 84.96 LM + ROOT + POS 84.91 81.63 90.18 85.98 LM + ROOT + POS + PROP 86.82 82.66 90.52 87.18 LM + ROOT + POS + PROP + CASE 88.58 84.71 91.47 88.71 Table 6: Results of Morpheme-Level (Morp) and Word-Level Models (Word) PRECISION RECALL F-MEASURE MORP WORD MORP WORD MORP WORD PERSON 91.87% 91.41% 86.92% 85.92% 89.32 88.58 ORGANIZATION 85.23% 91</context>
</contexts>
<marker>Tur, Hakkani-Tur, lazer, 2003</marker>
<rawString>Gokhan Tur, Dilek Z. Hakkani-Tur, and Kemal Of lazer. 2003. A statistical information extraction system for Turkish. In Natural Language Engineering, pages 181210.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>