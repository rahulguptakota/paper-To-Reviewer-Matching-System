Coling 2008: Companion volume – Posters and Demonstrations, pages 47–50
Manchester, August 2008
ILP-based Conceptual Analysis for Chinese NPs
Paul D. Ji
Center for Language and Philology
Oxford University
Paul_dji@yahoo.com.uk
Stephen Pulman
Computing Laboratory
Oxford University
sgp@clg.ox.ac.uk
ABSTRACT
In this paper, we explore a conceptual re-
source for Chinese nominal phrases,
which allows multi-dependency and dis-
tinction between dependency and the cor-
responding exact relation. We also pro-
vide an ILP-based method to learn map-
ping rules from training data, and use the
rules to analyze new nominal phrases.
1 Introduction
Nominal phrases have long been a concern in
linguistic research and language processing (e.g.,
Copestake and Briscoe, 2005; Giegerich, 2004).
Generally, nominal phrases can be classified into
two categories according to whether they contain
attributive clauses or not. We focus on nominal
phrases without attributive clauses.
Closely related with nominal phrases, nominal
compounds or base NPs have also attracted a
great attention in language processing. Gener-
ally, nominal compounds refer to nominal
phrases consisting of a series of nouns, while
base NPs refer to non-recursive nominal phrases.
However, such compounds or base NPs usually
co-occur with other non-nominal words in run-
ning texts, and it is impossible to separate them
during analysis. Furthermore, there exist syntac-
tic makers for attributive clauses, e.g., ‘which’ or
‘who’ in English and ‘ (of)’ in Chinese, nomi-
nal phrases without attributive clauses tend to be
a better linguistic category for theoretical and
practical investigation.
To analyze NPs, we need first to determine
what kinds of information are to be recognized.
In this work, we focus on conceptual relatedness
between words. For example, in linguistics and
© 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved.
law books, linguistic and law are both conceptu-
ally related with books, although linguistics
doesn’t have a superficial syntactic relation with
books. Then, we need to fulfill two sub-tasks.
One is about representation, i.e., what schemes
are to be used. The other is about analysis, i.e.,
how to derive the formal representation.
Regarding representation scheme, one possible
strategy would be using syntactic structures, as
are usually used in analysis for sentences. How-
ever, syntactic components for NPs, unlike those
for sentences (e.g., V, VP, A, AP, and S, etc.),
are difficult to differentiate, and rules governing
nominal phrases are especially difficult to deter-
mine. As an example, consider (bank
loan interest), which is a nominal compound
consisting of three serial nouns. For such a NP, if
a rule with binary combination is used, it would
produce two structures for the unambiguous NP.
If a rule with triple combination is used, as in
Chinese Treebank (Xue et al., 2005), it would be
difficult to disclose the lexical relation between
(bank) and (loan).
Another possible representation strategy
would be using dependency structures (Mel’cuk,
1988). Under this strategy, a NP could be repre-
sented as a dependency tree, which captures
various lexical control or dependency in the
phrase. However, traditional framework only
focuses on syntactic dependency, while concep-
tual relatedness may exist without syntactic rela-
tions. For example, for (eco-
nomic development and law construction in Shang-
hai), in traditional dependency analysis,
(Shanghai) would depend on the conjunction
word (and), since conjunction words are usu-
ally regarded as heads in coordinate structures.
Although the relatedness may go downward from
the head, it would be difficult to derive the relat-
edness between (Shanghai) and
(economic) or (law), since the two words are
even not heads of the conjuncts (eco-
47
nomic development) and (law develop-
ment).
As to analysis of NPs, there have been a lot of
work on statistical techniques for lexical depend-
ency parsing of sentences (Collins and Roark,
2004; McDonald et al., 2005), and these tech-
niques potentially can be used for analysis of
NPs if appropriate resources for NPs are avail-
able. However, these techniques are all meant to
building a dependency tree, while the conceptual
relatedness in NPs may form a graph, with multi-
dependency allowed. Additionally, these meth-
ods generally suffer from the difficulty of local
estimation from limited contexts and the struc-
tural information is difficult to be exploited
(Califf and Mooney, 2003).
Recently, relational learning methods in gen-
eral and inductive logic programming (ILP) in
particular have attracted a great of attention due
to their capability of going beyond finite feature
vectors and exploiting unbounded structural in-
formation from data (Califf and Mooney, 2003;
Page et al., 2003; Srinivasan et al., 2003).
In this work, we try to extend syntactic de-
pendency to conceptual dependency to capture
the embedded lexical relatedness, and use ILP to
analyze nominal phrases, making use of the
structural information provided by the resources
based on conceptual dependency.
2 Conceptual dependency
In comparison with syntactic dependency, con-
ceptual dependency may allow a word to be de-
pendent on multiple words at the same time. For
example, in (Economic devel-
opment and law construction in Shanghai),
(Shanghai) conceptually relates with both
(economic) and (law), while in
(activity of blood donation for university student
volunteers), (university student) relates on
both (volunteer) and (blood donation).
In addition, syntactic dependency doesn’t
exactly specify what kind of relatedness held
between words, although the words denoting the
relatedness may occur within NPs. For example,
1) is an ambiguous compound with two possible
interpretations listed in 2).
1) (student discussion)
2) i) discussion by students
ii) discussion about students
However, the dependency trees corresponding
with the two interpretations remain the same:
(student) depends on (discussion) in both
cases. In fact, their difference lies in the exact
semantic relations held between the words:
(student) is agent and patient of (discussion)
in 2i) and 2ii) respectively. This suggests that
only syntactic dependency is not enough to re-
flect conceptual difference.
Notice that in (2), the relations between the
two words (student) and (discussion) are
denoted by two proper nouns, agent and patient,
which may never co-occur with them in running
texts. However, in some cases, some word co-
occurring with two conceptually related words
do denote the relatedness exactly. Consider
(car in read color), where (color) relates with
both (car) and (red). In the conceptual view,
(color) can be seen as a feature of (car), and
(red) can be seen as a kind of value for the fea-
ture, as was also adopted in dealing with adjec-
tives in WordNet (Fellbaum, 1988). In this set-
ting, (red) directly depends on (car), and
(color) represents the relation between them.
In building the resource for Chinese NPs,
the conceptual relatedness is based on semantic
reference, while the dependency is based on syn-
tactic or potential syntactic relations. The feature
words we adopt are mostly listed in a medium
class, coded as Dn, in a Chinese thesaurus,
Tongyici Cilin (henceafter Cilin, Mei et al.,
1982). Function words (e.g., (from)), Part
words (e.g., (leg)) and Number words (e.g.,
(count)) are also regarded as feature words.
3 ILP-based Analysis
Fig. 1 gives the overall structure of the analysis
procedure.
END
Fig. 1 Overall structure of analysis procedure
The analysis consists of two phases, training and
parsing. During the training phase, rules are
learned for mapping from conceptual depend-
ency graphs to word strings based on training
examples. During the parsing phase, there are
three steps. Search is to find candidate depend-
ency graphs, Generation is to generate word
strings from candidate dependency graphs using
Rule Learning
Search
Generation
Evaluation
Parsing
Training
48
the learned rules, and Evaluation is to compare
the generated word strings with the original NPs.
3.1 Training: learning rules
For each training sample, we have a nominal
phrase and its corresponding conceptual depend-
ency graph. To learn the rules mapping from de-
pendency graphs to word strings, we need to tag
the words with their sense labels, which denote
the synsets in the thesaurus (Mei et al., 1982).
For the sense tagging, we used the same method
as in (Yarowsky, 1992) and used the minor cate-
gories in the thesaurus as the synsets.
Generally, a rule consists of two parts, Gr and
Sr. Gr is a dependency sub-graph and Sr is a
sense label string. Intuitively, conceptual con-
figuration in Gr is represented by the label string
of Sr.
To capture more structural information, we
need to find the maximal sub-graph in the train-
ing data, whose corresponding labels form a con-
tinuous substring in the training data. But the
problem is NP hard, and we thus use heuristics to
find am optimally maximal sub-graphs. How-
ever, the search has a bias to larger sub-graphs,
and to avoid the bias, we set the coverage of a
sub-graph as the penalty. Here, the coverage of
the sub-graph refers to the percentage of the
nodes in the sub-graphs among all the nodes in
the training data. The overall algorithm is:
i) to find the most common edge in the training data,
whose corresponding label strings are continuous;
ii) to add another edge to the sub-graph, if the label
strings corresponding with the new sub-graph are
still continuous until the coverage of the sub-graph
doesn’t increase.
After finding such a sub-graph, we merge all
the nodes into one, and merge the sense label
strings into one, and repeat the process until all
the nodes in the training data are covered The
result of the learning is a set of rules, and each
rule specifies a sub-graph and a label string.
For example, w got a rule which includes the
sub-graph in Fig. 2 and sense label string in 3).
Fig. 2. Sub-graph in a rule.
3) SL( )SL( )SL( )
For rule generalization, we don’t try to com-
press the rule set, and simply use the sense hier-
archy in the thesaurus, including the minor, me-
dium and major classes.
3.2 Parsing
After training phase, we get a set of learned
rules. During parsing, the task is to find a con-
ceptual dependency graph for a new input data,
which would generate the NP using the learned
rules.
The optimal parsing can be implemented in a
greedy manner. First, one dependency with two
words is selected. Then, another word is added if
the resulted conceptual dependency graph gener-
ates a word string which best matches the input
nominal phrase. This process can be repeated
until the graph includes all the words in the data.
To compare the generated word string with the
original input, we use edit distance between
them, which is based on the times of operations
(including adjacent move, deletion, insertion)
needed to convert one word string to another.
4 Experiments and Evaluation
There are 10,000 nominal phrases annotated in
the resource, and they were selected from 1,221
articles form the corpora of China daily, 1992.
Table 1 gives the statistics of the resource.
num ‘de’
structure
Nominal
compound
Depend-
ency with
feature
Multi-
depend-
ency
10K 4,234 5,766 1,235 976
Table 1. Statistics of NP resource
Here, ‘de’ structure refer to the phrase with
word ‘ ’ (of). Nominal compounds refer to the
nominal phrases with no occurrence of ‘ ’(of).
Dependency with features refers to those tagged
with features, which also occur in the same NPs.
Multi-dependency refers to the number of mono-
dependencies occurring in the multi-dependency.
We randomly selected 10% of the training
data as closed test data, and the other 90% or less
as training data. To evaluate the performance of
the dependency analysis, we used F-scores as
evaluation measure as usual. Fig. 4 shows the
results for overall dependency, multi-dependency
and dependency with features. The results are
averaged over 10 random runs.
(and)
(boys)
(some)
49
0
0. 2
0. 4
0. 6
0. 8
1
10% 30% 50% 70% 90%
Tr ai ni ng dat a
F-
S
cor
e
over al dependency
m
ul t i - dependency
dependency w
i t h f eat ures
Fig. 3 Performance with varying training data
Fig. 3 demonstrates that with more training
data, the performance generally improved. The
performance for dependency with features
seemed better than that for overall dependency or
multi-dependency. To check the reason, we
found that we treated the Amount words in
Number-Amount structures as features, and these
words are generally easier to be identified, since
they tend to be unambiguous. Once they were
recognized as Amount words, the relevant de-
pendency would be correctly identified.
For an open test, we selected another 1,000
nominal phrases from the same corpus, but from
different time period (1994). Such phrases were
annotated with the same standard as those train-
ing data. Fig. 4 shows the results with varying
training data.
0
0. 2
0. 4
0. 6
0. 8
1
10% 30% 50% 70% 90%
Tr ai ni ng dat a
F-
Scor
e
cl osed t est ( 1000)
open t est (1000)
Fig. 4 Comparison: Closed test and open test
Fig. 4 shows that the open test performance is
generally worse than that of the closed test. No-
tice that although the test data was selected from
the same resource, but with a different period,
which may account for the different perform-
ance.
5 Conclusion
In this paper, we described a resource for lexical
conceptual dependency of Chinese nominal
phrases. Compared with other ones, it allows
multi-dependency and distinguishes dependency
and relation, which exactly denotes what kinds of
dependency held. We also provided an ILP-
based analysis method, in which some rules
mapping from conceptual dependency to word
strings are learned from the training data, and
then the rules are used to find the conceptual de-
pendency graph for a new data. Compared with
other search strategies, this method makes use of
the structural information and allows construc-
tion of a dependency graph, not just a depend-
ency tree.
References
Califf, M.R. and Mooney, R.J. 2003. Bottom-Up Re-
lational Learning of Pattern Matching Rules for In-
formation Extraction, JMLR: 4:177-210.
Collins M. and Roark, B. 2004. Incremental parsing
with the perceptron algorithm. In Proc. of the 42rd
Annual Meeting of the ACL.
Copestake, A. and Briscoe, T. 2005. Noun com-
pounds revisited. In John I. Tait, editor, Charting a
New Course: Natural Language Processing and
Information Retrieval. Springer, Berlin, 2005.
Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. The MIT Press.
Giegerich, H.J. Compound or phrase? English noun-
plus-noun constructions and the stress criterion.
English Language and Linguistics, 8(1):1-24,
2004.
McDonald, R., Pereira, F., Ribarov, K. and Hajiˇc, J.
2005. Non-projective dependency parsing using
spanning tree algorithms. In Proc. of HLT/EMNLP.
Mei, J., Zhu, Y., Gao, Y., and Yin, H. 1982. Tongyici Cilin.
Shanghai Dictionary Press.
Mel'cuk, I., 1988. Dependency Syntax: Theory and
Practice. Albany. State Univ. of New York Press.
Page, D. Srinivasan A. 2003. ILP: A Short Look Back
and a Longer Look Forward. Journal of Machine
Learning Research 4: 415-430
Srinivasan, A. Ross D. K., Michael B. 2003. An Em-
pirical Study of the Use of Relevance Information
in Inductive Logic Programming. Journal of Ma-
chine Learning Research 4: 369-383.
Xue, N.W., Xia, F., Chiou, F.D.and Palmer, M. The
Penn Chinese TreeBank: Phrase Structure Annota-
tion of a Large Corpus. Natural Language Engi-
neering, 11(2): 207-238.
Yarowsky, D. 1982. Word-Sense Disambiguation
Using Statistical Models of Roget's Categories
Trained on Large Corpora. In Proceedings, COL-
ING-92. pp. 454-460, 1992.
50
