<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000510">
<title confidence="0.835812">
b&apos;Extracting Paraphrases from a Parallel Corpus
</title>
<author confidence="0.901267">
Regina Barzilay and Kathleen R. McKeown
</author>
<affiliation confidence="0.9898455">
Computer Science Department
Columbia University
</affiliation>
<address confidence="0.869939">
10027, New York, NY, USA
</address>
<email confidence="0.89296">
regina,kathy\x01 @cs.columbia.edu
</email>
<sectionHeader confidence="0.987284" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998354166666667">
While paraphrasing is critical both for
interpretation and generation of natu-
ral language, current systems use man-
ual or semi-automatic methods to col-
lect paraphrases. We present an un-
supervised learning algorithm for iden-
tification of paraphrases from a cor-
pus of multiple English translations of
the same source text. Our approach
yields phrasal and single word lexical
paraphrases as well as syntactic para-
phrases.
</bodyText>
<sectionHeader confidence="0.993406" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.971479645833333">
Paraphrases are alternative ways to convey the
same information. A method for the automatic
acquisition of paraphrases has both practical and
linguistic interest. From a practical point of view,
diversity in expression presents a major challenge
for many NLP applications. In multidocument
summarization, identification of paraphrasing is
required to find repetitive information in the in-
put documents. In generation, paraphrasing is
employed to create more varied and fluent text.
Most current applications use manually collected
paraphrases tailored to a specific application, or
utilize existing lexical resources such as Word-
Net (Miller et al., 1990) to identify paraphrases.
However, the process of manually collecting para-
phrases is time consuming, and moreover, the col-
lection is not reusable in other applications. Ex-
isting resources only include lexical paraphrases;
they do not include phrasal or syntactically based
paraphrases.
From a linguistic point of view, questions
concern the operative definition of paraphrases:
what types of lexical relations and syntactic
mechanisms can produce paraphrases? Many
linguists (Halliday, 1985; de Beaugrande and
Dressler, 1981) agree that paraphrases retain ap-
proximate conceptual equivalence, and are not
limited only to synonymy relations. But the ex-
tent of interchangeability between phrases which
form paraphrases is an open question (Dras,
1999). A corpus-based approach can provide in-
sights on this question by revealing paraphrases
that people use.
This paper presents a corpus-based method for
automatic extraction of paraphrases. We use a
large collection of multiple parallel English trans-
lations of novels1. This corpus provides many
instances of paraphrasing, because translations
preserve the meaning of the original source, but
may use different words to convey the mean-
ing. An example of parallel translations is shown
in Figure 1. It contains two pairs of para-
phrases: (burst into tears, cried) and (com-
fort, console).
Emma burst into tears and he tried to comfort her, say-
ing things to make her smile.
Emma cried, and he tried to console her, adorning his
words with puns.
</bodyText>
<figureCaption confidence="0.972616">
Figure 1: Two English translations of the French
</figureCaption>
<bodyText confidence="0.956493777777778">
sentence from Flauberts Madame Bovary
Our method for paraphrase extraction builds
upon methodology developed in Machine Trans-
lation (MT). In MT, pairs of translated sentences
from a bilingual corpus are aligned, and occur-
rence patterns of words in two languages in the
text are extracted and matched using correlation
measures. However, our parallel corpus is far
from the clean parallel corpora used in MT. The
</bodyText>
<page confidence="0.867431">
1
</page>
<bodyText confidence="0.995961673076923">
Foreign sources are not used in our experiment.
\x0crendition of a literary text into another language
not only includes the translation, but also restruc-
turing of the translation to fit the appropriate lit-
erary style. This process introduces differences
in the translations which are an intrinsic part of
the creative process. This results in greater dif-
ferences across translations than the differences
in typical MT parallel corpora, such as the Cana-
dian Hansards. We will return to this point later
in Section 3.
Based on the specifics of our corpus, we de-
veloped an unsupervised learning algorithm for
paraphrase extraction. During the preprocessing
stage, the corresponding sentences are aligned.
We base our method for paraphrasing extraction
on the assumption that phrases in aligned sen-
tences which appear in similar contexts are para-
phrases. To automatically infer which contexts
are good predictors of paraphrases, contexts sur-
rounding identical words in aligned sentences are
extracted and filtered according to their predic-
tive power. Then, these contexts are used to ex-
tract new paraphrases. In addition to learning lex-
ical paraphrases, the method also learns syntactic
paraphrases, by generalizing syntactic patterns of
the extracted paraphrases. Extracted paraphrases
are then applied to the corpus, and used to learn
new context rules. This iterative algorithm con-
tinues until no new paraphrases are discovered.
A novel feature of our approach is the ability to
extract multiple kinds of paraphrases:
Identification of lexical paraphrases. In con-
trast to earlier work on similarity, our approach
allows identification of multi-word paraphrases,
in addition to single words, a challenging issue
for corpus-based techniques.
Extraction of morpho-syntactic paraphrasing
rules. Our approach yields a set of paraphras-
ing patterns by extrapolating the syntactic and
morphological structure of extracted paraphrases.
This process relies on morphological information
and a part-of-speech tagging. Many of the rules
identified by the algorithm match those that have
been described as productive paraphrases in the
linguistic literature.
In the following sections, we provide an
overview of existing work on paraphrasing, then
we describe data used in this work, and detail our
paraphrase extraction technique. We present re-
sults of our evaluation, and conclude with a dis-
cussion of our results.
</bodyText>
<sectionHeader confidence="0.996568" genericHeader="related work">
2 Related Work on Paraphrasing
</sectionHeader>
<bodyText confidence="0.999384403846154">
Many NLP applications are required to deal with
the unlimited variety of human language in ex-
pressing the same information. So far, three
major approaches of collecting paraphrases have
emerged: manual collection, utilization of exist-
ing lexical resources and corpus-based extraction
of similar words.
Manual collection of paraphrases is usually
used in generation (Iordanskaja et al., 1991;
Robin, 1994). Paraphrasing is an inevitable part
of any generation task, because a semantic con-
cept can be realized in many different ways.
Knowledge of possible concept verbalizations can
help to generate a text which best fits existing syn-
tactic and pragmatic constraints. Traditionally, al-
ternative verbalizations are derived from a man-
ual corpus analysis, and are, therefore, applica-
tion specific.
The second approach utilization of existing
lexical resources, such as WordNet overcomes
the scalability problem associated with an appli-
cation specific collection of paraphrases. Lexical
resources are used in statistical generation, sum-
marization and question-answering. The ques-
tion here is what type of WordNet relations can
be considered as paraphrases. In some appli-
cations, only synonyms are considered as para-
phrases (Langkilde and Knight, 1998); in others,
looser definitions are used (Barzilay and Elhadad,
1997). These definitions are valid in the context
of particular applications; however, in general, the
correspondence between paraphrasing and types
of lexical relations is not clear. The same ques-
tion arises with automatically constructed the-
sauri (Pereira et al., 1993; Lin, 1998). While
the extracted pairs are indeed similar, they are not
paraphrases. For example, while dog and cat
are recognized as the most similar concepts by
the method described in (Lin, 1998), it is hard
to imagine a context in which these words would
be interchangeable.
The first attempt to derive paraphrasing rules
from corpora was undertaken by (Jacquemin et
al., 1997), who investigated morphological and
syntactic variants of technical terms. While these
\x0crules achieve high accuracy in identifying term
paraphrases, the techniques used have not been
extended to other types of paraphrasing yet. Sta-
tistical techniques were also successfully used
by (Lapata, 2001) to identify paraphrases of
adjective-noun phrases. In contrast, our method
is not limited to a particular paraphrase type.
</bodyText>
<sectionHeader confidence="0.984739" genericHeader="method">
3 The Data
</sectionHeader>
<bodyText confidence="0.998055891891892">
The corpus we use for identification of para-
phrases is a collection of multiple English trans-
lations from a foreign source text. Specifically,
we use literary texts written by foreign authors.
Many classical texts have been translated more
than once, and these translations are available
on-line. In our experiments we used 5 books,
among them, Flauberts Madame Bovary, Ander-
sens Fairy Tales and Vernes Twenty Thousand
Leagues Under the Sea. Some of the translations
were created during different time periods and in
different countries. In total, our corpus contains
11 translations 2.
At first glance, our corpus seems quite simi-
lar to parallel corpora used by researchers in MT,
such as the Canadian Hansards. The major dis-
tinction lies in the degree of proximity between
the translations. Analyzing multiple translations
of the literary texts, critics (e.g. (Wechsler, 1998))
have observed that translations are never iden-
tical, and each translator creates his own inter-
pretations of the text. Clauses such as adorning
his words with puns and saying things to make
her smile from the sentences in Figure 1 are ex-
amples of distinct translations. Therefore, a com-
plete match between words of related sentences
is impossible. This characteristic of our corpus
is similar to problems with noisy and comparable
corpora (Veronis, 2000), and it prevents us from
using methods developed in the MT community
based on clean parallel corpora, such as (Brown
et al., 1993).
Another distinction between our corpus and
parallel MT corpora is the irregularity of word
matchings: in MT, no words in the source lan-
guage are kept as is in the target language trans-
lation; for example, an English translation of
</bodyText>
<page confidence="0.972876">
2
</page>
<bodyText confidence="0.985033304347826">
Free of copyright restrictions part of
our corpus(9 translations) is available at
http://www.cs.columbia.edu/ regina /par.
a French source does not contain untranslated
French fragments. In contrast, in our corpus
the same word is usually used in both transla-
tions, and only sometimes its paraphrases are
used, which means that wordparaphrase pairs
will have lower co-occurrence rates than word
translation pairs in MT. For example, consider oc-
currences of the word boy in two translations of
Madame Bovary E. Marx-Avelings transla-
tion and Etexts translation. The first text contains
55 occurrences of boy, which correspond to 38
occurrences of boy and 17 occurrences of its
paraphrases (son, young fellow and young-
ster). This rules out using word translation meth-
ods based only on word co-occurrence counts.
On the other hand, the big advantage of our cor-
pus comes from the fact that parallel translations
share many words, which helps the matching pro-
cess. We describe below a method of paraphrase
extraction, exploiting these features of our corpus.
</bodyText>
<sectionHeader confidence="0.991967" genericHeader="method">
4 Preprocessing
</sectionHeader>
<bodyText confidence="0.999428454545455">
During the preprocessing stage, we perform sen-
tence alignment. Sentences which are translations
of the same source sentence contain a number of
identical words, which serve as a strong clue to
the matching process. Alignment is performed
using dynamic programming (Gale and Church,
1991) with a weight function based on the num-
ber of common words in a sentence pair. This
simple method achieves good results for our cor-
pus, because 42% of the words in corresponding
sentences are identical words on average. Align-
ment produces 44,562 pairs of sentences with
1,798,526 words. To evaluate the accuracy of
the alignment process, we analyzed 127 sentence
pairs from the algorithms output. 120(94.5%)
alignments were identified as correct alignments.
We then use a part-of-speech tagger and chun-
ker (Mikheev, 1997) to identify noun and verb
phrases in the sentences. These phrases become
the atomic units of the algorithm. We also record
for each token its derivational root, using the
CELEX(Baayen et al., 1993) database.
</bodyText>
<sectionHeader confidence="0.907097" genericHeader="method">
5 Method for Paraphrase Extraction
</sectionHeader>
<bodyText confidence="0.996467714285714">
Given the aforementioned differences between
translations, our method builds on similarity in
\x0cthe local context, rather than on global alignment.
Consider the two sentences in Figure 2.
And finally, dazzlingly white, it shone high above
them in the empty ? .
It appeared white and dazzling in the empty ? .
</bodyText>
<figureCaption confidence="0.854149">
Figure 2: Fragments of aligned sentences
</figureCaption>
<bodyText confidence="0.989153515151515">
Analyzing the contexts surrounding ? -
marked blanks in both sentences, one expects that
they should have the same meaning, because they
have the same premodifier empty and relate to
the same preposition in (in fact, the first ?
stands for sky, and the second for heavens).
Generalizing from this example, we hypothesize
that if the contexts surrounding two phrases look
similar enough, then these two phrases are likely
to be paraphrases. The definition of the context
depends on how similar the translations are. Once
we know which contexts are good paraphrase pre-
dictors, we can extract paraphrase patterns from
our corpus.
Examples of such contexts are verb-object re-
lations and noun-modifier relations, which were
traditionally used in word similarity tasks from
non-parallel corpora (Pereira et al., 1993; Hatzi-
vassiloglou and McKeown, 1993). However, in
our case, more indirect relations can also be clues
for paraphrasing, because we know a priori that
input sentences convey the same information. For
example, in sentences from Figure 3, the verbs
ringing and sounding do not share identical
subject nouns, but the modifier of both subjects
Evening is identical. Can we conclude that
identical modifiers of the subject imply verb sim-
ilarity? To address this question, we need a way
to identify contexts that are good predictors for
paraphrasing in a corpus.
People said The Evening Noise is sounding, the sun
is setting.
The evening bell is ringing, people used to say.
</bodyText>
<figureCaption confidence="0.910647">
Figure 3: Fragments of aligned sentences
</figureCaption>
<bodyText confidence="0.997838225806452">
To find good contexts, we can analyze all
contexts surrounding identical words in the pairs
of aligned sentences, and use these contexts to
learn new paraphrases. This provides a basis for
a bootstrapping mechanism. Starting with identi-
cal words in aligned sentences as a seed, we can
incrementally learn the good contexts, and in
turn use them to learn new paraphrases. Iden-
tical words play two roles in this process: first,
they are used to learn context rules; second, iden-
tical words are used in application of these rules,
because the rules contain information about the
equality of words in context.
This method of co-training has been previously
applied to a variety of natural language tasks,
such as word sense disambiguation (Yarowsky,
1995), lexicon construction for information ex-
traction (Riloff and Jones, 1999), and named en-
tity classification (Collins and Singer, 1999). In
our case, the co-training process creates a binary
classifier, which predicts whether a given pair of
phrases makes a paraphrase or not.
Our model is based on the DLCoTrain algo-
rithm proposed by (Collins and Singer, 1999),
which applies a co-training procedure to decision
list classifiers for two independent sets of fea-
tures. In our case, one set of features describes the
paraphrase pair itself, and another set of features
corresponds to contexts in which paraphrases oc-
cur. These features and their computation are de-
scribed below.
</bodyText>
<subsectionHeader confidence="0.953003">
5.1 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999272268292683">
Our paraphrase features include lexical and syn-
tactic descriptions of the paraphrase pair. The
lexical feature set consists of the sequence of to-
kens for each phrase in the paraphrase pair; the
syntactic feature set consists of a sequence of
part-of-speech tags where equal words and words
with the same root are marked. For example, the
value of the syntactic feature for the pair (the
vast chimney, the chimney) is (DT\x02 JJ NN\x03 ,
DT\x02 NN\x03 ), where indices indicate word equali-
ties. We believe that this feature can be useful for
two reasons: first, we expect that some syntac-
tic categories can not be paraphrased in another
syntactic category. For example, a determiner is
unlikely to be a paraphrase of a verb. Second,
this description is able to capture regularities in
phrase level paraphrasing. In fact, a similar rep-
resentation was used by (Jacquemin et al., 1997)
to describe term variations.
The contextual feature is a combination of
the left and right syntactic contexts surrounding
actual known paraphrases. There are a num-
\x0cber of context representations that can be con-
sidered as possible candidates: lexical n-grams,
POS-ngrams and parse tree fragments. The nat-
ural choice is a parse tree; however, existing
parsers perform poorly in our domain3. Part-
of-speech tags provide the required level of ab-
straction, and can be accurately computed for our
data. The left (right) context is a sequence of
part-of-speech tags of \x04 words, occurring on the
left (right) of the paraphrase. As in the case
of syntactic paraphrase features, tags of identi-
cal words are marked. For example, when \x04\x06\x05
\x07 , the contextual feature for the paraphrase pair
(comfort, console) from Figure 1 sentences
is left\x02 =VB\x02 TO\x03 , (tried to), left\x03 =VB\x02
TO\x03 , (tried to), right\x02 =PRP$\x08 ,\t , (her,)
right context$\x03 =PRP$\x08 ,\t , (her,). In the next
section, we describe how the classifiers for con-
textual and paraphrasing features are co-trained.
</bodyText>
<subsectionHeader confidence="0.998583">
5.2 The co-training algorithm
</subsectionHeader>
<bodyText confidence="0.990759">
Our co-training algorithm has three stages: ini-
tialization, training of the contextual classifier and
training of the paraphrasing classifiers.
Initialization Words which appear in both sen-
tences of an aligned pair are used to create the ini-
tial seed rules. Using identical words, we cre-
ate a set of positive paraphrasing examples, such
as word\x02 =tried, word\x03 =tried. However, train-
ing of the classifier demands negative examples
as well; in our case it requires pairs of words
in aligned sentences which are not paraphrases
of each other. To find negative examples, we
match identical words in the alignment against
all different words in the aligned sentence, as-
suming that identical words can match only each
other, and not any other word in the aligned sen-
tences. For example, tried from the first sen-
tence in Figure 1 does not correspond to any other
word in the second sentence but tried. Based
on this observation, we can derive negative ex-
amples such as word\x02 =tried, word\x03 =Emma and
word\x02 =tried, word\x03 =console. Given a pair of
identical words from two sentences of length \x04
and
, the algorithm produces one positive ex-
</bodyText>
<page confidence="0.987861">
3
</page>
<bodyText confidence="0.8993808">
To the best of our knowledge all existing statistical
parsers are trained on WSJ or similar type of corpora. In the
experiments we conducted, their performance significantly
degraded on our corpus literary texts.
ample and \x0b\x0c\x04\x0e
</bodyText>
<equation confidence="0.6563985">
\x10\x0f\x12\x11\x14\x13\x15\x0b\x16
\x17
</equation>
<bodyText confidence="0.979638171428572">
\x15\x0f\x12\x11 negative examples.
Training of the contextual classifier Using
this initial seed, we record contexts around pos-
itive and negative paraphrasing examples. From
all the extracted contexts we must identify the
ones which are strong predictors of their category.
Following (Collins and Singer, 1999), filtering is
based on the strength of the context and its fre-
quency. The strength of positive context \x18 is de-
fined as \x19\x1b\x1a\x12\x1c\x1e\x1d \x1f!\x0b\x16\x18&quot;\x13#\x11%$\x12\x19\x1b\x1a\x12\x1c\x1e\x1d \x1f!\x0b\x16\x18&quot;\x11 , where \x19&amp;\x1a\&apos;\x1c(\x1d)\x1f*\x0b\x0c\x18+\x13,\x11
is the number of times context \x18 surrounds posi-
tive examples (paraphrase pairs) and \x19&amp;\x1a\&apos;\x1c(\x1d)\x1f*\x0b\x0c\x18+\x11 is
the frequency of the context \x18 . Strength of the
negative context is defined in a symmetrical man-
ner. For the positive and the negative categories
we select - rules (-.\x05/\x0f\x120 in our experiments)
with the highest frequency and strength higher
than the predefined threshold of 95%. Examples
of selected context rules are shown in Figure 4.
The parameter of the contextual classifier is a
context length. In our experiments we found that
a maximal context length of three produces best
results. We also observed that for some rules a
shorter context works better. Therefore, when
recording contexts around positive and negative
examples, we record all the contexts with length
smaller or equal to the maximal length.
Because our corpus consists of translations of
several books, created by different translators,
we expect that the similarity between translations
varies from one book to another. This implies that
contextual rules should be specific to a particular
pair of translations. Therefore, we train the con-
textual classifier for each pair of translations sep-
arately.
</bodyText>
<equation confidence="0.99997675">
left1 = (VB2 TO1) right1 = (PRP$3 ,)
left3 = (VB2 TO1) right3 = (PRP$3 ,)
left1 = (WRB2 NN1) right1 = (NN3 IN)
left3 = (WRB2 NN1) right3 = (NN3 IN)
left1 = (VB2 ) right1 = (JJ1)
left3 = (VB2 ) right3 = (JJ1)
left1 = (IN NN2 ) right1 = (NN3 IN4 )
left3 = (NN2 ,) right3 = (NN3 IN4 )
</equation>
<figureCaption confidence="0.85467">
Figure 4: Example of context rules extracted by
the algorithm.
</figureCaption>
<bodyText confidence="0.98479284">
Training of the paraphrasing classifier Con-
text rules extracted in the previous stage are then
applied to the corpus to derive a new set of pairs
\x0cof positive and negative paraphrasing examples.
Applications of the rule performed by searching
sentence pairs for subsequences which match the
left and right parts of the contextual rule, and are
less than 5 tokens apart. For example, apply-
ing the first rule from Figure 4 to sentences from
Figure 1 yields the paraphrasing pair (comfort,
console). Note that in the original seed set, the
left and right contexts were separated by one to-
ken. This stretch in rule application allows us to
extract multi-word paraphrases.
For each extracted example, paraphrasing rules
are recorded and filtered in a similar manner as
contextual rules. Examples of lexical and syntac-
tic paraphrasing rules are shown in Figure 5 and
in Figure 6. After extracted lexical and syntactic
paraphrases are applied to the corpus, the contex-
tual classifier is retrained. New paraphrases not
only add more positive and negative instances to
the contextual classifier, but also revise contex-
tual rules for known instances based on new para-
phrase information.
</bodyText>
<figure confidence="0.982473933333333">
(NN2 POS NN1)6 (NN1 IN DT NN2 )
Kings son son of the king
(IN NN
2 )6 (VB
2 )
in bottles bottled
(VB2 to VB
1)6 (VB2 VB
1)
start to talk start talking
(VB2 RB1)6 (RB1 VB2 )
suddenly came came suddenly
(VB NN
2 )6 (VB
2 )
</figure>
<figureCaption confidence="0.969343333333333">
make appearance appear
Figure 5: Morpho-Syntactic patterns extracted by
the algorithm. Lower indices denote token equiv-
alence, upper indices denote root equivalence.
(countless, lots of) (repulsion, aversion)
(undertone, low voice) (shrubs, bushes)
(refuse, say no) (dull tone, gloom)
(sudden appearance, apparition)
Figure 6: Lexical paraphrases extracted by the al-
</figureCaption>
<bodyText confidence="0.91478725">
gorithm.
The iterative process is terminated when no
new paraphrases are discovered or the number of
iterations exceeds a predefined threshold.
</bodyText>
<sectionHeader confidence="0.989034" genericHeader="method">
6 The results
</sectionHeader>
<bodyText confidence="0.999656530612245">
Our algorithm produced 9483 pairs of lexical
paraphrases and 25 morpho-syntactic rules. To
evaluate the quality of produced paraphrases, we
picked at random 500 paraphrasing pairs from the
lexical paraphrases produced by our algorithm.
These pairs were used as test data and also to eval-
uate whether humans agree on paraphrasing judg-
ments. The judges were given a page of guide-
lines, defining paraphrase as approximate con-
ceptual equivalence. The main dilemma in de-
signing the evaluation is whether to include the
context: should the human judge see only a para-
phrase pair or should a pair of sentences contain-
ing these paraphrases also be given? In a simi-
lar MT task evaluation of word-to-word trans-
lation context is usually included (Melamed,
2001). Although paraphrasing is considered to
be context dependent, there is no agreement on
the extent. To evaluate the influence of context
on paraphrasing judgments, we performed two
experiments with and without context. First,
the human judge is given a paraphrase pair with-
out context, and after the judge entered his an-
swer, he is given the same pair with its surround-
ing context. Each context was evaluated by two
judges (other than the authors). The agreement
was measured using the Kappa coefficient (Siegel
and Castellan, 1988). Complete agreement be-
tween judges would correspond to K equals \x0f ;
if there is no agreement among judges, then K
equals 0 .
The judges agreement on the paraphrasing
judgment without context was 7 \x05 0\&apos;8:9\&apos;;
which is substantial agreement (Landis and Koch,
1977). The first judge found 439(87.8%) pairs
as correct paraphrases, and the second judge
426(85.2%). Judgments with context have even
higher agreement (7&lt;\x05.0\&apos;8:=\&apos;&gt; ), and judges identi-
fied 459(91.8%) and 457(91.4%) pairs as correct
paraphrases.
The recall of our method is a more problematic
issue. The algorithm can identify paraphrasing re-
lations only between words which occurred in our
corpus, which of course does not cover all English
tokens. Furthermore, direct comparison with an
electronic thesaurus like WordNet is impossible,
because it is not known a priori which lexical re-
lations in WordNet can form paraphrases. Thus,
we can not evaluate recall. We hand-evaluated
the coverage, by asking a human judges to extract
paraphrases from 50 sentences, and then counted
\x0chow many of these paraphrases where predicted
by our algorithm. From 70 paraphrases extracted
by human judge, 48(69%) were identified as para-
phrases by our algorithm.
In addition to evaluating our system output
through precision and recall, we also compared
our results with two other methods. The first of
these was a machine translation technique for de-
riving bilingual lexicons (Melamed, 2001) includ-
ing detection of non-compositional compounds 4.
We did this evaluation on 60% of the full dataset;
this is the portion of the data which is pub-
licly available. Our system produced 6,826 word
pairs from this data and Melamed provided the
top 6,826 word pairs resulting from his system
on this data. We randomly extracted 500 pairs
each from both sets of output. Of the 500 pairs
produced by our system, 354(70.8%) were sin-
gle word pairs and 146(29.2%) were multi-word
paraphrases, while the majority of pairs produced
by Melameds system were single word pairs
(90%). We mixed this output and gave the re-
sulting, randomly ordered 1000 pairs to six eval-
uators, all of whom were native speakers. Each
evaluator provided judgments on 500 pairs with-
out context. Precision for our system was 71.6%
and for Melameds was 52.7%. This increased
precision is a clear advantage of our approach and
shows that machine translation techniques cannot
be used without modification for this task, par-
ticularly for producing multi-word paraphrases.
There are three caveats that should be noted;
Melameds system was run without changes for
this new task of paraphrase extraction and his sys-
tem does not use chunk segmentation, he ran the
system for three days of computation and the re-
sult may be improved with more running time
since it makes incremental improvements on sub-
sequent rounds, and finally, the agreement be-
tween human judges was lower than in our pre-
vious experiments. We are currently exploring
whether the information produced by the two dif-
ferent systems may be combined to improve the
performance of either system alone.
Another view on the extracted paraphrases can
be derived by comparing them with the Word-
Net thesaurus. This comparison provides us with
</bodyText>
<page confidence="0.931358">
4
</page>
<bodyText confidence="0.997440269230769">
The equivalences that were identical on both sides were
removed from the output
quantitative evidence on the types of lexical re-
lations people use to create paraphrases. We se-
lected 112 paraphrasing pairs which occurred at
least 20 times in our corpus and such that the
words comprising each pair appear in WordNet.
The 20 times cutoff was chosen to ensure that
the identified pairs are general enough and not
idiosyncratic. We use the frequency threshold
to select paraphrases which are not tailored to
one context. Examples of paraphrases and their
WordNet relations are shown in Figure 7. Only
40(35%) paraphrases are synonyms, 36(32%) are
hyperonyms, 20(18%) are siblings in the hyper-
onym tree, 11(10%) are unrelated, and the re-
maining 5% are covered by other relations. These
figures quantitatively validate our intuition that
synonymy is not the only source of paraphras-
ing. One of the practical implications is that us-
ing synonymy relations exclusively to recognize
paraphrasing limits system performance.
Synonyms: (rise, stand up), (hot, warm)
Hyperonyms: (landlady, hostess), (reply, say)
Siblings: (city, town), (pine, fir)
Unrelated: (sick, tired), (next, then)
</bodyText>
<figureCaption confidence="0.842924">
Figure 7: Lexical paraphrases extracted by the al-
gorithm.
</figureCaption>
<sectionHeader confidence="0.978726" genericHeader="conclusions">
7 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.99971124">
In this paper, we presented a method for corpus-
based identification of paraphrases from multi-
ple English translations of the same source text.
We showed that a co-training algorithm based on
contextual and lexico-syntactic features of para-
phrases achieves high performance on our data.
The wide range of paraphrases extracted by our
algorithm sheds light on the paraphrasing phe-
nomena, which has not been studied from an em-
pirical perspective.
Future work will extend this approach to ex-
tract paraphrases from comparable corpora, such
as multiple reports from different news agencies
about the same event or different descriptions of
a disease from the medical literature. This exten-
sion will require using a more selective alignment
technique (similar to that of (Hatzivassiloglou et
al., 1999)). We will also investigate a more pow-
erful representation of contextual features. Fortu-
nately, statistical parsers produce reliable results
\x0con news texts, and therefore can be used to im-
prove context representation. This will allow us
to extract macro-syntactic paraphrases in addition
to local paraphrases which are currently produced
by the algorithm.
</bodyText>
<sectionHeader confidence="0.96697" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.944200857142857">
This work was partially supported by a Louis
Morin scholarship and by DARPA grant N66001-
00-1-8919 under the TIDES program. We are
grateful to Dan Melamed for providing us with
the output of his program. We thank Noemie El-
hadad, Mike Collins, Michael Elhadad and Maria
Lapata for useful discussions.
</bodyText>
<sectionHeader confidence="0.921488" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998026043478261">
R. H. Baayen, R. Piepenbrock, and H. van Rijn, editors.
1993. The CELEX Lexical Database(CD-ROM). Lin-
guistic Data Consortium, University of Pennsylvania.
R. Barzilay and M. Elhadad. 1997. Using lexical chains for
text summarization. In Proceedings of the ACL Workshop
on Intelligent Scalable Text Summarization, pages 1017,
Madrid, Spain, August.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of statistical machine transla-
tion: Parameter estimation. Computational Linguistics,
19(2):263311.
M. Collins and Y. Singer. 1999. Unsupervised models for
named entity classification. In proceedings of the Joint
SIGDAT Conference on Empirical Methods in Natural
Language Processing and Very Large Corpora.
R. de Beaugrande and W. V. Dressler. 1981. Introduction to
Text Linguistics. Longman, New York, NY.
M. Dras. 1999. Tree Adjoining Grammar and the Reluctant
Paraphrasing of Text. Ph.D. thesis, Macquarie Univer-
sity, Australia.
W. Gale and K. W. Church. 1991. A program for align-
ing sentences in bilingual corpora. In Proceedings of
the 29th Annual Meeting of the Association for Computa-
tional Linguistics, pages 18.
M. Halliday. 1985. An introduction to functional grammar.
Edward Arnold, UK.
V. Hatzivassiloglou and K.R. McKeown. 1993. Towards the
automatic identification of adjectival scales: Clustering
adjectives according to their meaning. In Proceedings of
the 31rd Annual Meeting of the Association for Compu-
tational Linguistics, pages 172182.
V. Hatzivassiloglou, J. Klavans, and E. Eskin. 1999. Detect-
ing text similarity over short passages: Exploring linguis-
tic feature combinations via machine learning. In pro-
ceedings of the Joint SIGDAT Conference on Empirical
Methods in Natural Language Processing and Very Large
Corpora.
L. Iordanskaja, R. Kittredge, and A. Polguere, 1991. Natural
language Generation in Artificial Intelligence and Com-
putational Linguistics, chapter 11. Kluwer Academic
Publishers.
C. Jacquemin, J. Klavans, and E. Tzoukermann. 1997. Ex-
pansion of multi-word terms for indexing and retrieval
using morphology and syntax. In proceedings of the 35th
Annual Meeting of the ACL, pages 2431, Madrid, Spain,
July. ACL.
J.R. Landis and G.G. Koch. 1977. The measurement
of observer agreement for categorical data. Biometrics,
33:159174.
I. Langkilde and K. Knight. 1998. Generation that exploits
corpus-based statistical knowledge. In proceedings of the
COLING-ACL.
Maria Lapata. 2001. A corpus-based account of regular pol-
ysemy: The case of context-sensitive adjectives. In Pro-
ceedings of the 2nd Meeting of the NAACL, Pittsburgh,
PA.
D. Lin. 1998. Automatic retrieval and clustering of similar
words. In proceedings of the COLING-ACL, pages 768
774.
Melamed. 2001. Empirical Methods for Exploiting Parallel
Texts. MIT press.
A. Mikheev. 1997. the ltg part of speech tagger. University
of Edinburgh.
G.A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K.J.
Miller. 1990. Introduction to WordNet: An on-line lexi-
cal database. International Journal of Lexicography (spe-
cial issue), 3(4):235245.
F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clus-
tering of english words. In proceedings of the 30th An-
nual Meeting of the ACL, pages 183190. ACL.
E. Riloff and R. Jones. 1999. Learning Dictionaries
for Information Extraction by Multi-level Boot-strapping.
In Proceedings of the Sixteenth National Conference
on Artificial Intelligence, pages 10441049. The AAAI
Press/MIT Press.
J. Robin. 1994. Revision-Based Generation of Natural
Language Summaries Providing Historical Background:
Corpus-Based Analysis, Design, Implementation, and
Evaluation. Ph.D. thesis, Department of Computer Sci-
ence, Columbia University, NY.
S. Siegel and N.J. Castellan. 1988. Non Parametric Statis-
tics for Behavioral Sciences. McGraw-Hill.
J. Veronis, editor. 2000. Parallel Text Processing: Align-
ment and Use of Translation Corpora. Kluwer Academic
Publishers.
R. Wechsler. 1998. Performing Without a Stage: The Art of
Literary Translation. Catbird Press.
D. Yarowsky. 1995. Unsupervised word sense disambigua-
tion rivaling supervised methods. In Proceedings of the
33rd Annual Meeting of the Association for Computa-
tional Linguistics, pages 189 196.
\x0c&apos;
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.834543">
<title confidence="0.999654">b&apos;Extracting Paraphrases from a Parallel Corpus</title>
<author confidence="0.999926">Regina Barzilay</author>
<author confidence="0.999926">Kathleen R McKeown</author>
<affiliation confidence="0.999964">Computer Science Department Columbia University</affiliation>
<address confidence="0.999999">10027, New York, NY, USA</address>
<email confidence="0.996794">regina,kathy\x01@cs.columbia.edu</email>
<abstract confidence="0.987426461538462">While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>H van Rijn</author>
<author>editors</author>
</authors>
<date>1993</date>
<booktitle>The CELEX Lexical Database(CD-ROM). Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania.</institution>
<marker>Baayen, Piepenbrock, van Rijn, editors, 1993</marker>
<rawString>R. H. Baayen, R. Piepenbrock, and H. van Rijn, editors. 1993. The CELEX Lexical Database(CD-ROM). Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization,</booktitle>
<pages>1017</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="6991" citStr="Barzilay and Elhadad, 1997" startWordPosition="1043" endWordPosition="1046">ative verbalizations are derived from a manual corpus analysis, and are, therefore, application specific. The second approach utilization of existing lexical resources, such as WordNet overcomes the scalability problem associated with an application specific collection of paraphrases. Lexical resources are used in statistical generation, summarization and question-answering. The question here is what type of WordNet relations can be considered as paraphrases. In some applications, only synonyms are considered as paraphrases (Langkilde and Knight, 1998); in others, looser definitions are used (Barzilay and Elhadad, 1997). These definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear. The same question arises with automatically constructed thesauri (Pereira et al., 1993; Lin, 1998). While the extracted pairs are indeed similar, they are not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be interchangeable. The first attempt to derive paraphrasing rules from cor</context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>R. Barzilay and M. Elhadad. 1997. Using lexical chains for text summarization. In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization, pages 1017, Madrid, Spain, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="9537" citStr="Brown et al., 1993" startWordPosition="1443" endWordPosition="1446">s, critics (e.g. (Wechsler, 1998)) have observed that translations are never identical, and each translator creates his own interpretations of the text. Clauses such as adorning his words with puns and saying things to make her smile from the sentences in Figure 1 are examples of distinct translations. Therefore, a complete match between words of related sentences is impossible. This characteristic of our corpus is similar to problems with noisy and comparable corpora (Veronis, 2000), and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as (Brown et al., 1993). Another distinction between our corpus and parallel MT corpora is the irregularity of word matchings: in MT, no words in the source language are kept as is in the target language translation; for example, an English translation of 2 Free of copyright restrictions part of our corpus(9 translations) is available at http://www.cs.columbia.edu/ regina /par. a French source does not contain untranslated French fragments. In contrast, in our corpus the same word is usually used in both translations, and only sometimes its paraphrases are used, which means that wordparaphrase pairs will have lower </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Y Singer</author>
</authors>
<title>Unsupervised models for named entity classification.</title>
<date>1999</date>
<booktitle>In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="14651" citStr="Collins and Singer, 1999" startWordPosition="2262" endWordPosition="2265">tences as a seed, we can incrementally learn the good contexts, and in turn use them to learn new paraphrases. Identical words play two roles in this process: first, they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context. This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our case, the co-training process creates a binary classifier, which predicts whether a given pair of phrases makes a paraphrase or not. Our model is based on the DLCoTrain algorithm proposed by (Collins and Singer, 1999), which applies a co-training procedure to decision list classifiers for two independent sets of features. In our case, one set of features describes the paraphrase pair itself, and another set of features corresponds to contexts in which paraphrases occur. These features and their computation are described below. 5.1 Feature Extraction Our paraphrase features include lex</context>
<context position="18976" citStr="Collins and Singer, 1999" startWordPosition="2953" endWordPosition="2956">rithm produces one positive ex3 To the best of our knowledge all existing statistical parsers are trained on WSJ or similar type of corpora. In the experiments we conducted, their performance significantly degraded on our corpus literary texts. ample and \x0b\x0c\x04\x0e \x10\x0f\x12\x11\x14\x13\x15\x0b\x16 \x17 \x15\x0f\x12\x11 negative examples. Training of the contextual classifier Using this initial seed, we record contexts around positive and negative paraphrasing examples. From all the extracted contexts we must identify the ones which are strong predictors of their category. Following (Collins and Singer, 1999), filtering is based on the strength of the context and its frequency. The strength of positive context \x18 is defined as \x19\x1b\x1a\x12\x1c\x1e\x1d \x1f!\x0b\x16\x18&quot;\x13#\x11%$\x12\x19\x1b\x1a\x12\x1c\x1e\x1d \x1f!\x0b\x16\x18&quot;\x11 , where \x19&amp;\x1a\&apos;\x1c(\x1d)\x1f*\x0b\x0c\x18+\x13,\x11 is the number of times context \x18 surrounds positive examples (paraphrase pairs) and \x19&amp;\x1a\&apos;\x1c(\x1d)\x1f*\x0b\x0c\x18+\x11 is the frequency of the context \x18 . Strength of the negative context is defined in a symmetrical manner. For the positive and the negative categories we select - rules (-.\</context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>M. Collins and Y. Singer. 1999. Unsupervised models for named entity classification. In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R de Beaugrande</author>
<author>W V Dressler</author>
</authors>
<title>Introduction to Text Linguistics.</title>
<date>1981</date>
<publisher>Longman,</publisher>
<location>New York, NY.</location>
<marker>de Beaugrande, Dressler, 1981</marker>
<rawString>R. de Beaugrande and W. V. Dressler. 1981. Introduction to Text Linguistics. Longman, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dras</author>
</authors>
<title>Tree Adjoining Grammar and the Reluctant Paraphrasing of Text.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>Macquarie University,</institution>
<contexts>
<context position="2039" citStr="Dras, 1999" startWordPosition="291" endWordPosition="292">reusable in other applications. Existing resources only include lexical paraphrases; they do not include phrasal or syntactically based paraphrases. From a linguistic point of view, questions concern the operative definition of paraphrases: what types of lexical relations and syntactic mechanisms can produce paraphrases? Many linguists (Halliday, 1985; de Beaugrande and Dressler, 1981) agree that paraphrases retain approximate conceptual equivalence, and are not limited only to synonymy relations. But the extent of interchangeability between phrases which form paraphrases is an open question (Dras, 1999). A corpus-based approach can provide insights on this question by revealing paraphrases that people use. This paper presents a corpus-based method for automatic extraction of paraphrases. We use a large collection of multiple parallel English translations of novels1. This corpus provides many instances of paraphrasing, because translations preserve the meaning of the original source, but may use different words to convey the meaning. An example of parallel translations is shown in Figure 1. It contains two pairs of paraphrases: (burst into tears, cried) and (comfort, console). Emma burst into</context>
</contexts>
<marker>Dras, 1999</marker>
<rawString>M. Dras. 1999. Tree Adjoining Grammar and the Reluctant Paraphrasing of Text. Ph.D. thesis, Macquarie University, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>18</pages>
<contexts>
<context position="11128" citStr="Gale and Church, 1991" startWordPosition="1696" endWordPosition="1699">ut using word translation methods based only on word co-occurrence counts. On the other hand, the big advantage of our corpus comes from the fact that parallel translations share many words, which helps the matching process. We describe below a method of paraphrase extraction, exploiting these features of our corpus. 4 Preprocessing During the preprocessing stage, we perform sentence alignment. Sentences which are translations of the same source sentence contain a number of identical words, which serve as a strong clue to the matching process. Alignment is performed using dynamic programming (Gale and Church, 1991) with a weight function based on the number of common words in a sentence pair. This simple method achieves good results for our corpus, because 42% of the words in corresponding sentences are identical words on average. Alignment produces 44,562 pairs of sentences with 1,798,526 words. To evaluate the accuracy of the alignment process, we analyzed 127 sentence pairs from the algorithms output. 120(94.5%) alignments were identified as correct alignments. We then use a part-of-speech tagger and chunker (Mikheev, 1997) to identify noun and verb phrases in the sentences. These phrases become the </context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>W. Gale and K. W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Halliday</author>
</authors>
<title>An introduction to functional grammar.</title>
<date>1985</date>
<publisher>Edward Arnold, UK.</publisher>
<contexts>
<context position="1781" citStr="Halliday, 1985" startWordPosition="253" endWordPosition="254"> paraphrases tailored to a specific application, or utilize existing lexical resources such as WordNet (Miller et al., 1990) to identify paraphrases. However, the process of manually collecting paraphrases is time consuming, and moreover, the collection is not reusable in other applications. Existing resources only include lexical paraphrases; they do not include phrasal or syntactically based paraphrases. From a linguistic point of view, questions concern the operative definition of paraphrases: what types of lexical relations and syntactic mechanisms can produce paraphrases? Many linguists (Halliday, 1985; de Beaugrande and Dressler, 1981) agree that paraphrases retain approximate conceptual equivalence, and are not limited only to synonymy relations. But the extent of interchangeability between phrases which form paraphrases is an open question (Dras, 1999). A corpus-based approach can provide insights on this question by revealing paraphrases that people use. This paper presents a corpus-based method for automatic extraction of paraphrases. We use a large collection of multiple parallel English translations of novels1. This corpus provides many instances of paraphrasing, because translations</context>
</contexts>
<marker>Halliday, 1985</marker>
<rawString>M. Halliday. 1985. An introduction to functional grammar. Edward Arnold, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Towards the automatic identification of adjectival scales: Clustering adjectives according to their meaning.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>172182</pages>
<contexts>
<context position="13093" citStr="Hatzivassiloglou and McKeown, 1993" startWordPosition="2008" endWordPosition="2012">act, the first ? stands for sky, and the second for heavens). Generalizing from this example, we hypothesize that if the contexts surrounding two phrases look similar enough, then these two phrases are likely to be paraphrases. The definition of the context depends on how similar the translations are. Once we know which contexts are good paraphrase predictors, we can extract paraphrase patterns from our corpus. Examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks from non-parallel corpora (Pereira et al., 1993; Hatzivassiloglou and McKeown, 1993). However, in our case, more indirect relations can also be clues for paraphrasing, because we know a priori that input sentences convey the same information. For example, in sentences from Figure 3, the verbs ringing and sounding do not share identical subject nouns, but the modifier of both subjects Evening is identical. Can we conclude that identical modifiers of the subject imply verb similarity? To address this question, we need a way to identify contexts that are good predictors for paraphrasing in a corpus. People said The Evening Noise is sounding, the sun is setting. The evening bell </context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>V. Hatzivassiloglou and K.R. McKeown. 1993. Towards the automatic identification of adjectival scales: Clustering adjectives according to their meaning. In Proceedings of the 31rd Annual Meeting of the Association for Computational Linguistics, pages 172182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>J Klavans</author>
<author>E Eskin</author>
</authors>
<title>Detecting text similarity over short passages: Exploring linguistic feature combinations via machine learning.</title>
<date>1999</date>
<booktitle>In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="29310" citStr="Hatzivassiloglou et al., 1999" startWordPosition="4609" endWordPosition="4612">aining algorithm based on contextual and lexico-syntactic features of paraphrases achieves high performance on our data. The wide range of paraphrases extracted by our algorithm sheds light on the paraphrasing phenomena, which has not been studied from an empirical perspective. Future work will extend this approach to extract paraphrases from comparable corpora, such as multiple reports from different news agencies about the same event or different descriptions of a disease from the medical literature. This extension will require using a more selective alignment technique (similar to that of (Hatzivassiloglou et al., 1999)). We will also investigate a more powerful representation of contextual features. Fortunately, statistical parsers produce reliable results \x0con news texts, and therefore can be used to improve context representation. This will allow us to extract macro-syntactic paraphrases in addition to local paraphrases which are currently produced by the algorithm. Acknowledgments This work was partially supported by a Louis Morin scholarship and by DARPA grant N66001- 00-1-8919 under the TIDES program. We are grateful to Dan Melamed for providing us with the output of his program. We thank Noemie Elha</context>
</contexts>
<marker>Hatzivassiloglou, Klavans, Eskin, 1999</marker>
<rawString>V. Hatzivassiloglou, J. Klavans, and E. Eskin. 1999. Detecting text similarity over short passages: Exploring linguistic feature combinations via machine learning. In proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>R Kittredge</author>
<author>A Polguere</author>
</authors>
<date>1991</date>
<booktitle>Natural language Generation in Artificial Intelligence and Computational Linguistics, chapter 11.</booktitle>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="6066" citStr="Iordanskaja et al., 1991" startWordPosition="907" endWordPosition="910">isting work on paraphrasing, then we describe data used in this work, and detail our paraphrase extraction technique. We present results of our evaluation, and conclude with a discussion of our results. 2 Related Work on Paraphrasing Many NLP applications are required to deal with the unlimited variety of human language in expressing the same information. So far, three major approaches of collecting paraphrases have emerged: manual collection, utilization of existing lexical resources and corpus-based extraction of similar words. Manual collection of paraphrases is usually used in generation (Iordanskaja et al., 1991; Robin, 1994). Paraphrasing is an inevitable part of any generation task, because a semantic concept can be realized in many different ways. Knowledge of possible concept verbalizations can help to generate a text which best fits existing syntactic and pragmatic constraints. Traditionally, alternative verbalizations are derived from a manual corpus analysis, and are, therefore, application specific. The second approach utilization of existing lexical resources, such as WordNet overcomes the scalability problem associated with an application specific collection of paraphrases. Lexical resource</context>
</contexts>
<marker>Iordanskaja, Kittredge, Polguere, 1991</marker>
<rawString>L. Iordanskaja, R. Kittredge, and A. Polguere, 1991. Natural language Generation in Artificial Intelligence and Computational Linguistics, chapter 11. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
<author>J Klavans</author>
<author>E Tzoukermann</author>
</authors>
<title>Expansion of multi-word terms for indexing and retrieval using morphology and syntax.</title>
<date>1997</date>
<booktitle>In proceedings of the 35th Annual Meeting of the ACL,</booktitle>
<pages>2431</pages>
<publisher>ACL.</publisher>
<location>Madrid, Spain,</location>
<contexts>
<context position="7638" citStr="Jacquemin et al., 1997" startWordPosition="1145" endWordPosition="1148">valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear. The same question arises with automatically constructed thesauri (Pereira et al., 1993; Lin, 1998). While the extracted pairs are indeed similar, they are not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be interchangeable. The first attempt to derive paraphrasing rules from corpora was undertaken by (Jacquemin et al., 1997), who investigated morphological and syntactic variants of technical terms. While these \x0crules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet. Statistical techniques were also successfully used by (Lapata, 2001) to identify paraphrases of adjective-noun phrases. In contrast, our method is not limited to a particular paraphrase type. 3 The Data The corpus we use for identification of paraphrases is a collection of multiple English translations from a foreign source text. Specifically, we use literary texts </context>
<context position="16097" citStr="Jacquemin et al., 1997" startWordPosition="2501" endWordPosition="2504">ags where equal words and words with the same root are marked. For example, the value of the syntactic feature for the pair (the vast chimney, the chimney) is (DT\x02 JJ NN\x03 , DT\x02 NN\x03 ), where indices indicate word equalities. We believe that this feature can be useful for two reasons: first, we expect that some syntactic categories can not be paraphrased in another syntactic category. For example, a determiner is unlikely to be a paraphrase of a verb. Second, this description is able to capture regularities in phrase level paraphrasing. In fact, a similar representation was used by (Jacquemin et al., 1997) to describe term variations. The contextual feature is a combination of the left and right syntactic contexts surrounding actual known paraphrases. There are a num\x0cber of context representations that can be considered as possible candidates: lexical n-grams, POS-ngrams and parse tree fragments. The natural choice is a parse tree; however, existing parsers perform poorly in our domain3. Partof-speech tags provide the required level of abstraction, and can be accurately computed for our data. The left (right) context is a sequence of part-of-speech tags of \x04 words, occurring on the left (</context>
</contexts>
<marker>Jacquemin, Klavans, Tzoukermann, 1997</marker>
<rawString>C. Jacquemin, J. Klavans, and E. Tzoukermann. 1997. Expansion of multi-word terms for indexing and retrieval using morphology and syntax. In proceedings of the 35th Annual Meeting of the ACL, pages 2431, Madrid, Spain, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Landis</author>
<author>G G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<pages>33--159174</pages>
<contexts>
<context position="24311" citStr="Landis and Koch, 1977" startWordPosition="3814" endWordPosition="3817"> experiments with and without context. First, the human judge is given a paraphrase pair without context, and after the judge entered his answer, he is given the same pair with its surrounding context. Each context was evaluated by two judges (other than the authors). The agreement was measured using the Kappa coefficient (Siegel and Castellan, 1988). Complete agreement between judges would correspond to K equals \x0f ; if there is no agreement among judges, then K equals 0 . The judges agreement on the paraphrasing judgment without context was 7 \x05 0\&apos;8:9\&apos;; which is substantial agreement (Landis and Koch, 1977). The first judge found 439(87.8%) pairs as correct paraphrases, and the second judge 426(85.2%). Judgments with context have even higher agreement (7&lt;\x05.0\&apos;8:=\&apos;&gt; ), and judges identified 459(91.8%) and 457(91.4%) pairs as correct paraphrases. The recall of our method is a more problematic issue. The algorithm can identify paraphrasing relations only between words which occurred in our corpus, which of course does not cover all English tokens. Furthermore, direct comparison with an electronic thesaurus like WordNet is impossible, because it is not known a priori which lexical relations in W</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>J.R. Landis and G.G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33:159174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
<author>K Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In proceedings of the COLING-ACL.</booktitle>
<contexts>
<context position="6922" citStr="Langkilde and Knight, 1998" startWordPosition="1033" endWordPosition="1036">s existing syntactic and pragmatic constraints. Traditionally, alternative verbalizations are derived from a manual corpus analysis, and are, therefore, application specific. The second approach utilization of existing lexical resources, such as WordNet overcomes the scalability problem associated with an application specific collection of paraphrases. Lexical resources are used in statistical generation, summarization and question-answering. The question here is what type of WordNet relations can be considered as paraphrases. In some applications, only synonyms are considered as paraphrases (Langkilde and Knight, 1998); in others, looser definitions are used (Barzilay and Elhadad, 1997). These definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear. The same question arises with automatically constructed thesauri (Pereira et al., 1993; Lin, 1998). While the extracted pairs are indeed similar, they are not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be int</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>I. Langkilde and K. Knight. 1998. Generation that exploits corpus-based statistical knowledge. In proceedings of the COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>A corpus-based account of regular polysemy: The case of context-sensitive adjectives.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd Meeting of the NAACL,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="7938" citStr="Lapata, 2001" startWordPosition="1189" endWordPosition="1190">not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be interchangeable. The first attempt to derive paraphrasing rules from corpora was undertaken by (Jacquemin et al., 1997), who investigated morphological and syntactic variants of technical terms. While these \x0crules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet. Statistical techniques were also successfully used by (Lapata, 2001) to identify paraphrases of adjective-noun phrases. In contrast, our method is not limited to a particular paraphrase type. 3 The Data The corpus we use for identification of paraphrases is a collection of multiple English translations from a foreign source text. Specifically, we use literary texts written by foreign authors. Many classical texts have been translated more than once, and these translations are available on-line. In our experiments we used 5 books, among them, Flauberts Madame Bovary, Andersens Fairy Tales and Vernes Twenty Thousand Leagues Under the Sea. Some of the translation</context>
</contexts>
<marker>Lapata, 2001</marker>
<rawString>Maria Lapata. 2001. A corpus-based account of regular polysemy: The case of context-sensitive adjectives. In Proceedings of the 2nd Meeting of the NAACL, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In proceedings of the COLING-ACL,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="7268" citStr="Lin, 1998" startWordPosition="1086" endWordPosition="1087">resources are used in statistical generation, summarization and question-answering. The question here is what type of WordNet relations can be considered as paraphrases. In some applications, only synonyms are considered as paraphrases (Langkilde and Knight, 1998); in others, looser definitions are used (Barzilay and Elhadad, 1997). These definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear. The same question arises with automatically constructed thesauri (Pereira et al., 1993; Lin, 1998). While the extracted pairs are indeed similar, they are not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be interchangeable. The first attempt to derive paraphrasing rules from corpora was undertaken by (Jacquemin et al., 1997), who investigated morphological and syntactic variants of technical terms. While these \x0crules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of paraphrasing yet</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In proceedings of the COLING-ACL, pages 768 774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melamed</author>
</authors>
<title>Empirical Methods for Exploiting Parallel Texts.</title>
<date>2001</date>
<publisher>MIT press.</publisher>
<contexts>
<context position="23509" citStr="Melamed, 2001" startWordPosition="3685" endWordPosition="3686"> we picked at random 500 paraphrasing pairs from the lexical paraphrases produced by our algorithm. These pairs were used as test data and also to evaluate whether humans agree on paraphrasing judgments. The judges were given a page of guidelines, defining paraphrase as approximate conceptual equivalence. The main dilemma in designing the evaluation is whether to include the context: should the human judge see only a paraphrase pair or should a pair of sentences containing these paraphrases also be given? In a similar MT task evaluation of word-to-word translation context is usually included (Melamed, 2001). Although paraphrasing is considered to be context dependent, there is no agreement on the extent. To evaluate the influence of context on paraphrasing judgments, we performed two experiments with and without context. First, the human judge is given a paraphrase pair without context, and after the judge entered his answer, he is given the same pair with its surrounding context. Each context was evaluated by two judges (other than the authors). The agreement was measured using the Kappa coefficient (Siegel and Castellan, 1988). Complete agreement between judges would correspond to K equals \x0</context>
<context position="25490" citStr="Melamed, 2001" startWordPosition="3997" endWordPosition="3998">priori which lexical relations in WordNet can form paraphrases. Thus, we can not evaluate recall. We hand-evaluated the coverage, by asking a human judges to extract paraphrases from 50 sentences, and then counted \x0chow many of these paraphrases where predicted by our algorithm. From 70 paraphrases extracted by human judge, 48(69%) were identified as paraphrases by our algorithm. In addition to evaluating our system output through precision and recall, we also compared our results with two other methods. The first of these was a machine translation technique for deriving bilingual lexicons (Melamed, 2001) including detection of non-compositional compounds 4. We did this evaluation on 60% of the full dataset; this is the portion of the data which is publicly available. Our system produced 6,826 word pairs from this data and Melamed provided the top 6,826 word pairs resulting from his system on this data. We randomly extracted 500 pairs each from both sets of output. Of the 500 pairs produced by our system, 354(70.8%) were single word pairs and 146(29.2%) were multi-word paraphrases, while the majority of pairs produced by Melameds system were single word pairs (90%). We mixed this output and ga</context>
</contexts>
<marker>Melamed, 2001</marker>
<rawString>Melamed. 2001. Empirical Methods for Exploiting Parallel Texts. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mikheev</author>
</authors>
<title>the ltg part of speech tagger.</title>
<date>1997</date>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="11650" citStr="Mikheev, 1997" startWordPosition="1782" endWordPosition="1783">e matching process. Alignment is performed using dynamic programming (Gale and Church, 1991) with a weight function based on the number of common words in a sentence pair. This simple method achieves good results for our corpus, because 42% of the words in corresponding sentences are identical words on average. Alignment produces 44,562 pairs of sentences with 1,798,526 words. To evaluate the accuracy of the alignment process, we analyzed 127 sentence pairs from the algorithms output. 120(94.5%) alignments were identified as correct alignments. We then use a part-of-speech tagger and chunker (Mikheev, 1997) to identify noun and verb phrases in the sentences. These phrases become the atomic units of the algorithm. We also record for each token its derivational root, using the CELEX(Baayen et al., 1993) database. 5 Method for Paraphrase Extraction Given the aforementioned differences between translations, our method builds on similarity in \x0cthe local context, rather than on global alignment. Consider the two sentences in Figure 2. And finally, dazzlingly white, it shone high above them in the empty ? . It appeared white and dazzling in the empty ? . Figure 2: Fragments of aligned sentences Anal</context>
</contexts>
<marker>Mikheev, 1997</marker>
<rawString>A. Mikheev. 1997. the ltg part of speech tagger. University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K J Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography (special issue),</journal>
<pages>3--4</pages>
<contexts>
<context position="1291" citStr="Miller et al., 1990" startWordPosition="182" endWordPosition="185">o convey the same information. A method for the automatic acquisition of paraphrases has both practical and linguistic interest. From a practical point of view, diversity in expression presents a major challenge for many NLP applications. In multidocument summarization, identification of paraphrasing is required to find repetitive information in the input documents. In generation, paraphrasing is employed to create more varied and fluent text. Most current applications use manually collected paraphrases tailored to a specific application, or utilize existing lexical resources such as WordNet (Miller et al., 1990) to identify paraphrases. However, the process of manually collecting paraphrases is time consuming, and moreover, the collection is not reusable in other applications. Existing resources only include lexical paraphrases; they do not include phrasal or syntactically based paraphrases. From a linguistic point of view, questions concern the operative definition of paraphrases: what types of lexical relations and syntactic mechanisms can produce paraphrases? Many linguists (Halliday, 1985; de Beaugrande and Dressler, 1981) agree that paraphrases retain approximate conceptual equivalence, and are </context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>G.A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K.J. Miller. 1990. Introduction to WordNet: An on-line lexical database. International Journal of Lexicography (special issue), 3(4):235245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>N Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of english words.</title>
<date>1993</date>
<booktitle>In proceedings of the 30th Annual Meeting of the ACL,</booktitle>
<pages>183190</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7256" citStr="Pereira et al., 1993" startWordPosition="1082" endWordPosition="1085"> paraphrases. Lexical resources are used in statistical generation, summarization and question-answering. The question here is what type of WordNet relations can be considered as paraphrases. In some applications, only synonyms are considered as paraphrases (Langkilde and Knight, 1998); in others, looser definitions are used (Barzilay and Elhadad, 1997). These definitions are valid in the context of particular applications; however, in general, the correspondence between paraphrasing and types of lexical relations is not clear. The same question arises with automatically constructed thesauri (Pereira et al., 1993; Lin, 1998). While the extracted pairs are indeed similar, they are not paraphrases. For example, while dog and cat are recognized as the most similar concepts by the method described in (Lin, 1998), it is hard to imagine a context in which these words would be interchangeable. The first attempt to derive paraphrasing rules from corpora was undertaken by (Jacquemin et al., 1997), who investigated morphological and syntactic variants of technical terms. While these \x0crules achieve high accuracy in identifying term paraphrases, the techniques used have not been extended to other types of para</context>
<context position="13056" citStr="Pereira et al., 1993" startWordPosition="2004" endWordPosition="2007">e preposition in (in fact, the first ? stands for sky, and the second for heavens). Generalizing from this example, we hypothesize that if the contexts surrounding two phrases look similar enough, then these two phrases are likely to be paraphrases. The definition of the context depends on how similar the translations are. Once we know which contexts are good paraphrase predictors, we can extract paraphrase patterns from our corpus. Examples of such contexts are verb-object relations and noun-modifier relations, which were traditionally used in word similarity tasks from non-parallel corpora (Pereira et al., 1993; Hatzivassiloglou and McKeown, 1993). However, in our case, more indirect relations can also be clues for paraphrasing, because we know a priori that input sentences convey the same information. For example, in sentences from Figure 3, the verbs ringing and sounding do not share identical subject nouns, but the modifier of both subjects Evening is identical. Can we conclude that identical modifiers of the subject imply verb similarity? To address this question, we need a way to identify contexts that are good predictors for paraphrasing in a corpus. People said The Evening Noise is sounding, </context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clustering of english words. In proceedings of the 30th Annual Meeting of the ACL, pages 183190. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-level Boot-strapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence,</booktitle>
<pages>10441049</pages>
<publisher>The AAAI Press/MIT Press.</publisher>
<contexts>
<context position="14591" citStr="Riloff and Jones, 1999" startWordPosition="2253" endWordPosition="2256">ng mechanism. Starting with identical words in aligned sentences as a seed, we can incrementally learn the good contexts, and in turn use them to learn new paraphrases. Identical words play two roles in this process: first, they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context. This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our case, the co-training process creates a binary classifier, which predicts whether a given pair of phrases makes a paraphrase or not. Our model is based on the DLCoTrain algorithm proposed by (Collins and Singer, 1999), which applies a co-training procedure to decision list classifiers for two independent sets of features. In our case, one set of features describes the paraphrase pair itself, and another set of features corresponds to contexts in which paraphrases occur. These features and their computation are described below</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning Dictionaries for Information Extraction by Multi-level Boot-strapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence, pages 10441049. The AAAI Press/MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background: Corpus-Based Analysis, Design, Implementation, and Evaluation.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, Columbia University, NY.</institution>
<contexts>
<context position="6080" citStr="Robin, 1994" startWordPosition="911" endWordPosition="912">g, then we describe data used in this work, and detail our paraphrase extraction technique. We present results of our evaluation, and conclude with a discussion of our results. 2 Related Work on Paraphrasing Many NLP applications are required to deal with the unlimited variety of human language in expressing the same information. So far, three major approaches of collecting paraphrases have emerged: manual collection, utilization of existing lexical resources and corpus-based extraction of similar words. Manual collection of paraphrases is usually used in generation (Iordanskaja et al., 1991; Robin, 1994). Paraphrasing is an inevitable part of any generation task, because a semantic concept can be realized in many different ways. Knowledge of possible concept verbalizations can help to generate a text which best fits existing syntactic and pragmatic constraints. Traditionally, alternative verbalizations are derived from a manual corpus analysis, and are, therefore, application specific. The second approach utilization of existing lexical resources, such as WordNet overcomes the scalability problem associated with an application specific collection of paraphrases. Lexical resources are used in </context>
</contexts>
<marker>Robin, 1994</marker>
<rawString>J. Robin. 1994. Revision-Based Generation of Natural Language Summaries Providing Historical Background: Corpus-Based Analysis, Design, Implementation, and Evaluation. Ph.D. thesis, Department of Computer Science, Columbia University, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Non Parametric Statistics for Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context position="24041" citStr="Siegel and Castellan, 1988" startWordPosition="3769" endWordPosition="3772">ilar MT task evaluation of word-to-word translation context is usually included (Melamed, 2001). Although paraphrasing is considered to be context dependent, there is no agreement on the extent. To evaluate the influence of context on paraphrasing judgments, we performed two experiments with and without context. First, the human judge is given a paraphrase pair without context, and after the judge entered his answer, he is given the same pair with its surrounding context. Each context was evaluated by two judges (other than the authors). The agreement was measured using the Kappa coefficient (Siegel and Castellan, 1988). Complete agreement between judges would correspond to K equals \x0f ; if there is no agreement among judges, then K equals 0 . The judges agreement on the paraphrasing judgment without context was 7 \x05 0\&apos;8:9\&apos;; which is substantial agreement (Landis and Koch, 1977). The first judge found 439(87.8%) pairs as correct paraphrases, and the second judge 426(85.2%). Judgments with context have even higher agreement (7&lt;\x05.0\&apos;8:=\&apos;&gt; ), and judges identified 459(91.8%) and 457(91.4%) pairs as correct paraphrases. The recall of our method is a more problematic issue. The algorithm can identify pa</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and N.J. Castellan. 1988. Non Parametric Statistics for Behavioral Sciences. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<date>2000</date>
<booktitle>Parallel Text Processing: Alignment and Use of Translation Corpora.</booktitle>
<editor>J. Veronis, editor.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>2000</marker>
<rawString>J. Veronis, editor. 2000. Parallel Text Processing: Alignment and Use of Translation Corpora. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wechsler</author>
</authors>
<title>Performing Without a Stage: The Art of Literary Translation.</title>
<date>1998</date>
<publisher>Catbird Press.</publisher>
<contexts>
<context position="8951" citStr="Wechsler, 1998" startWordPosition="1348" endWordPosition="1349">anslations are available on-line. In our experiments we used 5 books, among them, Flauberts Madame Bovary, Andersens Fairy Tales and Vernes Twenty Thousand Leagues Under the Sea. Some of the translations were created during different time periods and in different countries. In total, our corpus contains 11 translations 2. At first glance, our corpus seems quite similar to parallel corpora used by researchers in MT, such as the Canadian Hansards. The major distinction lies in the degree of proximity between the translations. Analyzing multiple translations of the literary texts, critics (e.g. (Wechsler, 1998)) have observed that translations are never identical, and each translator creates his own interpretations of the text. Clauses such as adorning his words with puns and saying things to make her smile from the sentences in Figure 1 are examples of distinct translations. Therefore, a complete match between words of related sentences is impossible. This characteristic of our corpus is similar to problems with noisy and comparable corpora (Veronis, 2000), and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as (Brown et al., 1993). Another dist</context>
</contexts>
<marker>Wechsler, 1998</marker>
<rawString>R. Wechsler. 1998. Performing Without a Stage: The Art of Literary Translation. Catbird Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="14517" citStr="Yarowsky, 1995" startWordPosition="2245" endWordPosition="2246"> to learn new paraphrases. This provides a basis for a bootstrapping mechanism. Starting with identical words in aligned sentences as a seed, we can incrementally learn the good contexts, and in turn use them to learn new paraphrases. Identical words play two roles in this process: first, they are used to learn context rules; second, identical words are used in application of these rules, because the rules contain information about the equality of words in context. This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999). In our case, the co-training process creates a binary classifier, which predicts whether a given pair of phrases makes a paraphrase or not. Our model is based on the DLCoTrain algorithm proposed by (Collins and Singer, 1999), which applies a co-training procedure to decision list classifiers for two independent sets of features. In our case, one set of features describes the paraphrase pair itself, and another set of features corresponds to contexts in which p</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 189 196. \x0c&apos;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>